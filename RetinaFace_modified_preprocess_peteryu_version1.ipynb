{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RetinaFace_modified_preprocess_peteryu_version1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kFHP_nLW7yyO",
        "pqrgECUcYvT1",
        "sHkLDU-7ZOam",
        "FODMpgPBbJek",
        "FGt6N_Nw783q",
        "7Ym8x_UvhjiY",
        "dLQYPK1MjHVA",
        "a9PpNkLwg0xn",
        "HQrSN2ZXkkGQ",
        "anadRtgKnGS9",
        "8coJacdLeW5c",
        "5CadaTTxdeky",
        "txncwMKUWKXn",
        "4IXSZvFMnQdM"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcadSkq8uTYn",
        "outputId": "3b2d8a6a-81ae-474d-a95c-d1b3296d2dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Start\n",
        "repo - https://github.com/peteryuX/retinaface-tf2\n",
        "\n",
        "Dataset - http://shuoyang1213.me/WIDERFACE/\n",
        "\n",
        "Training dataset download link - https://drive.google.com/file/d/15hGDLhsx8bLgLcIRD5DhYt5iBxnjNF1M/view\n",
        "\n",
        "Validation dataset download link - https://drive.google.com/file/d/1GUCogbp16PMGa39thoMMeWxp7Rp5oM8Q/view\n",
        "\n",
        "RetinaFace official annotations - http://shuoyang1213.me/WIDERFACE/support/bbx_annotation/wider_face_split.zip"
      ],
      "metadata": {
        "id": "hUFL9-au2sZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import tqdm\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd"
      ],
      "metadata": {
        "id": "Z-ncd2qR2uPq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download Dataset and annotations"
      ],
      "metadata": {
        "id": "kFHP_nLW7yyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "3gfA1wwoDaI4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training images\n",
        "gdd.download_file_from_google_drive(file_id='15hGDLhsx8bLgLcIRD5DhYt5iBxnjNF1M',\n",
        "                                    dest_path='/content/data/widertrain.zip',\n",
        "                                    unzip=True)"
      ],
      "metadata": {
        "id": "iQm7esuT3AA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e4e2ad-592e-44df-8a44-8602e2aea55e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 15hGDLhsx8bLgLcIRD5DhYt5iBxnjNF1M into /content/data/widertrain.zip... Done.\n",
            "Unzipping...Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#validation images\n",
        "gdd.download_file_from_google_drive(file_id='1GUCogbp16PMGa39thoMMeWxp7Rp5oM8Q',\n",
        "                                    dest_path='/content/data/widerval.zip',\n",
        "                                    unzip=True)"
      ],
      "metadata": {
        "id": "z7QwjI7U2_-j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f21dccb2-f255-4e42-c0be-226b36299d48"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1GUCogbp16PMGa39thoMMeWxp7Rp5oM8Q into /content/data/widerval.zip... Done.\n",
            "Unzipping...Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir labels"
      ],
      "metadata": {
        "id": "RUug0GigEGys"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ground truth labels\n",
        "gdd.download_file_from_google_drive(file_id='1vgCABX1JI3NGBzsHxwBXlmRjaLV3NIsG',\n",
        "                                    dest_path='/content/labels/widergt.zip',\n",
        "                                    unzip=True)"
      ],
      "metadata": {
        "id": "BQFrpK4X2_8L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7b9ce73-0925-4014-840f-f035fdec344b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1vgCABX1JI3NGBzsHxwBXlmRjaLV3NIsG into /content/labels/widergt.zip... Done.\n",
            "Unzipping...Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/labels/train/label.txt /content/data/WIDER_train/"
      ],
      "metadata": {
        "id": "PMEfWnmN2_5W"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/labels/val/label.txt /content/data/WIDER_val/"
      ],
      "metadata": {
        "id": "1a1oZ1SU2uNI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From official site as well http://shuoyang1213.me/WIDERFACE/"
      ],
      "metadata": {
        "id": "uj96H9bkLcOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://shuoyang1213.me/WIDERFACE/support/bbx_annotation/wider_face_split.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh13uhzALBYk",
        "outputId": "2bf71a8d-17a9-4e1b-a8cc-442ea03bfa2d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-10 09:15:59--  http://shuoyang1213.me/WIDERFACE/support/bbx_annotation/wider_face_split.zip\n",
            "Resolving shuoyang1213.me (shuoyang1213.me)... 192.30.252.153, 192.30.252.154\n",
            "Connecting to shuoyang1213.me (shuoyang1213.me)|192.30.252.153|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3591642 (3.4M) [application/zip]\n",
            "Saving to: ‘wider_face_split.zip’\n",
            "\n",
            "wider_face_split.zi 100%[===================>]   3.42M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-01-10 09:15:59 (30.6 MB/s) - ‘wider_face_split.zip’ saved [3591642/3591642]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip /content/wider_face_split.zip"
      ],
      "metadata": {
        "id": "-SxQLvDiLBVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/wider_face_split/wider_face_train_bbx_gt.txt /content/data/WIDER_train\n",
        "!cp /content/wider_face_split/wider_face_val_bbx_gt.txt /content/data/WIDER_val"
      ],
      "metadata": {
        "id": "dBUUJ4HHLBS6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a23799dd-de96-4826-c485-27555bba3611"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/wider_face_split/wider_face_train_bbx_gt.txt': No such file or directory\n",
            "cp: cannot stat '/content/wider_face_split/wider_face_val_bbx_gt.txt': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/data/widerface\n",
        "!mkdir /content/data/widerface/train\n",
        "!mkdir /content/data/widerface/val"
      ],
      "metadata": {
        "id": "Bvo5lPlbF2_t"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ji6CExGFRXbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking Dataset"
      ],
      "metadata": {
        "id": "JeIroEQbF3l5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_folder = '/content/data/widerface/train/images'\n",
        "len(os.listdir(train_images_folder))"
      ],
      "metadata": {
        "id": "QqPSlJypF5c-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c5dd231-03ac-4399-fc21-d07f9e4566b6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(os.path.join(\n",
        "    train_images_folder, \n",
        "    os.listdir(train_images_folder)[0])))"
      ],
      "metadata": {
        "id": "jqANuetZGEhH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3295c0b9-b182-4957-baa0-47a59632d98c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "105"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "24IfOwWMGEaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing dataset"
      ],
      "metadata": {
        "id": "OcRA6qQG88AQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/data/widerface/train/label.txt') as f:\n",
        "    lines = f.readlines()"
      ],
      "metadata": {
        "id": "oEkv2NdiITvw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkpyDS2OITs3",
        "outputId": "e9dac489-70b2-4787-c5e7-45e3093c7982"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['# 0--Parade/0_Parade_marchingband_1_849.jpg\\n',\n",
              " '449 330 122 149 488.906 373.643 0.0 542.089 376.442 0.0 515.031 412.83 0.0 485.174 425.893 0.0 538.357 431.491 0.0 0.82\\n',\n",
              " '# 0--Parade/0_Parade_Parade_0_904.jpg\\n',\n",
              " '361 98 263 339 424.143 251.656 0.0 547.134 232.571 0.0 494.121 325.875 0.0 453.83 368.286 0.0 561.978 342.839 0.0 0.89\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,line in enumerate(lines):\n",
        "    if '#' not in line:\n",
        "        l = len(line.split())\n",
        "        if l!=20:\n",
        "            print(i,l)"
      ],
      "metadata": {
        "id": "2_WFsrVEIkal"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "clIKv8aoFwZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Oz1aOlxVVeXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing img and bounding boxes"
      ],
      "metadata": {
        "id": "pqrgECUcYvT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(samples)"
      ],
      "metadata": {
        "id": "L3Kau-GqE1JP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "b45b476a-811f-4aa0-8f0b-7bf5db12478f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-7dc288e44ddf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'samples' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(samples[4][0])\n",
        "for i in samples[4][1]:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "92Gx-UuJE1L9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "3f8850cb-4bb6-404c-b0e7-cf66a274e16f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-8ec9ded588b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'samples' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "im = cv2.imread(samples[4][0])\n",
        "im.shape"
      ],
      "metadata": {
        "id": "EGTag7uGE1Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(im[:,:,::-1])"
      ],
      "metadata": {
        "id": "DsHr9QZqZjgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples[4][1][0][:4]"
      ],
      "metadata": {
        "id": "sT06zt91aRaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for s in samples[4][1]:\n",
        "    x,y,w,h = s[:4]\n",
        "    cv2.rectangle(im, (int(x), int(y)),(int(x+w), int(y+h)), (0,255,0), 4)"
      ],
      "metadata": {
        "id": "KWpJwGSAZjdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(im[:,:,::-1])"
      ],
      "metadata": {
        "id": "v1Iiz9OBcAAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9kMHSsMj7_2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing tfrecord"
      ],
      "metadata": {
        "id": "rND9pouqgS33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from absl import app, flags, logging"
      ],
      "metadata": {
        "id": "mY_QRtzNYSpC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tqdm\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "dataset_path = './data/widerface/train'\n",
        "output_path = 'widerface_train_bin.tfrecord'\n",
        "is_binary = True\n",
        "\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy()\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
        "\n",
        "\n",
        "def _float_feature(value):\n",
        "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
        "\n",
        "\n",
        "def _int64_feature(value):\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
        "\n",
        "\n",
        "def make_example(img_name, img_path, target, is_binary):\n",
        "    # Create a dictionary with features that may be relevant.\n",
        "    feature = {'image/img_name': _bytes_feature([img_name]),\n",
        "               'image/object/bbox/xmin': _float_feature(target[:, 0]),\n",
        "               'image/object/bbox/ymin': _float_feature(target[:, 1]),\n",
        "               'image/object/bbox/xmax': _float_feature(target[:, 2]),\n",
        "               'image/object/bbox/ymax': _float_feature(target[:, 3]),\n",
        "               'image/object/landmark0/x': _float_feature(target[:, 4]),\n",
        "               'image/object/landmark0/y': _float_feature(target[:, 5]),\n",
        "               'image/object/landmark1/x': _float_feature(target[:, 6]),\n",
        "               'image/object/landmark1/y': _float_feature(target[:, 7]),\n",
        "               'image/object/landmark2/x': _float_feature(target[:, 8]),\n",
        "               'image/object/landmark2/y': _float_feature(target[:, 9]),\n",
        "               'image/object/landmark3/x': _float_feature(target[:, 10]),\n",
        "               'image/object/landmark3/y': _float_feature(target[:, 11]),\n",
        "               'image/object/landmark4/x': _float_feature(target[:, 12]),\n",
        "               'image/object/landmark4/y': _float_feature(target[:, 13]),\n",
        "               'image/object/landmark/valid': _float_feature(target[:, 14])}\n",
        "    if is_binary:\n",
        "        img_str = open(img_path, 'rb').read()\n",
        "        feature['image/encoded'] = _bytes_feature([img_str])\n",
        "    else:\n",
        "        feature['image/img_path'] = _bytes_feature([img_path])\n",
        "\n",
        "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "\n",
        "def load_info(txt_path):\n",
        "    \"\"\"load info from txt\"\"\"\n",
        "    img_paths = []\n",
        "    words = []\n",
        "\n",
        "    f = open(txt_path, 'r')\n",
        "    lines = f.readlines()\n",
        "    isFirst = True\n",
        "    labels = []\n",
        "    for line in lines:\n",
        "        line = line.rstrip()\n",
        "        if line.startswith('#'):\n",
        "            if isFirst is True:\n",
        "                isFirst = False\n",
        "            else:\n",
        "                labels_copy = labels.copy()\n",
        "                words.append(labels_copy)\n",
        "                labels.clear()\n",
        "            path = line[2:]\n",
        "            path = txt_path.replace('label.txt', 'images/') + path\n",
        "            img_paths.append(path)\n",
        "        else:\n",
        "            line = line.split(' ')\n",
        "            label = [float(x) for x in line]\n",
        "            labels.append(label)\n",
        "\n",
        "    words.append(labels)\n",
        "    return img_paths, words\n",
        "\n",
        "\n",
        "def get_target(labels):\n",
        "    annotations = np.zeros((0, 15))\n",
        "    if len(labels) == 0:\n",
        "        return annotations\n",
        "    for idx, label in enumerate(labels):\n",
        "        annotation = np.zeros((1, 15))\n",
        "        # bbox\n",
        "        annotation[0, 0] = label[0]  # x1\n",
        "        annotation[0, 1] = label[1]  # y1\n",
        "        annotation[0, 2] = label[0] + label[2]  # x2\n",
        "        annotation[0, 3] = label[1] + label[3]  # y2\n",
        "\n",
        "        # landmarks\n",
        "        annotation[0, 4] = label[4]    # l0_x\n",
        "        annotation[0, 5] = label[5]    # l0_y\n",
        "        annotation[0, 6] = label[7]    # l1_x\n",
        "        annotation[0, 7] = label[8]    # l1_y\n",
        "        annotation[0, 8] = label[10]   # l2_x\n",
        "        annotation[0, 9] = label[11]   # l2_y\n",
        "        annotation[0, 10] = label[13]  # l3_x\n",
        "        annotation[0, 11] = label[14]  # l3_y\n",
        "        annotation[0, 12] = label[16]  # l4_x\n",
        "        annotation[0, 13] = label[17]  # l4_y\n",
        "        if (annotation[0, 4] < 0):\n",
        "            annotation[0, 14] = -1  # w/o landmark\n",
        "        else:\n",
        "            annotation[0, 14] = 1\n",
        "\n",
        "        annotations = np.append(annotations, annotation, axis=0)\n",
        "    target = np.array(annotations)\n",
        "\n",
        "    return target\n",
        "\n",
        "\n",
        "\n",
        "if not os.path.isdir(dataset_path):\n",
        "    logging.info('Please define valid dataset path.')\n",
        "else:\n",
        "    logging.info('Loading {}'.format(dataset_path))\n",
        "\n",
        "logging.info('Reading data list...')\n",
        "img_paths, words = load_info(os.path.join(dataset_path, 'label.txt'))\n",
        "samples = list(zip(img_paths, words))\n",
        "random.shuffle(samples)\n",
        "\n",
        "if os.path.exists(output_path):\n",
        "    logging.info('{:s} already exists. Exit...'.format(\n",
        "        output_path))\n",
        "    exit()\n",
        "\n",
        "logging.info('Writing {} sample to tfrecord file...'.format(len(samples)))\n",
        "\n",
        "with tf.io.TFRecordWriter(output_path) as writer:\n",
        "    for img_path, word in tqdm.tqdm(samples):\n",
        "        target = get_target(word)\n",
        "        img_name = os.path.basename(img_path).replace('.jpg', '')\n",
        "\n",
        "        tf_example = make_example(img_name=str.encode(img_name),\n",
        "                                    img_path=str.encode(img_path),\n",
        "                                    target=target,\n",
        "                                    is_binary=is_binary)\n",
        "\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6BugOB7XchY",
        "outputId": "aa28bc12-b12c-473c-e712-f9383aefd185"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12880/12880 [00:14<00:00, 861.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8dKER4bZXcew"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Zf6hjDRSlltS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset checker"
      ],
      "metadata": {
        "id": "sHkLDU-7ZOam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AQSO5Vo9ZQcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "b49Ni11cZQ44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HRV8hEyGZQiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "FODMpgPBbJek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = {\n",
        "'batch_size': 1,\n",
        "'input_size': 640,\n",
        "'backbone_type': 'MobileNetV2',  # 'ResNet50', 'MobileNetV2'\n",
        "'sub_name': 'retinaface_mbv2',\n",
        "\n",
        "# training dataset\n",
        "'dataset_path': '/content/widerface_train_bin.tfrecord',\n",
        "'dataset_len': 12880,  # number of training samples\n",
        "'using_bin': True,            #using binary or not\n",
        "'using_flip': True,\n",
        "'using_distort': True,\n",
        "\n",
        "# testing dataset\n",
        "'testing_dataset_path': './data/widerface/val',\n",
        "\n",
        "# network\n",
        "'out_channel': 64,\n",
        "\n",
        "# anchor setting\n",
        "'min_sizes': [[16, 32], [64, 128], [256, 512]],\n",
        "'steps': [8, 16, 32],\n",
        "'match_thresh': 0.45,\n",
        "'ignore_thresh': 0.3,\n",
        "'variances': [0.1, 0.2],\n",
        "'clip': False,\n",
        "\n",
        "# training setting\n",
        "'epoch': 1,\n",
        "'init_lr': float(1e-2),\n",
        "'lr_decay_epoch': [50, 68],\n",
        "'lr_rate': 0.1,\n",
        "'warmup_epoch': 5,\n",
        "'min_lr': float(1e-3),\n",
        "\n",
        "'weights_decay': float(5e-4),\n",
        "'momentum': 0.9,\n",
        "\n",
        "'pretrain': True,\n",
        "\n",
        "'save_steps': 1000\n",
        "}"
      ],
      "metadata": {
        "id": "MiD3WxrqbMLN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions/Utilities - modules"
      ],
      "metadata": {
        "id": "FGt6N_Nw783q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Eb36_qEHhjOW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anchor"
      ],
      "metadata": {
        "id": "7Ym8x_UvhjiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r9JE2AeKSPUG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from itertools import product as product\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "#   Tensorflow / Numpy Priors                                                 #\n",
        "###############################################################################\n",
        "def prior_box(image_sizes, min_sizes, steps, clip=False):\n",
        "    \"\"\"prior box\"\"\"\n",
        "    feature_maps = [\n",
        "        [math.ceil(image_sizes[0] / step), math.ceil(image_sizes[1] / step)]\n",
        "        for step in steps]\n",
        "\n",
        "    anchors = []\n",
        "    for k, f in enumerate(feature_maps):\n",
        "        for i, j in product(range(f[0]), range(f[1])):\n",
        "            for min_size in min_sizes[k]:\n",
        "                s_kx = min_size / image_sizes[1]\n",
        "                s_ky = min_size / image_sizes[0]\n",
        "                cx = (j + 0.5) * steps[k] / image_sizes[1]\n",
        "                cy = (i + 0.5) * steps[k] / image_sizes[0]\n",
        "                anchors += [cx, cy, s_kx, s_ky]\n",
        "\n",
        "    output = np.asarray(anchors).reshape([-1, 4])\n",
        "\n",
        "    if clip:\n",
        "        output = np.clip(output, 0, 1)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def prior_box_tf(image_sizes, min_sizes, steps, clip=False):\n",
        "    \"\"\"prior box\"\"\"\n",
        "    image_sizes = tf.cast(tf.convert_to_tensor(image_sizes), tf.float32)\n",
        "    feature_maps = tf.math.ceil(\n",
        "        tf.reshape(image_sizes, [1, 2]) /\n",
        "        tf.reshape(tf.cast(steps, tf.float32), [-1, 1]))\n",
        "\n",
        "    anchors = []\n",
        "    for k in range(len(min_sizes)):\n",
        "        grid_x, grid_y = _meshgrid_tf(tf.range(feature_maps[k][1]),\n",
        "                                      tf.range(feature_maps[k][0]))\n",
        "        cx = (grid_x + 0.5) * steps[k] / image_sizes[1]\n",
        "        cy = (grid_y + 0.5) * steps[k] / image_sizes[0]\n",
        "        cxcy = tf.stack([cx, cy], axis=-1)\n",
        "        cxcy = tf.reshape(cxcy, [-1, 2])\n",
        "        cxcy = tf.repeat(cxcy, repeats=tf.shape(min_sizes[k])[0], axis=0)\n",
        "\n",
        "        sx = min_sizes[k] / image_sizes[1]\n",
        "        sy = min_sizes[k] / image_sizes[0]\n",
        "        sxsy = tf.stack([sx, sy], 1)\n",
        "        sxsy = tf.repeat(sxsy[tf.newaxis],\n",
        "                         repeats=tf.shape(grid_x)[0] * tf.shape(grid_x)[1],\n",
        "                         axis=0)\n",
        "        sxsy = tf.reshape(sxsy, [-1, 2])\n",
        "\n",
        "        anchors.append(tf.concat([cxcy, sxsy], 1))\n",
        "\n",
        "    output = tf.concat(anchors, axis=0)\n",
        "\n",
        "    if clip:\n",
        "        output = tf.clip_by_value(output, 0, 1)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def _meshgrid_tf(x, y):\n",
        "    \"\"\" workaround solution of the tf.meshgrid() issue:\n",
        "        https://github.com/tensorflow/tensorflow/issues/34470\"\"\"\n",
        "    grid_shape = [tf.shape(y)[0], tf.shape(x)[0]]\n",
        "    grid_x = tf.broadcast_to(tf.reshape(x, [1, -1]), grid_shape)\n",
        "    grid_y = tf.broadcast_to(tf.reshape(y, [-1, 1]), grid_shape)\n",
        "    return grid_x, grid_y\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "#   Tensorflow Encoding                                                       #\n",
        "###############################################################################\n",
        "def encode_tf(labels, priors, match_thresh, ignore_thresh,\n",
        "              variances=[0.1, 0.2]):\n",
        "    \"\"\"tensorflow encoding\"\"\"\n",
        "    assert ignore_thresh <= match_thresh\n",
        "    priors = tf.cast(priors, tf.float32)\n",
        "    bbox = labels[:, :4]\n",
        "    landm = labels[:, 4:-1]\n",
        "    landm_valid = labels[:, -1]  # 1: with landm, 0: w/o landm.\n",
        "\n",
        "    # jaccard index\n",
        "    overlaps = _jaccard(bbox, _point_form(priors))\n",
        "\n",
        "    # (Bipartite Matching)\n",
        "    # [num_objects] best prior for each ground truth\n",
        "    best_prior_overlap, best_prior_idx = tf.math.top_k(overlaps, k=1)\n",
        "    best_prior_overlap = best_prior_overlap[:, 0]\n",
        "    best_prior_idx = best_prior_idx[:, 0]\n",
        "\n",
        "    # [num_priors] best ground truth for each prior\n",
        "    overlaps_t = tf.transpose(overlaps)\n",
        "    best_truth_overlap, best_truth_idx = tf.math.top_k(overlaps_t, k=1)\n",
        "    best_truth_overlap = best_truth_overlap[:, 0]\n",
        "    best_truth_idx = best_truth_idx[:, 0]\n",
        "\n",
        "    # ensure best prior\n",
        "    def _loop_body(i, bt_idx, bt_overlap):\n",
        "        bp_mask = tf.one_hot(best_prior_idx[i], tf.shape(bt_idx)[0])\n",
        "        bp_mask_int = tf.cast(bp_mask, tf.int32)\n",
        "        new_bt_idx = bt_idx * (1 - bp_mask_int) + bp_mask_int * i\n",
        "        bp_mask_float = tf.cast(bp_mask, tf.float32)\n",
        "        new_bt_overlap = bt_overlap * (1 - bp_mask_float) + bp_mask_float * 2\n",
        "        return tf.cond(best_prior_overlap[i] > match_thresh,\n",
        "                       lambda: (i + 1, new_bt_idx, new_bt_overlap),\n",
        "                       lambda: (i + 1, bt_idx, bt_overlap))\n",
        "    _, best_truth_idx, best_truth_overlap = tf.while_loop(\n",
        "        lambda i, bt_idx, bt_overlap: tf.less(i, tf.shape(best_prior_idx)[0]),\n",
        "        _loop_body, [tf.constant(0), best_truth_idx, best_truth_overlap])\n",
        "\n",
        "    matches_bbox = tf.gather(bbox, best_truth_idx)  # [num_priors, 4]\n",
        "    matches_landm = tf.gather(landm, best_truth_idx)  # [num_priors, 10]\n",
        "    matches_landm_v = tf.gather(landm_valid, best_truth_idx)  # [num_priors]\n",
        "\n",
        "    loc_t = _encode_bbox(matches_bbox, priors, variances)\n",
        "    landm_t = _encode_landm(matches_landm, priors, variances)\n",
        "    landm_valid_t = tf.cast(matches_landm_v > 0, tf.float32)\n",
        "    conf_t = tf.cast(best_truth_overlap > match_thresh, tf.float32)\n",
        "    conf_t = tf.where(\n",
        "        tf.logical_and(best_truth_overlap < match_thresh,\n",
        "                       best_truth_overlap > ignore_thresh),\n",
        "        tf.ones_like(conf_t) * -1, conf_t)    # 1: pos, 0: neg, -1: ignore\n",
        "\n",
        "    return tf.concat([loc_t, landm_t, landm_valid_t[..., tf.newaxis],\n",
        "                      conf_t[..., tf.newaxis]], axis=1)\n",
        "\n",
        "\n",
        "def _encode_bbox(matched, priors, variances):\n",
        "    \"\"\"Encode the variances from the priorbox layers into the ground truth\n",
        "    boxes we have matched (based on jaccard overlap) with the prior boxes.\n",
        "    Args:\n",
        "        matched: (tensor) Coords of ground truth for each prior in point-form\n",
        "            Shape: [num_priors, 4].\n",
        "        priors: (tensor) Prior boxes in center-offset form\n",
        "            Shape: [num_priors,4].\n",
        "        variances: (list[float]) Variances of priorboxes\n",
        "    Return:\n",
        "        encoded boxes (tensor), Shape: [num_priors, 4]\n",
        "    \"\"\"\n",
        "\n",
        "    # dist b/t match center and prior's center\n",
        "    g_cxcy = (matched[:, :2] + matched[:, 2:]) / 2 - priors[:, :2]\n",
        "    # encode variance\n",
        "    g_cxcy /= (variances[0] * priors[:, 2:])\n",
        "    # match wh / prior wh\n",
        "    g_wh = (matched[:, 2:] - matched[:, :2]) / priors[:, 2:]\n",
        "    g_wh = tf.math.log(g_wh) / variances[1]\n",
        "    # return target for smooth_l1_loss\n",
        "    return tf.concat([g_cxcy, g_wh], 1)  # [num_priors,4]\n",
        "\n",
        "\n",
        "def _encode_landm(matched, priors, variances):\n",
        "    \"\"\"Encode the variances from the priorbox layers into the ground truth\n",
        "    boxes we have matched (based on jaccard overlap) with the prior boxes.\n",
        "    Args:\n",
        "        matched: (tensor) Coords of ground truth for each prior in point-form\n",
        "            Shape: [num_priors, 10].\n",
        "        priors: (tensor) Prior boxes in center-offset form\n",
        "            Shape: [num_priors,4].\n",
        "        variances: (list[float]) Variances of priorboxes\n",
        "    Return:\n",
        "        encoded landm (tensor), Shape: [num_priors, 10]\n",
        "    \"\"\"\n",
        "\n",
        "    # dist b/t match center and prior's center\n",
        "    matched = tf.reshape(matched, [tf.shape(matched)[0], 5, 2])\n",
        "    priors = tf.broadcast_to(\n",
        "        tf.expand_dims(priors, 1), [tf.shape(matched)[0], 5, 4])\n",
        "    g_cxcy = matched[:, :, :2] - priors[:, :, :2]\n",
        "    # encode variance\n",
        "    g_cxcy /= (variances[0] * priors[:, :, 2:])\n",
        "    # g_cxcy /= priors[:, :, 2:]\n",
        "    g_cxcy = tf.reshape(g_cxcy, [tf.shape(g_cxcy)[0], -1])\n",
        "    # return target for smooth_l1_loss\n",
        "    return g_cxcy\n",
        "\n",
        "\n",
        "def _point_form(boxes):\n",
        "    \"\"\" Convert prior_boxes to (xmin, ymin, xmax, ymax)\n",
        "    representation for comparison to point form ground truth data.\n",
        "    Args:\n",
        "        boxes: (tensor) center-size default boxes from priorbox layers.\n",
        "    Return:\n",
        "        boxes: (tensor) Converted xmin, ymin, xmax, ymax form of boxes.\n",
        "    \"\"\"\n",
        "    return tf.concat((boxes[:, :2] - boxes[:, 2:] / 2,\n",
        "                      boxes[:, :2] + boxes[:, 2:] / 2), axis=1)\n",
        "\n",
        "\n",
        "def _intersect(box_a, box_b):\n",
        "    \"\"\" We resize both tensors to [A,B,2]:\n",
        "    [A,2] -> [A,1,2] -> [A,B,2]\n",
        "    [B,2] -> [1,B,2] -> [A,B,2]\n",
        "    Then we compute the area of intersect between box_a and box_b.\n",
        "    Args:\n",
        "      box_a: (tensor) bounding boxes, Shape: [A,4].\n",
        "      box_b: (tensor) bounding boxes, Shape: [B,4].\n",
        "    Return:\n",
        "      (tensor) intersection area, Shape: [A,B].\n",
        "    \"\"\"\n",
        "    A = tf.shape(box_a)[0]\n",
        "    B = tf.shape(box_b)[0]\n",
        "    max_xy = tf.minimum(\n",
        "        tf.broadcast_to(tf.expand_dims(box_a[:, 2:], 1), [A, B, 2]),\n",
        "        tf.broadcast_to(tf.expand_dims(box_b[:, 2:], 0), [A, B, 2]))\n",
        "    min_xy = tf.maximum(\n",
        "        tf.broadcast_to(tf.expand_dims(box_a[:, :2], 1), [A, B, 2]),\n",
        "        tf.broadcast_to(tf.expand_dims(box_b[:, :2], 0), [A, B, 2]))\n",
        "    inter = tf.maximum((max_xy - min_xy), tf.zeros_like(max_xy - min_xy))\n",
        "    return inter[:, :, 0] * inter[:, :, 1]\n",
        "\n",
        "\n",
        "def _jaccard(box_a, box_b):\n",
        "    \"\"\"Compute the jaccard overlap of two sets of boxes.  The jaccard overlap\n",
        "    is simply the intersection over union of two boxes.  Here we operate on\n",
        "    ground truth boxes and default boxes.\n",
        "    E.g.:\n",
        "        A ∩ B / A ∪ B = A ∩ B / (area(A) + area(B) - A ∩ B)\n",
        "    Args:\n",
        "        box_a: (tensor) Ground truth bounding boxes, Shape: [num_objects,4]\n",
        "        box_b: (tensor) Prior boxes from priorbox layers, Shape: [num_priors,4]\n",
        "    Return:\n",
        "        jaccard overlap: (tensor) Shape: [box_a.size(0), box_b.size(0)]\n",
        "    \"\"\"\n",
        "    inter = _intersect(box_a, box_b)\n",
        "    area_a = tf.broadcast_to(\n",
        "        tf.expand_dims(\n",
        "            (box_a[:, 2] - box_a[:, 0]) * (box_a[:, 3] - box_a[:, 1]), 1),\n",
        "        tf.shape(inter))  # [A,B]\n",
        "    area_b = tf.broadcast_to(\n",
        "        tf.expand_dims(\n",
        "            (box_b[:, 2] - box_b[:, 0]) * (box_b[:, 3] - box_b[:, 1]), 0),\n",
        "        tf.shape(inter))  # [A,B]\n",
        "    union = area_a + area_b - inter\n",
        "    return inter / union  # [A,B]\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "#   Tensorflow Decoding                                                       #\n",
        "###############################################################################\n",
        "def decode_tf(labels, priors, variances=[0.1, 0.2]):\n",
        "    \"\"\"tensorflow decoding\"\"\"\n",
        "    bbox = _decode_bbox(labels[:, :4], priors, variances)\n",
        "    landm = _decode_landm(labels[:, 4:14], priors, variances)\n",
        "    landm_valid = labels[:, 14][:, tf.newaxis]\n",
        "    conf = labels[:, 15][:, tf.newaxis]\n",
        "\n",
        "    return tf.concat([bbox, landm, landm_valid, conf], axis=1)\n",
        "\n",
        "\n",
        "def _decode_bbox(pre, priors, variances=[0.1, 0.2]):\n",
        "    \"\"\"Decode locations from predictions using priors to undo\n",
        "    the encoding we did for offset regression at train time.\n",
        "    Args:\n",
        "        pre (tensor): location predictions for loc layers,\n",
        "            Shape: [num_priors,4]\n",
        "        priors (tensor): Prior boxes in center-offset form.\n",
        "            Shape: [num_priors,4].\n",
        "        variances: (list[float]) Variances of priorboxes\n",
        "    Return:\n",
        "        decoded bounding box predictions\n",
        "    \"\"\"\n",
        "    centers = priors[:, :2] + pre[:, :2] * variances[0] * priors[:, 2:]\n",
        "    sides = priors[:, 2:] * tf.math.exp(pre[:, 2:] * variances[1])\n",
        "\n",
        "    return tf.concat([centers - sides / 2, centers + sides / 2], axis=1)\n",
        "\n",
        "\n",
        "def _decode_landm(pre, priors, variances=[0.1, 0.2]):\n",
        "    \"\"\"Decode landm from predictions using priors to undo\n",
        "    the encoding we did for offset regression at train time.\n",
        "    Args:\n",
        "        pre (tensor): landm predictions for loc layers,\n",
        "            Shape: [num_priors,10]\n",
        "        priors (tensor): Prior boxes in center-offset form.\n",
        "            Shape: [num_priors,4].\n",
        "        variances: (list[float]) Variances of priorboxes\n",
        "    Return:\n",
        "        decoded landm predictions\n",
        "    \"\"\"\n",
        "    landms = tf.concat(\n",
        "        [priors[:, :2] + pre[:, :2] * variances[0] * priors[:, 2:],\n",
        "         priors[:, :2] + pre[:, 2:4] * variances[0] * priors[:, 2:],\n",
        "         priors[:, :2] + pre[:, 4:6] * variances[0] * priors[:, 2:],\n",
        "         priors[:, :2] + pre[:, 6:8] * variances[0] * priors[:, 2:],\n",
        "         priors[:, :2] + pre[:, 8:10] * variances[0] * priors[:, 2:]], axis=1)\n",
        "    return landms"
      ],
      "metadata": {
        "id": "grZEMEHnSPQT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "K1uooR5kSPK_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets"
      ],
      "metadata": {
        "id": "mcPa2FC3pn7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3GmgUdJEi_XW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def _parse_tfrecord(img_dim, using_bin, using_flip, using_distort,\n",
        "                    using_encoding, priors, match_thresh, ignore_thresh,\n",
        "                    variances):\n",
        "    def parse_tfrecord(tfrecord):\n",
        "        features = {\n",
        "            'image/img_name': tf.io.FixedLenFeature([], tf.string),\n",
        "            'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
        "            'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
        "            'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
        "            'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
        "            'image/object/landmark0/x': tf.io.VarLenFeature(tf.float32),\n",
        "            'image/object/landmark0/y': tf.io.VarLenFeature(tf.float32),\n",
        "            'image/object/landmark1/x': tf.io.VarLenFeature(tf.float32),\n",
        "            'image/object/landmark1/y': tf.io.VarLenFeature(tf.float32),\n",
        "            'image/object/landmark2/x': tf.io.VarLenFeature(tf.float32),\n",
        "            'image/object/landmark2/y': tf.io.VarLenFeature(tf.float32),\n",
        "            'image/object/landmark3/x': tf.io.VarLenFeature(tf.float32),\n",
        "            'image/object/landmark3/y': tf.io.VarLenFeature(tf.float32),\n",
        "            'image/object/landmark4/x': tf.io.VarLenFeature(tf.float32),\n",
        "            'image/object/landmark4/y': tf.io.VarLenFeature(tf.float32),\n",
        "            'image/object/landmark/valid': tf.io.VarLenFeature(tf.float32)}\n",
        "        if using_bin:\n",
        "            features['image/encoded'] = tf.io.FixedLenFeature([], tf.string)\n",
        "            x = tf.io.parse_single_example(tfrecord, features)\n",
        "            img = tf.image.decode_jpeg(x['image/encoded'], channels=3)\n",
        "        else:\n",
        "            features['image/img_path'] = tf.io.FixedLenFeature([], tf.string)\n",
        "            x = tf.io.parse_single_example(tfrecord, features)\n",
        "            image_encoded = tf.io.read_file(x['image/img_path'])\n",
        "            img = tf.image.decode_jpeg(image_encoded, channels=3)\n",
        "\n",
        "        labels = tf.stack(\n",
        "            [tf.sparse.to_dense(x['image/object/bbox/xmin']),\n",
        "             tf.sparse.to_dense(x['image/object/bbox/ymin']),\n",
        "             tf.sparse.to_dense(x['image/object/bbox/xmax']),\n",
        "             tf.sparse.to_dense(x['image/object/bbox/ymax']),\n",
        "             tf.sparse.to_dense(x['image/object/landmark0/x']),\n",
        "             tf.sparse.to_dense(x['image/object/landmark0/y']),\n",
        "             tf.sparse.to_dense(x['image/object/landmark1/x']),\n",
        "             tf.sparse.to_dense(x['image/object/landmark1/y']),\n",
        "             tf.sparse.to_dense(x['image/object/landmark2/x']),\n",
        "             tf.sparse.to_dense(x['image/object/landmark2/y']),\n",
        "             tf.sparse.to_dense(x['image/object/landmark3/x']),\n",
        "             tf.sparse.to_dense(x['image/object/landmark3/y']),\n",
        "             tf.sparse.to_dense(x['image/object/landmark4/x']),\n",
        "             tf.sparse.to_dense(x['image/object/landmark4/y']),\n",
        "             tf.sparse.to_dense(x['image/object/landmark/valid'])], axis=1)\n",
        "\n",
        "        img, labels = _transform_data(\n",
        "            img_dim, using_flip, using_distort, using_encoding, priors,\n",
        "            match_thresh, ignore_thresh, variances)(img, labels)\n",
        "\n",
        "        return img, labels\n",
        "    return parse_tfrecord\n",
        "\n",
        "\n",
        "def _transform_data(img_dim, using_flip, using_distort, using_encoding, priors,\n",
        "                    match_thresh, ignore_thresh, variances):\n",
        "    def transform_data(img, labels):\n",
        "        img = tf.cast(img, tf.float32)\n",
        "\n",
        "        # randomly crop\n",
        "        img, labels = _crop(img, labels)\n",
        "\n",
        "        # padding to square\n",
        "        img = _pad_to_square(img)\n",
        "\n",
        "        # resize\n",
        "        img, labels = _resize(img, labels, img_dim)\n",
        "\n",
        "        # randomly left-right flip\n",
        "        if using_flip:\n",
        "            img, labels = _flip(img, labels)\n",
        "\n",
        "        # distort\n",
        "        if using_distort:\n",
        "            img = _distort(img)\n",
        "\n",
        "        # encode labels to feature targets\n",
        "        if using_encoding:\n",
        "            labels = encode_tf(labels=labels, priors=priors,\n",
        "                               match_thresh=match_thresh,\n",
        "                               ignore_thresh=ignore_thresh,\n",
        "                               variances=variances)\n",
        "\n",
        "        return img, labels\n",
        "    return transform_data\n",
        "\n",
        "\n",
        "def load_tfrecord_dataset(tfrecord_name, batch_size, img_dim,\n",
        "                          using_bin=True, using_flip=True, using_distort=True,\n",
        "                          using_encoding=True, priors=None, match_thresh=0.45,\n",
        "                          ignore_thresh=0.3, variances=[0.1, 0.2],\n",
        "                          shuffle=True, buffer_size=10240):\n",
        "    \"\"\"load dataset from tfrecord\"\"\"\n",
        "    if not using_encoding:\n",
        "        assert batch_size == 1  # dynamic data len when using_encoding\n",
        "    else:\n",
        "        assert priors is not None\n",
        "\n",
        "    raw_dataset = tf.data.TFRecordDataset(tfrecord_name)\n",
        "    raw_dataset = raw_dataset.repeat()\n",
        "    if shuffle:\n",
        "        raw_dataset = raw_dataset.shuffle(buffer_size=buffer_size)\n",
        "    dataset = raw_dataset.map(\n",
        "        _parse_tfrecord(img_dim, using_bin, using_flip, using_distort,\n",
        "                        using_encoding, priors, match_thresh, ignore_thresh,\n",
        "                        variances),\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    dataset = dataset.prefetch(\n",
        "        buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "#   Data Augmentation                                                         #\n",
        "###############################################################################\n",
        "def _flip(img, labels):\n",
        "    flip_case = tf.random.uniform([], 0, 2, dtype=tf.int32)\n",
        "\n",
        "    def flip_func():\n",
        "        flip_img = tf.image.flip_left_right(img)\n",
        "        flip_labels = tf.stack([1 - labels[:, 2],  labels[:, 1],\n",
        "                                1 - labels[:, 0],  labels[:, 3],\n",
        "                                1 - labels[:, 6],  labels[:, 7],\n",
        "                                1 - labels[:, 4],  labels[:, 5],\n",
        "                                1 - labels[:, 8],  labels[:, 9],\n",
        "                                1 - labels[:, 12], labels[:, 13],\n",
        "                                1 - labels[:, 10], labels[:, 11],\n",
        "                                labels[:, 14]], axis=1)\n",
        "\n",
        "        return flip_img, flip_labels\n",
        "\n",
        "    img, labels = tf.case([(tf.equal(flip_case, 0), flip_func)],\n",
        "                          default=lambda: (img, labels))\n",
        "\n",
        "    return img, labels\n",
        "\n",
        "\n",
        "def _crop(img, labels, max_loop=250):\n",
        "    shape = tf.shape(img)\n",
        "\n",
        "    def matrix_iof(a, b):\n",
        "        \"\"\"\n",
        "        return iof of a and b, numpy version for data augenmentation\n",
        "        \"\"\"\n",
        "        lt = tf.math.maximum(a[:, tf.newaxis, :2], b[:, :2])\n",
        "        rb = tf.math.minimum(a[:, tf.newaxis, 2:], b[:, 2:])\n",
        "\n",
        "        area_i = tf.math.reduce_prod(rb - lt, axis=2) * \\\n",
        "            tf.cast(tf.reduce_all(lt < rb, axis=2), tf.float32)\n",
        "        area_a = tf.math.reduce_prod(a[:, 2:] - a[:, :2], axis=1)\n",
        "        return area_i / tf.math.maximum(area_a[:, tf.newaxis], 1)\n",
        "\n",
        "    def crop_loop_body(i, img, labels):\n",
        "        valid_crop = tf.constant(1, tf.int32)\n",
        "\n",
        "        pre_scale = tf.constant([0.3, 0.45, 0.6, 0.8, 1.0], dtype=tf.float32)\n",
        "        scale = pre_scale[tf.random.uniform([], 0, 5, dtype=tf.int32)]\n",
        "        short_side = tf.cast(tf.minimum(shape[0], shape[1]), tf.float32)\n",
        "        h = w = tf.cast(scale * short_side, tf.int32)\n",
        "        h_offset = tf.random.uniform([], 0, shape[0] - h + 1, dtype=tf.int32)\n",
        "        w_offset = tf.random.uniform([], 0, shape[1] - w + 1, dtype=tf.int32)\n",
        "        roi = tf.stack([w_offset, h_offset, w_offset + w, h_offset + h])\n",
        "        roi = tf.cast(roi, tf.float32)\n",
        "\n",
        "        value = matrix_iof(labels[:, :4], roi[tf.newaxis])\n",
        "        valid_crop = tf.cond(tf.math.reduce_any(value >= 1),\n",
        "                             lambda: valid_crop, lambda: 0)\n",
        "\n",
        "        centers = (labels[:, :2] + labels[:, 2:4]) / 2\n",
        "        mask_a = tf.reduce_all(\n",
        "            tf.math.logical_and(roi[:2] < centers, centers < roi[2:]),\n",
        "            axis=1)\n",
        "        labels_t = tf.boolean_mask(labels, mask_a)\n",
        "        valid_crop = tf.cond(tf.reduce_any(mask_a),\n",
        "                             lambda: valid_crop, lambda: 0)\n",
        "\n",
        "        img_t = img[h_offset:h_offset + h, w_offset:w_offset + w, :]\n",
        "        h_offset = tf.cast(h_offset, tf.float32)\n",
        "        w_offset = tf.cast(w_offset, tf.float32)\n",
        "        labels_t = tf.stack(\n",
        "            [labels_t[:, 0] - w_offset,  labels_t[:, 1] - h_offset,\n",
        "             labels_t[:, 2] - w_offset,  labels_t[:, 3] - h_offset,\n",
        "             labels_t[:, 4] - w_offset,  labels_t[:, 5] - h_offset,\n",
        "             labels_t[:, 6] - w_offset,  labels_t[:, 7] - h_offset,\n",
        "             labels_t[:, 8] - w_offset,  labels_t[:, 9] - h_offset,\n",
        "             labels_t[:, 10] - w_offset, labels_t[:, 11] - h_offset,\n",
        "             labels_t[:, 12] - w_offset, labels_t[:, 13] - h_offset,\n",
        "             labels_t[:, 14]], axis=1)\n",
        "\n",
        "        return tf.cond(valid_crop == 1,\n",
        "                       lambda: (max_loop, img_t, labels_t),\n",
        "                       lambda: (i + 1, img, labels))\n",
        "\n",
        "    _, img, labels = tf.while_loop(\n",
        "        lambda i, img, labels: tf.less(i, max_loop),\n",
        "        crop_loop_body,\n",
        "        [tf.constant(-1), img, labels],\n",
        "        shape_invariants=[tf.TensorShape([]),\n",
        "                          tf.TensorShape([None, None, 3]),\n",
        "                          tf.TensorShape([None, 15])])\n",
        "\n",
        "    return img, labels\n",
        "\n",
        "\n",
        "def _pad_to_square(img):\n",
        "    height = tf.shape(img)[0]\n",
        "    width = tf.shape(img)[1]\n",
        "\n",
        "    def pad_h():\n",
        "        img_pad_h = tf.ones([width - height, width, 3]) * \\\n",
        "            tf.reduce_mean(img, axis=[0, 1], keepdims=True)\n",
        "        return tf.concat([img, img_pad_h], axis=0)\n",
        "\n",
        "    def pad_w():\n",
        "        img_pad_w = tf.ones([height, height - width, 3]) * \\\n",
        "            tf.reduce_mean(img, axis=[0, 1], keepdims=True)\n",
        "        return tf.concat([img, img_pad_w], axis=1)\n",
        "\n",
        "    img = tf.case([(tf.greater(height, width), pad_w),\n",
        "                   (tf.less(height, width), pad_h)], default=lambda: img)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def _resize(img, labels, img_dim):\n",
        "    w_f = tf.cast(tf.shape(img)[1], tf.float32)\n",
        "    h_f = tf.cast(tf.shape(img)[0], tf.float32)\n",
        "    locs = tf.stack([labels[:, 0] / w_f,  labels[:, 1] / h_f,\n",
        "                     labels[:, 2] / w_f,  labels[:, 3] / h_f,\n",
        "                     labels[:, 4] / w_f,  labels[:, 5] / h_f,\n",
        "                     labels[:, 6] / w_f,  labels[:, 7] / h_f,\n",
        "                     labels[:, 8] / w_f,  labels[:, 9] / h_f,\n",
        "                     labels[:, 10] / w_f, labels[:, 11] / h_f,\n",
        "                     labels[:, 12] / w_f, labels[:, 13] / h_f], axis=1)\n",
        "    locs = tf.clip_by_value(locs, 0, 1)\n",
        "    labels = tf.concat([locs, labels[:, 14][:, tf.newaxis]], axis=1)\n",
        "\n",
        "    resize_case = tf.random.uniform([], 0, 5, dtype=tf.int32)\n",
        "\n",
        "    def resize(method):\n",
        "        def _resize():\n",
        "            return tf.image.resize(\n",
        "                img, [img_dim, img_dim], method=method, antialias=True)\n",
        "        return _resize\n",
        "\n",
        "    img = tf.case([(tf.equal(resize_case, 0), resize('bicubic')),\n",
        "                   (tf.equal(resize_case, 1), resize('area')),\n",
        "                   (tf.equal(resize_case, 2), resize('nearest')),\n",
        "                   (tf.equal(resize_case, 3), resize('lanczos3'))],\n",
        "                  default=resize('bilinear'))\n",
        "\n",
        "    return img, labels\n",
        "\n",
        "\n",
        "def _distort(img):\n",
        "    img = tf.image.random_brightness(img, 0.4)\n",
        "    img = tf.image.random_contrast(img, 0.5, 1.5)\n",
        "    img = tf.image.random_saturation(img, 0.5, 1.5)\n",
        "    img = tf.image.random_hue(img, 0.1)\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "FmD2wQ2WZ_8N"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5_aGK3I1Z_2I"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "dLQYPK1MjHVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Jp9MC1gvjKRV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import yaml\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from absl import logging\n",
        "\n",
        "\n",
        "\n",
        "def load_yaml(load_path):\n",
        "    \"\"\"load yaml file\"\"\"\n",
        "    with open(load_path, 'r') as f:\n",
        "        loaded = yaml.load(f, Loader=yaml.Loader)\n",
        "\n",
        "    return loaded\n",
        "\n",
        "\n",
        "def set_memory_growth():\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        try:\n",
        "            # Currently, memory growth needs to be the same across GPUs\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "                logical_gpus = tf.config.experimental.list_logical_devices(\n",
        "                    'GPU')\n",
        "                logging.info(\n",
        "                    \"Detect {} Physical GPUs, {} Logical GPUs.\".format(\n",
        "                        len(gpus), len(logical_gpus)))\n",
        "        except RuntimeError as e:\n",
        "            # Memory growth must be set before GPUs have been initialized\n",
        "            logging.info(e)\n",
        "\n",
        "\n",
        "def load_dataset(cfg, priors, shuffle=True, buffer_size=10240):\n",
        "    \"\"\"load dataset\"\"\"\n",
        "    logging.info(\"load dataset from {}\".format(cfg['dataset_path']))\n",
        "    dataset = load_tfrecord_dataset(\n",
        "        tfrecord_name=cfg['dataset_path'],\n",
        "        batch_size=cfg['batch_size'],\n",
        "        img_dim=cfg['input_size'],\n",
        "        using_bin=cfg['using_bin'],\n",
        "        using_flip=cfg['using_flip'],\n",
        "        using_distort=cfg['using_distort'],\n",
        "        using_encoding=True,\n",
        "        priors=priors,\n",
        "        match_thresh=cfg['match_thresh'],\n",
        "        ignore_thresh=cfg['ignore_thresh'],\n",
        "        variances=cfg['variances'],\n",
        "        shuffle=shuffle,\n",
        "        buffer_size=buffer_size)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "class ProgressBar(object):\n",
        "    \"\"\"A progress bar which can print the progress modified from\n",
        "       https://github.com/hellock/cvbase/blob/master/cvbase/progress.py\"\"\"\n",
        "    def __init__(self, task_num=0, completed=0, bar_width=25):\n",
        "        self.task_num = task_num\n",
        "        max_bar_width = self._get_max_bar_width()\n",
        "        self.bar_width = (bar_width\n",
        "                          if bar_width <= max_bar_width else max_bar_width)\n",
        "        self.completed = completed\n",
        "        self.first_step = completed\n",
        "        self.warm_up = False\n",
        "\n",
        "    def _get_max_bar_width(self):\n",
        "        if sys.version_info > (3, 3):\n",
        "            from shutil import get_terminal_size\n",
        "        else:\n",
        "            from backports.shutil_get_terminal_size import get_terminal_size\n",
        "        terminal_width, _ = get_terminal_size()\n",
        "        max_bar_width = min(int(terminal_width * 0.6), terminal_width - 50)\n",
        "        if max_bar_width < 10:\n",
        "            logging.info('terminal width is too small ({}), please consider '\n",
        "                         'widen the terminal for better progressbar '\n",
        "                         'visualization'.format(terminal_width))\n",
        "            max_bar_width = 10\n",
        "        return max_bar_width\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"reset\"\"\"\n",
        "        self.completed = 0\n",
        "        self.fps = 0\n",
        "\n",
        "    def update(self, inf_str=''):\n",
        "        \"\"\"update\"\"\"\n",
        "        self.completed += 1\n",
        "\n",
        "        if not self.warm_up:\n",
        "            self.start_time = time.time() - 1e-1\n",
        "            self.warm_up = True\n",
        "\n",
        "        if self.completed > self.task_num:\n",
        "            self.completed = self.completed % self.task_num\n",
        "            self.start_time = time.time() - 1 / self.fps\n",
        "            self.first_step = self.completed - 1\n",
        "            sys.stdout.write('\\n')\n",
        "\n",
        "        elapsed = time.time() - self.start_time\n",
        "        self.fps = (self.completed - self.first_step) / elapsed\n",
        "        percentage = self.completed / float(self.task_num)\n",
        "        mark_width = int(self.bar_width * percentage)\n",
        "        bar_chars = '>' * mark_width + ' ' * (self.bar_width - mark_width)\n",
        "        stdout_str = '\\rTraining [{}] {}/{}, {}  {:.1f} step/sec'\n",
        "        sys.stdout.write(stdout_str.format(\n",
        "            bar_chars, self.completed, self.task_num, inf_str, self.fps))\n",
        "\n",
        "        sys.stdout.flush()\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "#   Testing                                                                   #\n",
        "###############################################################################\n",
        "def pad_input_image(img, max_steps):\n",
        "    \"\"\"pad image to suitable shape\"\"\"\n",
        "    img_h, img_w, _ = img.shape\n",
        "\n",
        "    img_pad_h = 0\n",
        "    if img_h % max_steps > 0:\n",
        "        img_pad_h = max_steps - img_h % max_steps\n",
        "\n",
        "    img_pad_w = 0\n",
        "    if img_w % max_steps > 0:\n",
        "        img_pad_w = max_steps - img_w % max_steps\n",
        "\n",
        "    padd_val = np.mean(img, axis=(0, 1)).astype(np.uint8)\n",
        "    img = cv2.copyMakeBorder(img, 0, img_pad_h, 0, img_pad_w,\n",
        "                             cv2.BORDER_CONSTANT, value=padd_val.tolist())\n",
        "    pad_params = (img_h, img_w, img_pad_h, img_pad_w)\n",
        "\n",
        "    return img, pad_params\n",
        "\n",
        "\n",
        "def recover_pad_output(outputs, pad_params):\n",
        "    \"\"\"recover the padded output effect\"\"\"\n",
        "    img_h, img_w, img_pad_h, img_pad_w = pad_params\n",
        "    recover_xy = np.reshape(outputs[:, :14], [-1, 7, 2]) * \\\n",
        "        [(img_pad_w + img_w) / img_w, (img_pad_h + img_h) / img_h]\n",
        "    outputs[:, :14] = np.reshape(recover_xy, [-1, 14])\n",
        "\n",
        "    return outputs\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "#   Visulization                                                              #\n",
        "###############################################################################\n",
        "def draw_bbox_landm(img, ann, img_height, img_width):\n",
        "    \"\"\"draw bboxes and landmarks\"\"\"\n",
        "    # bbox\n",
        "    x1, y1, x2, y2 = int(ann[0] * img_width), int(ann[1] * img_height), \\\n",
        "                     int(ann[2] * img_width), int(ann[3] * img_height)\n",
        "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "    # confidence\n",
        "    text = \"{:.4f}\".format(ann[15])\n",
        "    cv2.putText(img, text, (int(ann[0] * img_width), int(ann[1] * img_height)),\n",
        "                cv2.FONT_HERSHEY_DUPLEX, 0.5, (255, 255, 255))\n",
        "\n",
        "    # landmark\n",
        "    if ann[14] > 0:\n",
        "        cv2.circle(img, (int(ann[4] * img_width),\n",
        "                         int(ann[5] * img_height)), 1, (255, 255, 0), 2)\n",
        "        cv2.circle(img, (int(ann[6] * img_width),\n",
        "                         int(ann[7] * img_height)), 1, (0, 255, 255), 2)\n",
        "        cv2.circle(img, (int(ann[8] * img_width),\n",
        "                         int(ann[9] * img_height)), 1, (255, 0, 0), 2)\n",
        "        cv2.circle(img, (int(ann[10] * img_width),\n",
        "                         int(ann[11] * img_height)), 1, (0, 100, 255), 2)\n",
        "        cv2.circle(img, (int(ann[12] * img_width),\n",
        "                         int(ann[13] * img_height)), 1, (255, 0, 100), 2)\n",
        "\n",
        "\n",
        "def draw_anchor(img, prior, img_height, img_width):\n",
        "    \"\"\"draw anchors\"\"\"\n",
        "    x1 = int(prior[0] * img_width - prior[2] * img_width / 2)\n",
        "    y1 = int(prior[1] * img_height - prior[3] * img_height / 2)\n",
        "    x2 = int(prior[0] * img_width + prior[2] * img_width / 2)\n",
        "    y2 = int(prior[1] * img_height + prior[3] * img_height / 2)\n",
        "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 0), 1)"
      ],
      "metadata": {
        "id": "Ftt3UbhAaWIU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xlhcXu1AaWBm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## losses"
      ],
      "metadata": {
        "id": "a9PpNkLwg0xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D3PdDh6yg2Qi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _smooth_l1_loss(y_true, y_pred):\n",
        "    t = tf.abs(y_pred - y_true)\n",
        "    return tf.where(t < 1, 0.5 * t ** 2, t - 0.5)\n",
        "\n",
        "\n",
        "def MultiBoxLoss(num_class=2, neg_pos_ratio=3):\n",
        "    \"\"\"multi-box loss\"\"\"\n",
        "    def multi_box_loss(y_true, y_pred):\n",
        "        num_batch = tf.shape(y_true)[0]\n",
        "        num_prior = tf.shape(y_true)[1]\n",
        "\n",
        "        loc_pred = tf.reshape(y_pred[0], [num_batch * num_prior, 4])\n",
        "        landm_pred = tf.reshape(y_pred[1], [num_batch * num_prior, 10])\n",
        "        class_pred = tf.reshape(y_pred[2], [num_batch * num_prior, num_class])\n",
        "\n",
        "        loc_true = tf.reshape(y_true[..., :4], [num_batch * num_prior, 4])\n",
        "        landm_true = tf.reshape(y_true[..., 4:14], [num_batch * num_prior, 10])\n",
        "        landm_valid = tf.reshape(y_true[..., 14], [num_batch * num_prior, 1])\n",
        "        class_true = tf.reshape(y_true[..., 15], [num_batch * num_prior, 1])\n",
        "\n",
        "        # define filter mask: class_true = 1 (pos), 0 (neg), -1 (ignore)\n",
        "        #                     landm_valid = 1 (w landm), 0 (w/o landm)\n",
        "        mask_pos = tf.equal(class_true, 1)\n",
        "        mask_neg = tf.equal(class_true, 0)\n",
        "        mask_landm = tf.logical_and(tf.equal(landm_valid, 1), mask_pos)\n",
        "\n",
        "        # landm loss (smooth L1)\n",
        "        mask_landm_b = tf.broadcast_to(mask_landm, tf.shape(landm_true))\n",
        "        loss_landm = _smooth_l1_loss(tf.boolean_mask(landm_true, mask_landm_b),\n",
        "                                     tf.boolean_mask(landm_pred, mask_landm_b))\n",
        "        loss_landm = tf.reduce_mean(loss_landm)\n",
        "\n",
        "        # localization loss (smooth L1)\n",
        "        mask_pos_b = tf.broadcast_to(mask_pos, tf.shape(loc_true))\n",
        "        loss_loc = _smooth_l1_loss(tf.boolean_mask(loc_true, mask_pos_b),\n",
        "                                   tf.boolean_mask(loc_pred, mask_pos_b))\n",
        "        loss_loc = tf.reduce_mean(loss_loc)\n",
        "\n",
        "        # classification loss (crossentropy)\n",
        "        # 1. compute max conf across batch for hard negative mining\n",
        "        loss_class = tf.where(mask_neg,\n",
        "                              1 - class_pred[:, 0][..., tf.newaxis], 0)\n",
        "\n",
        "        # 2. hard negative mining\n",
        "        loss_class = tf.reshape(loss_class, [num_batch, num_prior])\n",
        "        loss_class_idx = tf.argsort(loss_class, axis=1, direction='DESCENDING')\n",
        "        loss_class_idx_rank = tf.argsort(loss_class_idx, axis=1)\n",
        "        mask_pos_per_batch = tf.reshape(mask_pos, [num_batch, num_prior])\n",
        "        num_pos_per_batch = tf.reduce_sum(\n",
        "                tf.cast(mask_pos_per_batch, tf.float32), 1, keepdims=True)\n",
        "        num_pos_per_batch = tf.maximum(num_pos_per_batch, 1)\n",
        "        num_neg_per_batch = tf.minimum(neg_pos_ratio * num_pos_per_batch,\n",
        "                                       tf.cast(num_prior, tf.float32) - 1)\n",
        "        mask_hard_neg = tf.reshape(\n",
        "            tf.cast(loss_class_idx_rank, tf.float32) < num_neg_per_batch,\n",
        "            [num_batch * num_prior, 1])\n",
        "\n",
        "        # 3. classification loss including positive and negative examples\n",
        "        loss_class_mask = tf.logical_or(mask_pos, mask_hard_neg)\n",
        "        loss_class_mask_b = tf.broadcast_to(loss_class_mask,\n",
        "                                            tf.shape(class_pred))\n",
        "        filter_class_true = tf.boolean_mask(tf.cast(mask_pos, tf.float32),\n",
        "                                            loss_class_mask)\n",
        "        filter_class_pred = tf.boolean_mask(class_pred, loss_class_mask_b)\n",
        "        filter_class_pred = tf.reshape(filter_class_pred, [-1, num_class])\n",
        "        loss_class = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "            y_true=filter_class_true, y_pred=filter_class_pred)\n",
        "        loss_class = tf.reduce_mean(loss_class)\n",
        "\n",
        "        return loss_loc, loss_landm, loss_class\n",
        "\n",
        "    return multi_box_loss"
      ],
      "metadata": {
        "id": "nKYpTyQMAGJG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0ZN-OxCcAGGB"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## lr_scheduler"
      ],
      "metadata": {
        "id": "HQrSN2ZXkkGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TuC4EuT7knVz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MultiStepLR(initial_learning_rate, lr_steps, lr_rate, name='MultiStepLR'):\n",
        "    \"\"\"Multi-steps learning rate scheduler.\"\"\"\n",
        "    lr_steps_value = [initial_learning_rate]\n",
        "    for _ in range(len(lr_steps)):\n",
        "        lr_steps_value.append(lr_steps_value[-1] * lr_rate)\n",
        "    return tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "        boundaries=lr_steps, values=lr_steps_value)\n",
        "\n",
        "\n",
        "def MultiStepWarmUpLR(initial_learning_rate, lr_steps, lr_rate,\n",
        "                      warmup_steps=0., min_lr=0.,\n",
        "                      name='MultiStepWarmUpLR'):\n",
        "    \"\"\"Multi-steps warm up learning rate scheduler.\"\"\"\n",
        "    assert warmup_steps <= lr_steps[0]\n",
        "    assert min_lr <= initial_learning_rate\n",
        "    lr_steps_value = [initial_learning_rate]\n",
        "    for _ in range(len(lr_steps)):\n",
        "        lr_steps_value.append(lr_steps_value[-1] * lr_rate)\n",
        "    return PiecewiseConstantWarmUpDecay(\n",
        "        boundaries=lr_steps, values=lr_steps_value, warmup_steps=warmup_steps,\n",
        "        min_lr=min_lr)\n",
        "\n",
        "\n",
        "def CosineAnnealingLR_Restart(initial_learning_rate, t_period, lr_min):\n",
        "    \"\"\"Cosine annealing learning rate scheduler with restart.\"\"\"\n",
        "    return tf.keras.experimental.CosineDecayRestarts(\n",
        "        initial_learning_rate=initial_learning_rate,\n",
        "        first_decay_steps=t_period, t_mul=1.0, m_mul=1.0,\n",
        "        alpha=lr_min / initial_learning_rate)\n",
        "\n",
        "\n",
        "class PiecewiseConstantWarmUpDecay(\n",
        "        tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    \"\"\"A LearningRateSchedule wiht warm up schedule.\n",
        "    Modified from tf.keras.optimizers.schedules.PiecewiseConstantDecay\"\"\"\n",
        "\n",
        "    def __init__(self, boundaries, values, warmup_steps, min_lr,\n",
        "                 name=None):\n",
        "        super(PiecewiseConstantWarmUpDecay, self).__init__()\n",
        "\n",
        "        if len(boundaries) != len(values) - 1:\n",
        "            raise ValueError(\n",
        "                    \"The length of boundaries should be 1 less than the\"\n",
        "                    \"length of values\")\n",
        "\n",
        "        self.boundaries = boundaries\n",
        "        self.values = values\n",
        "        self.name = name\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.min_lr = min_lr\n",
        "\n",
        "    def __call__(self, step):\n",
        "        with tf.name_scope(self.name or \"PiecewiseConstantWarmUp\"):\n",
        "            step = tf.cast(tf.convert_to_tensor(step), tf.float32)\n",
        "            pred_fn_pairs = []\n",
        "            warmup_steps = self.warmup_steps\n",
        "            boundaries = self.boundaries\n",
        "            values = self.values\n",
        "            min_lr = self.min_lr\n",
        "\n",
        "            pred_fn_pairs.append(\n",
        "                (step <= warmup_steps,\n",
        "                 lambda: min_lr + step * (values[0] - min_lr) / warmup_steps))\n",
        "            pred_fn_pairs.append(\n",
        "                (tf.logical_and(step <= boundaries[0],\n",
        "                                step > warmup_steps),\n",
        "                 lambda: tf.constant(values[0])))\n",
        "            pred_fn_pairs.append(\n",
        "                (step > boundaries[-1], lambda: tf.constant(values[-1])))\n",
        "\n",
        "            for low, high, v in zip(boundaries[:-1], boundaries[1:],\n",
        "                                    values[1:-1]):\n",
        "                pred = (step > low) & (step <= high)\n",
        "                pred_fn_pairs.append((pred, lambda v=v: tf.constant(v)))\n",
        "\n",
        "            # The default isn't needed here because our conditions are mutually\n",
        "            # exclusive and exhaustive, but tf.case requires it.\n",
        "            return tf.case(pred_fn_pairs, lambda: tf.constant(values[0]),\n",
        "                           exclusive=True)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\n",
        "                \"boundaries\": self.boundaries,\n",
        "                \"values\": self.values,\n",
        "                \"warmup_steps\": self.warmup_steps,\n",
        "                \"min_lr\": self.min_lr,\n",
        "                \"name\": self.name\n",
        "        }\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    lr_scheduler = MultiStepWarmUpLR(1e-2, [5500, 6800], 0.1,\n",
        "                                     warmup_steps=500, min_lr=1e-3)\n",
        "    # lr_scheduler = MultiStepWarmUpLR(1e-3, [5500, 6800], 0.1)\n",
        "    # lr_scheduler = MultiStepLR(1e-4, [500, 1000, 2000, 3000], 0.5)\n",
        "    # lr_scheduler = CosineAnnealingLR_Restart(2e-4, 2500, 1e-7)\n",
        "\n",
        "    ##############################\n",
        "    # Draw figure\n",
        "    ##############################\n",
        "    N_iter = 10000\n",
        "    step_list = list(range(0, N_iter, 10))\n",
        "    lr_list = []\n",
        "    for i in step_list:\n",
        "        current_lr = lr_scheduler(i).numpy()\n",
        "        lr_list.append(current_lr)\n",
        "\n",
        "    import matplotlib as mpl\n",
        "    from matplotlib import pyplot as plt\n",
        "    import matplotlib.ticker as mtick\n",
        "    mpl.style.use('default')\n",
        "    import seaborn\n",
        "    seaborn.set(style='whitegrid')\n",
        "    seaborn.set_context('paper')\n",
        "\n",
        "    plt.figure(1)\n",
        "    plt.subplot(111)\n",
        "    plt.ticklabel_format(style='sci', axis='x', scilimits=(0, 0))\n",
        "    plt.title('Title', fontsize=16, color='k')\n",
        "    plt.plot(step_list, lr_list, linewidth=1.5, label='learning rate scheme')\n",
        "    legend = plt.legend(loc='upper right', shadow=False)\n",
        "    ax = plt.gca()\n",
        "    labels = ax.get_xticks().tolist()\n",
        "    for k, v in enumerate(labels):\n",
        "        labels[k] = str(int(v / 1000)) + 'K'\n",
        "    ax.set_xticklabels(labels)\n",
        "    ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.1e'))\n",
        "\n",
        "    ax.set_ylabel('Learning rate')\n",
        "    ax.set_xlabel('Iteration')\n",
        "    fig = plt.gcf()\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3yF3moKnaxAd",
        "outputId": "821deecf-e968-4fd7-eccb-46ea12eac96f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAHJCAYAAABHfXcUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXhU1f3H8c/MZELIxlZAFjGKSUCkJIRFQGQpEcWIiFYFifKzbCJRo7ZYi7IVqWIBBcsmChYFq6Vs4oLVKooaQFEsS3AhKBgXoCHJhCwz8/sjzEBMAplkljuT9+t5fDAzd+49c8KQT8753nNMTqfTKQAAANSZOdANAAAACBUEKwAAAC8hWAEAAHgJwQoAAMBLCFYAAABeQrACAADwEoIVAACAlxCsAAAAvIRgBQAA4CVhgW4AAPhTmzZtPH5Nr1699Morr+jGG2/Uhx9+qJdfflm9e/f26Bx1eS2A4EGwAlCv/Pa3v6302E8//aT//Oc/1T5/8cUXn/Wcf/3rXzV37lzdd999uv/++73STgDBiWAFoF6ZP39+pce2bdvmDlZVPe/y5JNPqqioqFajXgDqB4IVANQQgQrAuVC8DgA1dOONN6pNmzbatm2b+7E2bdpo7ty5kqS5c+eqTZs27v/uvffeGp9769atGjNmjJKTkxUXF6df//rX+t3vfqcdO3Z4/X0A8B1GrACgDn7729/qv//9r/bs2aNLLrlEnTp1cj/Xo0ePGp1jxowZWrJkicxms7p06aIePXro8OHDeuONN7RlyxbNmTNHN998s6/eAgAvIlgBQB3Mnz9ff/3rX7Vnzx5dddVVHhevv/DCC1qyZIni4uK0bNkyXXLJJe7nPvroI91+++168MEH1b17d1100UXebj4AL2MqEAACxOFwuKcRFy1aVCFUSdJll12me++9VyUlJVq1alUgmgjAQwQrAAiQL774Qrm5ue6aqqr06tVLkqi1AoIEU4EAECA5OTmSpIMHD57zjsOjR4/6o0kA6ohgBQAB4nA4JEktWrRQv379znps06ZN/dEkAHVEsAKAAGndurUkqUmTJmddmBRA8KDGCgDqyGq1SpLKyso8el1SUpKaNm2q7Oxs7d+/3xdNA+BnBCsAqKNWrVpJkrKzsz16ndVq1X333Sen06nf/e53ysrKqnSM3W7X+++/r507d3qlrQB8i6lAAKij/v37KzIyUq+//rqGDRumCy+8UBaLRd27dz/nwp7/93//p8OHD2vRokW6/vrrlZiYqLi4OEVEROjHH3/Unj17lJeXp9mzZyslJcVP7whAbRGsAKCOmjdvrlWrVmnevHnavXu3du7cKYfDobKyshqtmD5lyhQNHjxYzz//vLKysvSf//xHVqtVLVq0UK9evTRo0CBdffXVfngnAOrK5HQ6nYFuBAAAQCigxgoAAMBLCFYAAABeQrACAADwEoIVAACAlxCsAAAAvIRgBQAA4CWsY+VnZWVlysvLU4MGDWQ2k2sBAAgGDodDxcXFatSokcLCqo9PBCs/y8vL08GDBwPdDAAAUAtxcXFq1qxZtc8TrPysQYMGksq/MQ0bNvTaee12u7Kzs5WQkCCLxeK186Ii+tl/6Gv/oJ/9g372D1/2c1FRkQ4ePOj+OV4dgpWfuab/GjZsqMjISK+d1263S5IiIyP50PoQ/ew/9LV/0M/+QT/7hz/6+VxlPBT5AAAAeAnBCgAAwEuYCgQA+JTD4ZDT6Qx0MwLKNUXl+hO+UZd+NplMXrlbn2AFAPAJh8OhnJwcnTx5MtBNCTin06mwsDB9+eWXMplMgW5OyKprP0dEROiCCy6oU8AiWAEAfOLHH3+U2WxWfHx8vQ8TTqdTRUVFatiwYb3vC1+qSz87nU4dPnxYP/74o84777xat4FgBQDwOqfTqf/973+Ki4s762KK9YXT6ZTZbJbFYiFY+VBd+7lly5Y6ePCgWrZsWevvE8XrAACvczqdcjqdslqtgW4KUGNWq9X9d7e2CFYAAK+r78XqCG4EKwAAPDRw4EC99957Abn2Nddco23btgXk2kaRmJior776KtDN8DomvgEA8LNXX3010E1wW7Bggb7++mvNmzcv0E0JCYYbsVq1apWGDx+uSy+9VJmZmWc9NisrS2lpaerSpYtuuOEG7du3r87X7tu3r5KTk5WRkaG8vDz3c4899pgGDx6s5ORkpaamasWKFXW6FgAgNJWVlQW6CW5Gakt9Ybhg1aJFC02cOFE33XTTWY87fvy4Jk6cqDFjxmj79u1KS0vTnXfeqZKSklpd94MPPtCCBQu0ePFibd26VWazWVOnTnU/36BBAy1cuFA7d+7U3/72Nz377LPavHlzra4FADAWp9Op5557ToMHD1aPHj00duxY5ebmup+fPXu2+vfvr+TkZF1//fXKyspyP7dgwQJNmjRJf/zjH9WtWzctX75cDz74oKZNm6ZJkyYpOTlZQ4cO1f79+92vOXMacsGCBcrIyNCUKVOUkpKi1NTUCtOER44c0W233abk5GSNGDFCc+fOVXp6epXv47vvvlNiYqLWrl2rgQMHaujQoWdt/zvvvKMlS5bozTffVHJysgYOHChJKikp0dy5czVw4ED17NlT999/f4XBhjMdP35cd955p7p3767u3bvrt7/9rY4dOyZJys/P1yOPPKIrrrhCKSkpGjlyZIV1zXbs2KGrrrpKKSkpeuCBByr8DN+6dauGDx+ubt266frrr9eOHTvcz6Wnp2vevHkaNWqUkpKSlJ6erqNHj+ovf/mL+vfvr0GDBunjjz92H19QUOBuR58+fTRjxgwVFxdX+X7qynDB6sorr9SgQYPUpEmTsx63ZcsWtWvXTsOGDVN4eLhGjx4th8Ph/st4rg/JL61du1bDhw9Xp06dFB0drczMTG3ZskX5+fmSpHvvvVfx8fHuNVkGDhyonTt3eu+NA0CIczqdOllc5tP/alt0vGrVKm3cuFHLly/XBx98oEsuuaTCrEmnTp20du1abd++Xdddd53uueceFRUVuZ9/5513dPnllysrK0u33367JGnTpk0aPXq0duzYocsuu0yPP/54tdd/55131K9fP2VlZenWW2/VQw895H7uvvvu08UXX6yPPvpIjzzyiNauXXvO97N161Zt2LDBfWx17R8wYIDGjx+vK6+8Up9++qnefvttSdLcuXP13//+Vy+//LLeffddWa1WzZgxo8prPfvss3I6nXrvvff00UcfaerUqWrQoIEkafLkyTp69KjWrVunrKws3X///RUW33zjjTe0evVqvfnmm9q1a5c2bNggSdq3b58eeOABPfTQQ8rKytLdd9+tu+66yx3YJGnjxo2aPn26PvzwQ9ntdt10002Kj4/Xv//9b40YMUKPPPKI+9g//vGPKikp0ebNm/Xaa68pJydHf/vb387Zj7URtDVW2dnZ6tixo/trk8mkxMREZWdnq3///hU+JC1bttTChQuVmZmp1atXV3m+AwcO6IorrnB/HRcXJ6vVqq+//lpdunSpcKzD4dDOnTt166231rr9drvdq1sb+Gq7hJ/+V6Tpz3ysvALfJPtg43SW97HlXz+IpWh8i76uKCYyXH8a3V1tWkR79by++rfDbre7b1t3/Tf56fe17+Bxr17nlzrGNdVf7upTozWIXCHM6XRq9erVmjx5stq0aSNJ7pGmw4cPq3Xr1rr22mvdr7v99tv19NNP68svv9Sll14qp9OpTp06aciQIZLKZzicTqd+85vfKCUlRZI0dOhQvfzyyxWu6frT6XQqKSlJgwYNkiRdd911mj17to4dO6aioiLt2rVLy5YtU3h4uDp06KC0tDR98cUXVYZI12OTJk1SVFSU+7Fztf+XbVqzZo1eeeUVNW3aVJJ0991368orr9Rjjz0mi8VS4ZphYWE6fvy4cnJylJiYqE6dOkkqXyD23//+t7Zt2+YeLOnatWuFa40bN06NGzeWJPXr10///e9/dcMNN2jNmjW68cYb3f3Xv39/dejQQe+++66GDRsmp9OpYcOG6aKLLpIkDRo0SP/4xz80fPhwFRUVKS0tTXPmzFFBQYFOnjypt99+Wx999JG7TyZMmKAHH3xQ9957b6X+czqdVX4eavoZCdpgZbPZ1KhRowqPxcTEqLCwUJLcH5K2bdtKkjIyMpSUlKQjR46odevWVZ4vNja22vOd6fHHH1dYWJiGDx9e6/ZnZ2fX+rVns3v3bq+e75OvCvXdjwVePWdocAS6AfUIfS1J+bZSvfqfXeqR4N1g5eLtfzuk8h+4RUVFMpvN5T+wHL7/XjocdtlsthoHq5MnT8pms+nw4cPKzMys8Dqz2aycnBw1btxYzz//vNatW6eff/5ZklRYWKjc3FxddNFFKi0tVYsWLWSz2dyvtdvtatasmfsxk8mkoqIi9yjXmdcuLS1VkyZN3Me6QsfRo0f1888/Kzo6Wmaz2f18s2bN5HA4KlzPxTXN1rhx4wrPn6v9ZWVl7uNdge7mm2+ucG6TyaRvv/1WLVq0qPD4yJEjVVBQoEmTJqmoqEhDhgzRXXfdpW+++UbR0dGKiIiosq2SFB0d7X4uLCxMR48elc1m06FDh7Rz506tWbPGfWxZWZm6d+8um80mh8OhRo0auV9rsVjUtGnTCqOIrj7Mzc2V3W5X//79Kzxnt9srtcvhcKi0tLROn4egDVaRkZHuaTqXgoICdxp1fUjOHHI0m83Kzc3Vhg0btGTJEklSSkqKnnnmmXOez+Vvf/ub3nnnHa1atUrh4eG1bn9CQoIiIyNr/fpfstvt2r17tzp37lzpt4m6+OZ/X0k6ru4dW+q2IR28dt5g5XA4lJ2drYSEBK9s1onq0denPbtxjz7N/klt27ZVUlKcV8/tq3877Ha7vvzySzVs2NB93sczrlBxiW83IW4QXvMVt00mkyIiIhQZGalWrVpp2rRp6tmzZ6XjduzYoeeee07PP/+8uySkR48eatCggSIjI2W1WmW1Wiv8m26xWCo8FhERIUnurVbOvLbValVYWJj7WFd/RUREqF27diooKJDD4VB0dHmoPnr0qMxmc5U/Q1zXiYqKck/Hnav94eHhFa4fERGhiIgIrVu3zj04cTaRkZF66KGH9NBDD+nQoUMaO3asEhIS1K9fPxUUFKi4uLja8p6GDRu6r2u1WmWxWBQZGXnq73qSMjIyqnyd2WxWeHi4+7Xh4eEym81q2LChioqKKvT3hRdeqLCwMG3btu2cP7ftdrusVqs6duxY6fNgs9lqNCgStMEqISFBL730kvtrp9Op/fv3a8SIEZKkVq1aafr06VV+SLp27aoJEyZUeCw+Pl579+51F/rl5OSopKTEPcwoSUuXLtW//vUvrVq1Ss2bN69T+y0Wi1f/EfPVeQtPlt9Rct6vohTXurHXzhus7Ha7jv9g1QWtGvnk+4fT6OvTIhuWr15uMpl81he++DfJFSBcQcdkMqlhhHFC8pntGjFihObPn6/HH39c7dq1U15enj744AMNGTJENptNYWFhatKkiex2u5YuXaqCggL3a888T1Xn/uWfv3zN2Y5t06aNkpKS9OSTT+oPf/iDvv76a23atEkXXnhhlQGyqvOeq/2/+tWvtHXr1grbwdx88836y1/+oqlTp6pFixY6evSoPv30U/d05ZneeecdxcXF6YILLlBMTIw7ILVo0UIDBgzQtGnTNG3aNDVq1EifffaZLr300goB55f9ZjKZdPPNN2v8+PHq3bu3unbtqpKSEu3atUtxcXE677zzqu3zqvqwefPm6tevnx599FHdd999io2NVW5ubqUSoDPPUdXnoaafD+P8DT+lrKxMxcXFKisrk8PhUHFxsUpLSysdl5qaqpycHK1fv14lJSVauXKlJKl3796SpBEjRmjevHk6dOiQJCkvL++sd/ENHz5ca9eu1Z49e1RYWKj58+crNTVVMTExkqRly5ZpzZo1WrFihVq2bOntt21Y+bbyOzRiIms/OgcARpeenq5rrrlG48ePV9euXXXdddfp/ffflyRdfvnl6tevn66++moNHDhQYWFhatWqld/a9sQTT2j//v3q2bOnpk2bpmuvvdajGZNztf+qq65SWFiYevbs6Q5ODzzwgDp06KBbb71VycnJuuWWW6qdHsvJydGYMWPUtWtXDR06VH369NF1110nqXypoujoaA0dOlQ9e/bU3Llz5ajBlHCnTp302GOPac6cOerZs6cGDBig5557rkavrcpjjz0mq9WqYcOGKSUlRb/73e908ODBWp3rXExOg+07sGDBAi1cuLDCY9dff73+8pe/KDk5WcuWLVO3bt0kSR9//LFmzpypQ4cOKT4+Xn/+85/dBe0Oh0MvvPCCXnzxRf3www+KjY1V79699eijj1Z77VWrVmnx4sUqLCxUnz59NGvWLHcdV2Jionu41+Xaa6+t9i6J6thsNu3du1cdO3b0+lTgrl27lJSU5NXfOh9dkaUPd3+vCdd31jWXX3TuF4Q4X/UzKqOvT3vs+e16/7MjGn99Z6V5+XPoq3622+3uqdz6/v2TymdVbDabIiMj67wJ85///GcVFRVp1qxZXmpd6KhrP5/t721Nf34bbiowIyOj2jnVTz/9tMLXPXv21KZNm6o81mw2Kz09vdq1PqoyatQojRo1qsrnzlx/pD5xj1hFMWIFBJqxfg2Gv3zxxReKjo7WBRdcoJ07d2rdunX661//GuhmoRqGC1YwlvxCpgIBIJCOHj2qjIwMHTt2TL/61a901113qV+/foFuFqpBsMJZMWIFBF5dp44Q3Pr166d33nkn0M1ADRmueB3G4XQ6daKw/MaBWEasgIBzirlAwOgIVqjWyRK7yuzld2AwYgUAwLkRrFAtV31VmMWsiHDu6gECxT0RGEQDVq7pS4PdeA6clevva12m36mxQrVOnKqvio2yUuMBwCNms1lWq1VHjx5Vs2bN6v2/IU6nUw6HQ3a7vd73hS/VpZ+dTqeOHj0qq9Vap90eCFaoFncEAgYRpD+H27Vrp0OHDunYsWOBbkrAOZ1OlZaWymrlF1Vfqms/W61WtWvXrk5tIFihWq47AqMJVoAhBNukWnh4uC6++GI5HI56PyXo2pOxqj3o4D116WeTyeSVfUkJVqhWvu3UHYEUrgOog/q+ifaZfLVPLCoKZD/ztx3VYp9AwBhMchWCB7ghAM6JYIVqna6xsp7jSAAAIBGscBan7wpkxAoAgJogWKFa3BUIGIMpGBeyAuopghWqxT6BAAB4hmCFauWf2ieQESsgwFj2CAgaBCtUixorwFi4KxAwPoIVqmS3O1RYxIgVAACeIFihSgWnQpXEcgtAoLlmAhmxAoyPYIUqnTh1R2BkRJgsFv6aAABQE/zERJUKbEwDAkbBpr1A8CBYoUostQAYEXOBgNERrFAl11RgLCNWAADUGMEKVWIDZgAAPEewQpVOTwVyRyBgFNwVCBgfwQpVYioQAADPEaxQJYrXAeNw3RTIgBVgfAQrVIl9AgEA8BzBClVixAowDhO7MANBg2CFKlFjBRiPk+p1wPAIVqjE6XQyYgUAQC0QrFBJcYldpWUOSWzADBgBO9oAwYNghUryT+0TaDGb1LBBWIBbAwBA8CBYoZIzpwHZ/BUAgJojWKGS/EK2swGMiNp1wPgIVqjkxKkRq1gK1wEA8AjBCpWc3oCZwnXACJiSB4IHwQqVMBUIGJOTTW0AwyNYoRKmAgEAqB2CFSphxAowFmYCgeBBsEIlrnWsWHUdMBhmAgHDI1ihEkasAACoHYIVKqHGCjAmBqwA4yNYoZKCU8EqmuUWAADwCMEKFdgdThUUlddYxTIVCBgC61gBwYNghQoKi0rd22ZEE6wAQ2FLG8D4CFaowLXqesMGYbKG8dcDAABP8JMTFbjvCKRwHTAMJgKB4EGwQgXuOwIpXAeMh7lAwPAIVqiANawAAKg9ghUqcNVYMRUIGMipuUDGqwDjI1ihghOFrqlAghUAAJ4iWKEC9gkEjIfidSB4EKxQATVWgHFRuw4YH8EKFbhrrLgrEAAAjxGsUAHF64DxuLa0cVK+DhgewQoVMBUIAEDtEaxQwYlTxeuxjFgBAOAxghXcikvtKim1S2LECjAS912BzAQChme4YPXdd99p3Lhx6tGjh3r16qU//OEPKigoqPLY7Oxs3XTTTerSpYuGDBmiDz/8sE7Xfv311zVo0CB16dJFt99+uw4fPux+bs2aNUpNTVVKSop69+6tBx98sNp2BSvXNKDFbFJkRFiAWwMAQPAxXLB65JFH1KhRI7333nt6/fXXlZubqyeffLLScaWlpZowYYIGDhyo7du3a9KkSZo0aZKOHj1aq+t+9dVX+uMf/6hp06bp448/VmJiou69917383369NHLL7+snTt36s0331RpaameeOKJWr9PIzp9R2C4u1gWgAHwcQSChuGC1Xfffae0tDRFRESoUaNGGjx4sLKzsysdl5WVpZMnT2rcuHEKDw/XkCFDFB8fr9dff919zPr165WWlqZu3bpp5MiROnDgQLXX3bBhg/r27avLL79cERERuvvuu7Vv3z73a84//3w1btzYfbzJZNKhQ4e8+M4Dz7XqekwUSy0ARsRMIGB8hpvvuf3227Vx40Z169ZNxcXFev3119W/f/9Kxx04cEAJCQkym09nw44dO7pD2Ntvv60nn3xSixYt0sUXX6yXX35ZEyZM0Guvvabw8Mr1Q9nZ2ercubP76+joaLVr104HDhxQfHy8JOk///mP7r//fhUUFKhhw4Z66qmnav0+7Xa77HZ7rV9f1fnO/LM28gpOSpKiG4Z7tW2hxBv9jJqhr09znloZ1OlweL0/6Gf/oJ/9w5f9XNNzGi5Y9ejRQ//85z/VrVs3ORwOXX755UpPT690XGFhoWJjYys8Fhsb666LWr16tcaMGaPExERJ0i233KJnnnlGn332mbp3717pfDabrdL5YmJiVFhY6P66f//+2rlzp44cOaKXXnpJ559/fq3fZ1WjcN6we/fuWr92z4HymjFHmU27du3yVpNCUl36GZ6hr6Wff/qfJCn3hx+0a9dJn1yDfvYP+tk/AtnPhgpWdrtdY8aM0Q033KDVq1ertLRUs2bN0u9///tKdVZRUVHKz8+v8Fh+fr6ioqIkSYcPH9acOXM0d+5c9/OlpaX64YcftGHDBk2dOlWS1Lp1a7366quKjIysdL6CggL3+c7UunVr9e3bV/fdd5/+9a9/1eq9JiQkKDIyslavrYrdbtfu3bvVuXNnWSyWWp3jwNEDkv6ntq2aKympi9faFkq80c+oGfr6tB05X0jZBWrZsqWSkjp49dz0s3/Qz/7hy3622Ww1GhQxVLDKy8tTbm6uRo0apQYNGqhBgwYaMWKEbr/99krHxsfHa9myZXI4HO7pwL179yotLU2S1KpVK40ZM0bDhw+v8lpDhw6t8HVCQoL27t3r/rqwsFCHDh1yTwP+UllZWZ1qrCwWi08+XHU5b0FRmSSpUVQDPvjn4KvvHyqjr+X+N85kMvmsL+hn/6Cf/cMX/VzT8xmqeL1p06Y6//zz9eKLL6qkpEQ2m03/+Mc/3NN5Z+rRo4caNGigZ555RiUlJXrttdeUnZ2tq666SpI0YsQILV26VPv27ZPT6VRhYaHefvvtapdIGDp0qLZu3apt27apuLhYCxYsUGJiojtYvfLKK/rxxx8lSd9++63mz5+v3r17+6gnAsN1V2A0+wQCAFArhhqxkqSFCxdq9uzZev7552UymdSlSxc9/vjjkqRrrrlG48eP19ChQ2W1WrVo0SJNmTJFCxcuVJs2bbRw4UI1a9ZMkjRo0CCdPHlSkydP1nfffaeGDRsqJSVFPXr0qPK67du316OPPqqHH35YP//8s7p06aL58+e7n//88881f/58FRQUqHHjxrriiit0//33+75D/MgVrFh1HQCA2jFcsOrQoYNWrlxZ5XOvvvpqha8TExP18ssvV3uutLQ099RgTVx99dW6+uqrq3xuxowZmjFjRo3PFYzYJxAwKNaxAoKGoaYCEVjuBUIZsQIMyclCVoDhEazgdqLw1AbMjFgBAFArBCtIkhwOpwqLGLECjMh0ai7QyZAVYHgEK0iSCk+WynHq32xqrAAAqB2CFSSdLlxv2MAiaxh/LQAjYU90IHjwExSSpBM27ggEAKCuCFaQdMZSC9RXAQBQawQrSDpjqQVGrAAAqDWCFSSdXmqBYAUYFzcFAsZHsIIkqcA9YsU+gQAA1BbBCpLOKF6nxgowHNOp2wIZsAKMj2AFSaeL11l1HQCA2iNYQRL7BAJGxjJWQPAgWEGSlE/xOmB4bGkDGB/BCpJO11jFMmIFAECtEawgiXWsACNjSxsgeBCsoJJSu4pL7JKosQIAoC4IVnCPVpnNJkVFhAW4NQAABC+CFXSi8PTioCbmHADDonYdMD6CFaivAgDASwhWUL6NpRYAI2MkGQgeBCu4V10nWAHG5mRTG8DwCFY4Y9V1NmAGAKAuCFY4o3idESvAiJgJBIIHwQruEStWXQcMjplAwPAIVmCfQAAAvIRghTNqrAhWgJExYAUYH8EK7hqrWEasAACoE4IVGLECDI51rIDgQbCq5xwOpwpsp7e0AWBcTva0AQyPYFXP2U6WynHq32qK1wEAqBuCVT134tRoVYNwi8KtlgC3BkBV3BOBDFgBhkewqucK2CcQAACvIVjVc9wRCACA9xCs6jn2CQSCwKm5QGYCAeMjWNVz+ewTCACA1xCs6rkTrGEFGJ5JrGMFBAuCVT2XT40VEDRYxwowPoJVPZfvuiuQESsAAOqMYFXPUWMFGJ+J4nUgaBCs6jlXjVUsI1YAANQZwaqey2efQMDwKF0HggfBqp5zTwUyYgUYH3OBgOERrOqx0jK7TpbYJVFjBQCANxCs6jHXHYFmkxQVwVQgYFgmJgOBYEGwqsdc04BRDcNlNvMPN2B0zAQCxkewqsdO3xHIaBUAAN5AsKrHWMMKCA7udaxYeR0wPIJVPZbPPoEAAHgVwaoeO8GIFRAUqIAEgketg9UPP/ygXbt2ebMt8DPXXYGsug4AgHd4HKyOHTumO+64Q/369dPo0aMlSZs3b9bMmQnI2KAAACAASURBVDO93Tb4GDVWAAB4l8fBatasWWrevLneffddWa3ld5P17NlT77//vtcbB9+ixgoIEswFAkEjzNMXfPTRR3rrrbfUsGFDmU7dqtKsWTMdPXrU642Db7lqrGIZsQKCAjcFAsbn8YiVxWKR2VzxZQUFBYqJifFao+AfBUWuESvWsQIAwBs8Dlbdu3fXU089VeGx5cuXq2fPnl5rFPwjv7C8eJ0aK8DYTKfmAlnHCjA+j6cC//CHP2j06NHatGmTCgsLdeWVV6qsrExr1qzxRfvgI06n83SNFcEKAACv8DhYtWzZUuvXr9e7776rgwcPqnnz5kpNTVVUVJQv2gcfsZ0sk91R/tsvxeuAsbEHMxA8PJ4K3LRpk8LDw5WamqqxY8dq2LBhioqK0quvvuq1Rr3xxhtKS0tTUlKSBgwYoDfffLPK47KyspSWlqYuXbrohhtu0L59++p03VWrVqlv375KTk5WRkaG8vLy3M8tWLBAAwYMUNeuXdW3b1/Nnj1bpaWldbpeILlGq8KtFjWwWgLcGgAAQoPHweqRRx6p8vHp06fXuTGS9OGHH+rRRx/V9OnT9cknn+iVV15Rx44dKx13/PhxTZw4UWPGjNH27duVlpamO++8UyUlJbW67gcffKAFCxZo8eLF2rp1q8xms6ZOnep+/tprr9XGjRv1ySefaP369dqzZ49WrFhR27cZcKfvCKRwHQAAb/E4WFVVPPm///3PvfRCXT311FO66667lJKSIrPZrGbNmun888+vdNyWLVvUrl07DRs2TOHh4Ro9erQcDoe2bdvmbudzzz2nwYMHq0ePHho7dqxyc3Orve7atWs1fPhwderUSdHR0crMzNSWLVuUn58vSYqLi1N0dLT7eLPZrEOHDnnlPQcCa1gBAOB9Na6x6tevn0wmk4qLi9W/f/8Kzx0/fly/+c1v6twYu92u3bt3a8CAARo8eLAKCwvVt29fPfTQQ5WWc8jOzq4wkmUymZSYmKjs7Gz1799fq1at0saNG7V8+XK1bNlSCxcuVGZmplavXl3ltQ8cOKArrrjC/XVcXJysVqu+/vprdenSRZL04osvas6cObLZbGrcuLEmT55cp/dqt9tr/fqqznfmn+eSl39SkhQdafVqO0Kdp/2M2qOvT3P9QutwOL3eH/Szf9DP/uHLfq7pOWscrO699145nU5NmzZN99xzj/txk8mk5s2b67LLLvO8lb/w888/q7S0VJs3b9bKlSsVGRmp+++/X48++qhmz55d4VibzaZGjRpVeCwmJkaFhYWSpNWrV2vy5Mlq27atJCkjI0NJSUk6cuSIWrduXenaNptNsbGx1Z5PkkaOHKmRI0fqq6++0rp169S8efNav9fs7Oxav/Zsdu/eXaPj9h4oH4mzl9jY87EWatrPqDv6Wjpy5IQk6eixoz77vNLP/kE/+0cg+7nGwer666+XJLVr107dunXzSWMaNmwoSbr11lt13nnnSZImTJigu+66q9KxkZGR7mk6l4KCAvfdiYcPH1ZmZmaFxUzNZrNyc3O1YcMGLVmyRJKUkpKiZ5555pznO1P79u3Vvn17TZ8+XQsXLqzVe01ISFBkZGStXlsV12hf586dZbGcuxh974/7JeWpXesWSkrq7LV2hDpP+xm1R1+f9vXxL6XPTqhp06ZKSkry6rnpZ/+gn/3Dl/1ss9lqNCji8XILrlBls9kqbWNTVS2UJ2JjY9WqVasa1WslJCTopZdecn/tdDq1f/9+jRgxQpLUqlUrTZ8+vcqFS7t27aoJEyZUeCw+Pl579+7V0KFDJUk5OTkqKSnRRRddVOX17XZ7nWqsLBaLTz5cNT1vQVGZJCk2ugEf8lrw1fcPldHXkunUL4gmk8lnfUE/+wf97B++6Oeans/j4vXvvvtOt9xyi1JSUnTllVdW+M8bbrzxRr3wwgv66aefVFBQoGXLlmngwIGVjktNTVVOTo7Wr1+vkpISrVy5UpLUu3dvSdKIESM0b948d/jJy8vT5s2bq73u8OHDtXbtWu3Zs0eFhYWaP3++UlNT3bVdL774oo4fPy6n06l9+/Zp6dKl7msFo/xCFgcFggXLWAHBw+NgNWvWLDVp0kT//Oc/FRkZqbVr1+qKK66oVANVWxMmTFBKSoquueYapaamqkmTJnrooYckScnJydqxY4ckqUmTJnr66ae1bNkydevWTRs3btSiRYsUHl4eFNLT03XNNddo/Pjx6tq1q6677jq9//771V63T58+ysjI0Lhx43T55ZertLS0whIS7733nq6++mp17dpVd911l1JTU3Xfffd55T0HwulV11luAQgW7GgDGJ/HU4G7du3Sa6+9psaNG8tkMqljx46aMWOGxo8fr2HDhtW9QWFhmjJliqZMmVLpuU8//bTC1z179tSmTZuqPI/ZbFZ6errS09NrfO1Ro0Zp1KhRVT63ePHiGp8nGLDcAgAA3ufxiJXdblfjxo0lSRERESoqKlLLli2Dek2n+uiErXzV+FimAgHDY0sbIHh4PGLVtm1b7d+/X4mJibr44ou1Zs0axcTEuMMWgoO7xooRKwAAvMbjYDVu3Dj99NNPSkxM1MSJEzVhwgSVlJToz3/+sy/aBx8oLXOoqLj8rkCK1wEA8B6PgpXT6VT37t3VpEkTSVKPHj308ccfq7S01KtrMsG3Ck7VV5lMUlRDitcB4yufC6xqSzEAxuJRjZXT6dSAAQMqLOtutVoJVUHmxKlgFd3QKouZ4g0AALzFo2BlNpvVqlUr2Ww2X7UHfsAaVkBwoXgdCB4e3xV4zz33aMqUKcrJyVFZWZkcDof7PwQHlloAghMTgYDxeVy87loU86233qr03N69e+veIvjcicLypRYYsQIAwLs8DlbPP/+8L9oBP3KNWMUyYgUEBfdUIENWgOF5HKx69Ojhi3bAjwps1FgBAOALHtdYIfidKGSfQAAAfIFgVQ9RvA4EG9c6VgFuBoBzIljVQ/k2itcBAPAFglU95JoKZANmIDiwjhUQPAhW9RBTgUBwcnJbIGB4Ht8V2KFDB5mq+PUpPDxcrVu31tChQzVmzBhZrRRGG5HT6WTldQAAfMTjYPXggw9q9erVuu2229SmTRsdPnxYf//733XjjTcqLCxMzz33nE6ePKnMzExftBd1VFRcJruj/LfemCjCLxAM3L/KMmAFGJ7HwWrTpk1avHixLrzwQvdjvXv31u9//3u98sorSklJ0b333kuwMihXfVV4mFkR4R5/+wEAwFl4XGP1zTff6Pzzz6/wWNu2bfX1119Lkjp37qxjx455p3XwOuqrgCBE8ToQNDwOVhdeeKGWLVtW4bFnn33WPYKVm5ur6Oho77QOXpfPPoFA0GImEDA+j+eCHnnkEY0dO1YvvPCCWrVqpe+//16lpaXusPXNN99owoQJXm8ovOME+wQCAOAzHgerX//613rrrbf09ttv68cff1TLli01YMAAxcTESJJ69eqlXr16eb2h8A7XPoHRbGcDBA0Tc4FA0KhV9XJMTIyuu+46b7cFfsBSC0DwcrKnDWB4Hgcrh8Oh9evX6/PPP1dhYWGF5x5//HGvNQy+wVQgAAC+43GwmjZtmt544w1ddtllioyM9EWb4EMUrwPBx7UmM+NVgPF5HKzeeOMNvfTSS4qLi/NBc+Br7uUWCFYAAHidx8stWK1WtW3b1hdtgR8wFQgEH0rXgeDhcbC65ZZbtGrVKl+0BX5A8ToQxJgLBAzP46nAbdu26fPPP9cLL7ygFi1aVHjuhRde8FrD4BunV15nuQUAALzN42DVu3dv9e7d2xdtgY+V2R2ynSyTxIgVEFRMTAYCwcLjYDVp0iRftAN+4BqtMpmkaIIVEHSczAUChlejYOV0OmU69RuTw+Go9jiz2eOSLfiRq74qKsIqi5nfgAEA8LYaBauUlBR98sknkqRLLrnEHbJ+ae/evd5rGbwu33ZqDSvuCASCinsdKwasAMOrUbBaunSp+/+ff/55nzUGvnV6DSsK1wEA8IUaBatu3bq5/79Hjx4+awx8i6UWgODExD0QPGq1CfO3336rL774otJegTfeeKNXGgXfOL3UAsEKAABf8DhYrV69WjNnzlSjRo3UsGFD9+Mmk4lgZXAnTo1YxTJiBQCAT3gcrJYuXar58+fryiuv9EV74EMUrwNBinWsgKDh8foI+fn5hKogxQbMQHBzclsgYHgeB6t+/fopKyvLF22BjzEVCACAb3k8Fdi0aVPddddduvLKKyvtFXjPPfd4rWHwPvYJBIKTayKQASvA+DwOVvv27VOHDh106NAhHTp0yP14dYuGwjhYbgEAAN/yKFjZ7Xb9/ve/V4cOHRQezg/nYOJ0OlluAQhS/N4KBA+PaqwsFotuu+02Wa1MJQWbouIyldnL5xGosQIAwDc8Ll6/4IIL9OOPP/qiLfChglNLLVjDzGoQbglwawAACE0e11ilp6crMzNTkyZNUps2bWQ2n85m559/vlcbB+85ccY+gdTDAcGGzywQLDwOVlOmTJEk3XHHHe4f0E6nUyaTSXv37vVu6+A1FK4DwY+7AgHj8zhY/fvf//ZFO+BjFK4DAOB7HgerNm3a+KId8DFGrIDg5Zq9d4ohK8DoPA5WknTs2DF9/vnnOnr0aIUtFtiE2bhOnCpej2XECgAAn/E4WH300UeaNGmSTCaTCgsLFRUVJZvNpvPOO49gZWDsEwgEL0rXgeDh8XILc+fO1ejRo7V9+3ZFRUVp+/bt+r//+z/dcccdvmgfvISpQCD4UbwOGJ/Hweqbb77R+PHjJZ3eaX3ixIlavny5d1sGr3IttxDLPoEAAPiMx8EqLCzMHahiYmJ07NgxWa1WHT9+3OuNg/cwYgUEL5aeA4KHxzVWiYmJ2rlzp3r16qXk5GTNnDlTkZGRuvDCC33RPngJyy0AAOB7Ho9Y/elPf9KvfvUrSdLvf/97nThxQl9++aWmTZvm7bbBi/JP3RXIiBUAAL7j8YhVfHy8+/9btWpFbVUQsNsdKiwiWAHB6/QuFwCMrVbrWH377bd69dVX9cMPP2jq1KnKyclRWVmZ2rdv7+32wQsKToUqqXyvQAAA4BseTwV++OGHGjp0qLKysrRu3TpJ0k8//aTHHnvMqw07duyYevbsqZtuuqnaY7KyspSWlqYuXbrohhtu0L59++p0zVWrVqlv375KTk5WRkaG8vLy3M8tWLBAAwYMUNeuXdW3b1/Nnj1bpaWlZzmbcZw4VbgeFREmi8XjbzmAAKN4HQgeHv+UfeKJJzRnzhw9++yzCgsrH/C69NJLtWfPHq82bM6cObr44ourff748eOaOHGixowZo+3btystLU133nmnSkpKanW9Dz74QAsWLNDixYu1detWmc1mTZ061f38tddeq40bN+qTTz7R+vXrtWfPHq1YsaJW1/I3CteB0MBEIGB8HgernJwcDRo0SJJkOvVrVEREhIqLi73WqKysLB08eFDDhw+v9pgtW7aoXbt2GjZsmMLDwzV69Gg5HA5t27ZNUnktwnPPPafBgwerR48eGjt2rHJzc6s939q1azV8+HB16tRJ0dHRyszM1JYtW5Sfny9JiouLU3R0tPt4s9msQ4cOeekd+xZLLQAA4B8e11i1aNFCOTk5uuCCC9yPffXVVzrvvPO80qCSkhLNnDlTc+bMOesoWHZ2tjp27Oj+2mQyKTExUdnZ2erfv79WrVqljRs3avny5WrZsqUWLlyozMxMrV69usrzHThwQFdccYX767i4OFmtVn399dfq0qWLJOnFF1/UnDlzZLPZ1LhxY02ePLnW79Nut8tut9f69VWd78w/z5RXUB56YyKtXr1mfXS2foZ30denuYrWnQ6n1/uDfvYP+tk/fNnPNT2nx8Hqxhtv1L333qsHHnhADodDO3bs0BNPPHHWWihPLF26VL169VKHDh3OGqxsNpsaNWpU4bGYmBgVFhZKklavXq3Jkyerbdu2kqSMjAwlJSXpyJEjat26dZXni42NrfZ8kjRy5EiNHDlSX331ldatW6fmzZvX+n1mZ2fX+rVns3v37kqP7fuyfNSttLhQu3bt8sl165uq+hm+QV9LOTnl/w6dyD/hs88w/ewf9LN/BLKfPQ5Wo0ePVmFhoe655x4VFBRozJgxuuWWWzRq1Kg6NyYnJ0f/+te/tH79+nMeGxkZ6Z6mcykoKFBUVJQk6fDhw8rMzJTZfHq202w2Kzc3Vxs2bNCSJUskSSkpKXrmmWfOeb4ztW/fXu3bt9f06dO1cOFCj9+nJCUkJCgyMrJWr62K3W7X7t271blzZ1kslgrP7f5+r6Q8XdCmhZKSLvXaNeujs/UzvIu+Pu24/Tvpo+OKjYlVUlKSV89NP/sH/ewfvuxnm81Wo0ERj4OV2WxWRkaGMjIydPToUcXExMhqteqjjz5Sr169atVYl507d+rnn3/W4MGDJUknT55UcXGx+vTpozfeeKNCjVNCQoJeeukl99dOp1P79+/XiBEjJJWvsTV9+nT17Nmz0nW6du2qCRMmVHgsPj5ee/fu1dChQyWVh7ySkhJddNFFVbbVbrfXqcbKYrH45MNV1XkLisokSbHREXygvcRX3z9URl+rwi+IvuoL+tk/6Gf/8EU/1/R8dbr3vlmzZgoPD1dpaanuuOOOupxKkjRkyBC99dZbWrdundatW6e7775bCQkJWrduXaWRo9TUVOXk5Gj9+vUqKSnRypUrJUm9e/eWJI0YMULz5s1zh5+8vDxt3ry52msPHz5ca9eu1Z49e1RYWKj58+crNTVVMTExksrrq44fPy6n06l9+/Zp6dKl7msZnWu5hVjWsAIAwKdqtUBoVbyxInBERIQiIiLcX8fExCgsLMxdy5ScnKxly5apW7duatKkiZ5++mnNnDlTDz/8sOLj47Vo0SKFh5ff+Zaeni6z2azx48frhx9+UGxsrHr37q0hQ4ZUee0+ffooIyND48aNU2Fhofr06aNZs2a5n3/vvff01FNPqbi4WE2bNtXVV1+tu+++u87v2R9YbgEIbqxjBQQPrwUrkw8++cOHD6+w5MKnn35a4fmePXtq06ZNVb7WbDYrPT1d6enpNb7eqFGjqq0VW7x4cY3PYzQF7BMIhATWsQKMj2W464ETrGMFAIBf1HjE6sknn6z2OYfD4ZXGwPucTidTgUCQc88HMGQFGF6Ng9WOHTvO+ny3bt3q3Bh4X3GJXaVl5cGXDZgBAPCtGgerv//9775sB3zkxKnRqjCLSQ0beK2kDoA/Ub0OBA1qrELcmfsE+uIGAwD+42QuEDA8glWIo74KAAD/IViFuPxClloAgh1jzUDwIFiFOFeNVSwjVkDQ88I6zAB8jGAV4txTgYxYAQDgcwSrEHe6eJ2lFoBgxX0nQPAgWIW4fKYCAQDwG4JViMs/tU9gNFOBQNAyUb4OBA2CVYjLZ59AIGRQvA4YH8EqxHFXIAAA/kOwCnEUrwMhgJlAIGgQrEKY3eFU4clTC4QyYgUEPba0AYyPYBXCCmwl7poMaqwAAPA9glUIcy21EBkRpjAL32ogWLnWsaJ4HTA+ftqGMPYJBADAvwhWIcy9nQ31VUBQYx0rIHgQrELYiVN3BMYyYgUAgF8QrEJYQRGLgwIA4E8EqxDmGrGKiWINKyCoMRMIBA2CVQhz7RPIiBUQGpzcFggYHsEqhLFPIAAA/kWwCmHcFQiEBtdMIANWgPERrEIYdwUCAOBfBKsQdnrEiuJ1IJiZKF4HggbBKoRRYwUAgH8RrELUyZIylZQ5JEmx1FgBAOAXBKsQ5don0GI2qWGDsAC3BkDdMBcIBAuCVYg6845AEwUaQEhgHSvA+AhWIYr6KgAA/I9gFaLyT+0TSH0VEPxcg86MVwHGR7AKUa4Rq+iGLLUAAIC/EKxC1AkbI1ZAqKBKEggeBKsQ5borkBorIIQwFwgYHsEqRLFPIAAA/kewClEnuCsQCBmuJVOcDFkBhkewClH57horitcBAPAXglWIYh0rIIRQvQ4EDYJViKLGCgg9LLwOGB/BKgTZHU4VFJXfFRjLiBUAAH5DsApBhUWl7t9sowlWQNBjJhAIHgSrEFRwahqwYYMwWcP4FgOhgplAwPj4qRuCTlBfBQBAQBCsQtDpOwJZagEIBSb3LsyMWQFGR7AKQe47AqmvAgDArwhWIehEIXcEAgAQCASrEMQaVkBoYiIQMD6CVQhi1XUAAAKDYBWCTt8VSPE6EApMLGQFBA2CVQhyjVhRYwWEFm4KBIyPYBWCqLECACAwCFYhiBorILSYXJvaMGIFGB7BKgSdsJ1aboERKwAA/IpgFWKKS+0qKbVLYsQKCBkUrwNBg2AVYlwbMJvNJkVGhAW4NQC8yclcIGB4hgpWJSUl+tOf/qSBAwcqOTlZ11xzjTZu3Fjt8VlZWUpLS1OXLl10ww03aN++fXW6/qpVq9S3b18lJycrIyNDeXl57ucWLFigAQMGqGvXrurbt69mz56t0tLSOl3PF/JPTQPGRFpP7y8GAAD8wlDBqqysTC1atNDKlSv1ySefaPr06Zo2bZo+/fTTSsceP35cEydO1JgxY7R9+3alpaXpzjvvVElJSa2u/cEHH2jBggVavHixtm7dKrPZrKlTp7qfv/baa7Vx40Z98sknWr9+vfbs2aMVK1bU9q36DIXrQOjhVyQgeBgqWEVGRuqee+7R+eefL5PJpG7duqlr165VBqstW7aoXbt2GjZsmMLDwzV69Gg5HA5t27ZNkuR0OvXcc89p8ODB6tGjh8aOHavc3Nxqr7127VoNHz5cnTp1UnR0tDIzM7Vlyxbl5+dLkuLi4hQdHe0+3mw269ChQ17ugbpjA2YgdLGOFWB8hi7Csdls+uKLL3TbbbdVei47O1sdO3Z0f20ymZSYmKjs7Gz1799fq1at0saNG7V8+XK1bNlSCxcuVGZmplavXl3ltQ4cOKArrrjC/XVcXJysVqu+/vprdenSRZL04osvas6cObLZbGrcuLEmT55c6/dmt9tlt9tr/fqqzidJeQXFksqnAr15fpRz9Sl963v09WkOh+PU/zm93h/0s3/Qz/7hy36u6TkNG6wcDocefPBBde7cWZdffnml5202mxo1alThsZiYGBUWFkqSVq9ercmTJ6tt27aSpIyMDCUlJenIkSNq3bp1leeLjY2t9nySNHLkSI0cOVJfffWV1q1bp+bNm9f6/WVnZ9f6tWdz4JtvJUklJ/O1a9cun1wD0u7duwPdhHqDvpa+yj0pSbIVnfTZ55p+9g/62T8C2c+GDFZOp1NTp07Vjz/+qOXLl1dZhB0ZGemepnMpKChQVFSUJOnw4cPKzMyU2Xx6ttNsNis3N1cbNmzQkiVLJEkpKSl65plnznm+M7Vv317t27fX9OnTtXDhwlq9x4SEBEVGRtbqtVWx2+3avXu3omKaSjqhuLbnKSnpEq+dH+Vc/dy5c2dZLJZANyek0denmQ78JL39sxpGRCgpKcmr56af/YN+9g9f9rPNZqvRoIjhgpXT6dT06dO1d+9erVixospgI5UHk5deeqnC6/bv368RI0ZIklq1aqXp06erZ8+elV7btWtXTZgwocJj8fHx2rt3r4YOHSpJysnJUUlJiS666KIqr2+32+tUY2WxWHzy4SooKpMkxUY34MPrQ776/qEy+lqymMvfv8lk8llf0M/+QT/7hy/6uabnM1TxuiTNmDFDn332mZYvX16hWPyXUlNTlZOTo/Xr16ukpEQrV66UJPXu3VuSNGLECM2bN88dfvLy8rR58+Zqzzd8+HCtXbtWe/bsUWFhoebPn6/U1FTFxMRIKq+vOn78uJxOp/bt26elS5e6r2UkruJ1Vl0HQo+T6nXA8Aw1YnX48GG9+OKLCg8PV//+/d2Pjx8/XhMmTFBycrKWLVumbt26qUmTJnr66ac1c+ZMPfzww4qPj9eiRYsUHl4eKNLT02U2mzV+/Hj98MMPio2NVe/evTVkyJAqr92nTx9lZGRo3LhxKiwsVJ8+fTRr1iz38++9956eeuopFRcXq2nTprr66qt19913+7Q/auP0OlYEKwAA/M1QwapNmzbav39/tc//ctmFnj17atOmTVUeazablZ6ervT09Bpff9SoURo1alSVzy1evLjG5wkk18rrMYxYAaGDhayAoGG4qUDUjWvEKpYRKyDkMBEIGB/BKoQ4nE73iFV0pDXArQEAoP4hWIWQ4lKnHKd+paV4HQgdrhVnqF0HjI9gFUJsxeWrM0eEW2QN43ZeAAD8jWAVQoqKy5fbp3AdCC0mqteBoEGwCiGuESuWWgBCFXOBgNERrEJIUUl5sOKOQAAAAoNgFULcI1ZMBQKhhZlAIGgQrEJIkXsqkKUWgFDEXYGA8RGsQoithBErAAACiWAVQlwjVtRYAaHFNRPIiBVgfASrEFLEiBUAAAFFsAohLLcAhCaTiep1IFgQrEIIxetAqGMuEDA6glUIoXgdAIDAIliFiNIyu0rLyn+bpXgdCE0UrwPGR7AKEfmFpZIks0mKjGAqEACAQCBYhYgTthJJUnRkuMxmCl2BUELtOhA8CFYhIv9UsKJwHQhdzAQCxkewChH5tvKpQJZaAAAgcAhWISK/0DViRbACQo2JXZiBoEGwChHuEasopgKBkMVcIGB4BKsQUWBjxAoAgEAjWIUIaqyA0OW6K9DJkBVgeASrEMFdgQAABB7BKkQQrIAQRu06EDTCAt0AeAdTgUDoK7CV6uV/Z3v1nE6nU0eOnNBXx7+UySArkV7ctrGSE1sEuhlArRCsQkRpWfkGzE1jIwLcEgDe1sBqkSQVFJXq+c17fXORz0745ry1EGYx6YUZV7M9F4ISwSpEjL2uk3Z8nq02LaID3RQAXhbXKla3X3OJjvxU4PVzO5xOHTt6VE2bNZPZACNWb20/pDK7U0XFZQQrBCWCVYjo1rGlwoq/zx45AQAAEr1JREFUD3QzAPiAyWTSjQPjfXJuu92uXbt2KSmpiywWi0+u4Yl3Pz2sklK77HbugERwongdAGAYllObyNsdBCsEJ4IVAMAwzO5g5QhwS4DaIVgBAAzDNWLlYMQKQYpgBQAwDKYCEewIVgAAwyBYIdgRrAAAhmG2lP9YYioQwYpgBQAwDMuptbRYbgHBimAFADAM112BDifBCsGJYAUAMAyLheUWENwIVgAAw3AXrzMViCBFsAIAGIaZuwIR5AhWAADDYIFQBDuCFQDAMCzm8h9LjFghWBGsAACGYWbECkGOYAUAMAwLmzAjyBGsAACGQfE6gh3BCgBgGBSvI9gRrAAAhkHxOoIdwQoAYBinV14nWCE4EawAAIbhvivQTvE6ghPBCgBgGBYTI1YIbgQrAIBhmE9NBTqcBCsEJ4IVAMAw2IQZwY5gBQAwDO4KRLAjWAEADMPCAqEIcgQrAIBhmNnSBkGOYAUAMAxWXkewCwt0AwAAcHGNWK179yu9/uHBgLbF28rK7Apb90OgmxHy2jS1qEuXwAXzgAWrEydO6OGHH9Z7772nqKgojRkzRqNHj67y2KysLM2YMUPffvutLr74Ys2aNUsdOnTwa3uys7M1ZcoU7d+/X23atNHDDz+sXr16ebUNAFDfXdSmkSSptMyh0rIQnA4sCcH3ZDDfyxHQEc+ABasZM2aopKREW7du1eHDhzV69GhdeOGF6tevX4Xjjh8/rokTJ2rKlCkaMmSIXnjhBd1555164403FB4e7tE1FyxYIEnKyMjwqD2lpaWaMGGCbrrpJq1atUpvvfWWJk2apDfffFPNmjWrfScAACoYkHK+Lr3oVzpZUhbopniV3W7Xvn371KFDB1kslkA3J2TZ7XZ9/+0BWSyBq3QKSLCy2Wx6/fXXtXbtWkVHRysxMVE33XST/vnPf1YKVlu2bFG7du00bNgwSdLo0aO1YsUKbdu2Tf3795fT6dSKFSu0Zs0aHT9+XF26dNHMmTN13nnnea09WVlZOnnypMaNGyez2awhQ4bo+eef1+uvv65bb73Vq30DAPVd8yYNA90Er7Pb7Tr6vVXnt4whWPlQeT8Htnw8IMHq4MGDcjqdSkhIcD/WoUMHvfnmm5WOzc7OVseOHd1fm0wmJSYmKjs7W/3799eqVau0ceNGLV++XC1bttTChQuVmZmp1atXe609Bw4cUEJCgszm09+sjh07Kjs726P3fSa73S673V7r11d1vjP/hG/Qz/5DX/sH/ewf9LN/+LKfa3rOgI1YRUdHV3gsNjZWhYWFVR7bqFGjCo/FxMS4j129erUmT56stm3bSiqf5ktKStKRI0fUunVrr7SnsLBQsbGxlZ4/fPhwjc5flbqEsrPZvXu3T86Liuhn/6Gv/YN+9g/62T8C2c8BCVaRkZGVQlR+fr6ioqKqPDY/P7/CYwUFBe5jDx8+rMzMzAqjSWazWbm5uWrdurWuvfZaff/995Kk4uJiSdLKlSslSSkpKVqyZMk52xMVFVWpDdW1t6YSEhIUGRlZ69f/kt1u1+7du9W5c2eGmX2IfvYf+to/6Gf/oJ/9w5f9bLPZajQoEpBgFRcXJ6l8ii0+Pl6StHfvXvf/nykhIUEvvfSS+2un06n9+/drxIgRkqRWrVpp+vTp6tmzZ5XX2rhxo/v/qyteP1d74uPjtWzZMjkcDneA27t3r9LS0jx632eyWCw++XD56ryoiH72H/raP+hn/6Cf/cMX/VzT8wWkwisyMlKDBw/WvHnzVFBQoOzsbL3yyiu64YYbKh2bmpqqnJwcrV+/XiUlJe7Rpt69e0uSRowYoXnz5unQoUOSpLy8PG3evNmr7enRo4caNGigZ555RiUlJXrttdeUnZ2tq666qi7dAAAAQkzASuenTp2qsLAw9e3bV3fccYfGjh3rviMwOTlZO3bskCQ1adJETz/9tJYtW6Zu3bpp48aNWrRokXuphfT0dF1zzTUaP368unbtquuuu07vv/++V9tjtVq1aNEibdmyRd26ddNTTz2lhQsXstQCAACowOR0Otk3wI9sNpv27t2rjh07er3GateuXUpKSmKY2YfoZ/+hr/2DfvYP+tk/fNnPNf35zV6BAAAAXkKwAgAA8BKCFQAAgJcQrAAAALyEYAUAAOAlBCsAAAAvCcjK6/WZw+GQJP1/e/cfE3X9xwH8CRIoIAwEFhukbsLhQujiABkgHFqwQ1xho1qizSEwVMh+KbqkkNyMxMQfUEIKoWuGeYvxS1zljyR+TUEHGwUhiSbxYyac3c/P94/mtU9E8xsfIPT52Ny89/vl5173mnJP33B39+7dk/S69z8cUqPR8KW8k4hznjqc9dTgnKcG5zw1JnPO95+37z+Pj4fvYzXFBgcH0dPTM91tEBER0b+wYMGCf3yDcAarKWYwGHDnzh3Y2NiIPjiaiIiI/rtMJhO0Wi0cHR1hZTX+N/wYrIiIiIgkwiMTIiIiIokwWBERERFJhMGKiIiISCIMVkREREQSYbAiIiIikgiDFREREZFEGKyIiIiIJMJgRURERCQRBisiIiIiiTBYzUC//fYbMjIyIJfLERYWhmPHjpn3ZDIZurq6zLfVajWCgoLQ1NQ0DZ3OXDqdDjt27EBUVBTkcjliY2NRUVFh3uecpTc0NITg4GAkJCSY1zhn6dXW1mLlypV46qmnoFQqcebMGQCctZRu3LiB5ORkBAUFISQkBG+//TZGRkYAAFFRUTh//ry59uLFiwgMDERVVdV0tTtjlJWVIT4+Hr6+vtiyZYtor7OzEwkJCfD394dKpUJ9fb15r6GhAaGhoebbJpMJO3fuhEqlwu3btyXvc/wPu6H/rOzsbOh0Oly4cAF9fX149dVXsXDhQkRERIjqjh8/jvz8fBQVFcHPz2+aup2ZDAYD3NzcUFJSAg8PD7S0tCAlJQUeHh6Qy+WiWs5ZGrm5uVi0aBH0ev3f7nPOE1dfX4/du3cjLy8Pcrkcw8PD0Gg0Y+o464nZuXMn5s2bh/Pnz0Or1WLz5s3Yv38/duzYIaqrq6tDZmYmcnNzoVQqp6nbmcPNzQ1paWm4dOkShoeHzet6vR6pqalISEhAWVkZzp49i02bNuHMmTNjPizZYDBg69at6O7uRllZGZydnSXvkydWM4xGo0FNTQ22bNkCe3t7yGQyJCQk4NSpU6K6jz/+GIcPH0ZpaSm/MP4Ltra2yMjIgKenJywsLKBQKPD000/j8uXLojrOWRqNjY3o6elBfHz83+5zztLIz8/Hxo0bERAQAEtLS8ybNw+enp6iGs564m7cuIGVK1di9uzZcHR0RHR0NDo7O0U1arUamZmZOHDgAEPVA3r22WexYsUKODk5idYbGxvx+++/Izk5GdbW1lCpVPDy8kJNTY2oTqfTYfPmzejr60NJScmkhCqAJ1YzTk9PDwRBgLe3t3nNx8fHfJwP/PHFs7W1FWVlZVi4cOF0tPnQ0Wg0uHbtGtauXWte45ylodPpsGvXLuTm5qK9vX3MPucsDaPRiKtXr0KpVCI6Ohqjo6MIDw/H9u3bMXfuXACctVTWrVuHiooKKBQKaLVa1NTUIDIy0rxfXl6OhoYGHDlyZMwJOP3/fvjhB3h7e8PS8s+zosWLF4vCrMFgQHJyMgRBwKeffgpbW9tJ64cnVjOMRqOBvb29aM3BwQGjo6Pm2xcuXMDSpUv5hVEiJpMJ27Ztw5IlSxAWFmZe55yl8cknnyAkJAQ+Pj5/u885S2NgYAB6vR5VVVUoKSlBVVUVBgYGsHv3bnMNZy2NoKAgdHd3Q6FQICQkBNbW1khMTDTvX7x4EYsXL4avr+80dvnwGB0dhYODg2jtr8+Lo6OjaG5uxqpVqyY1VAEMVjOOra2t6C8LANy9exd2dnbm23l5eaivr8euXbumur2HjiAIyMrKQn9/P/bt2wcLCwvzHuc8cdevX8fp06eRnp4+bg3nLI05c+YAAF555RU8/vjjcHBwQGpqKr755htzDWc9cUajEUlJSYiMjMSVK1fQ0tICNzc3vPXWW+aarKwsDA0N4bXXXhv3ZwrpwdnZ2eHu3buitb8+Lzo6OuLAgQPIzs6e9BcKMFjNMAsWLADwx9HnfR0dHfDy8jLf9vT0RGlpKerq6pCTkzPVLT40BEHAe++9h46ODhQVFYn+kQKcsxRaWlowMDCA6OhohIaG4v3330d7eztCQ0PNr6LinKXh4OAAd3d30X8O/oqznrg7d+7gl19+wZo1a2BjYwN7e3u8/PLLolcCOjk54dixY+jt7cXrr78Og8EwjR3PfF5eXujs7ITJZDKvdXR0iH5kBgCUSiXy8vKQmZmJ6urqSeuHwWqGsbW1RXR0NPbt24eRkRF0dnaivLwcq1evFtXNnz8fpaWlqK2tFR3104PLzs5Ga2sriouLx3z79T7OeWJUKhXOnj0LtVoNtVqN9PR0eHt7Q61Wi4Is5yyNF154AcePH8evv/6KkZERHDlyBFFRUaIaznpinJ2d4enpiRMnTkCn00Gj0eDkyZOQyWRj6kpKSvDTTz8xXD0gg8EArVYLg8EAk8kErVYLvV6PoKAg2NjYoKioCDqdDtXV1ejs7ERMTMyYayxfvhx79+7Ftm3bUFtbOyl9MljNQFlZWbCyskJ4eDjWr1+PDRs2jHmrBeCP063S0lJUV1djz54909DpzNXX14cTJ07gxx9/RGRkJORyOeRyOQoLC8fUcs7/3uzZs+Hq6mr+NXfuXFhZWcHV1XXMyQrnPHGpqakICAhAbGwsnnnmGTg5OWH79u1j6jjriTl48CCampoQFhYGpVKJ/v5+fPDBB2Pq7oerrq4uvPnmmzAajdPQ7cxRUFAAPz8/FBYWoqamBn5+fnjnnXfw2GOPoaCgAHV1dVAoFMjPz8fBgwfHvNXCfStWrMDevXuxdetW1NXVSd6nhSAIguRXJSIiInoE8cSKiIiISCIMVkREREQSYbAiIiIikgiDFREREZFEGKyIiIiIJMJgRURERCQRBisiIiIiiTBYEREREUmEwYqIaArJ5XI0NDRMdxtENEkYrIjooZaYmIh9+/YBAKKiovDFF19Myf1++eWXWLZs2Zj1y5cvIzg4eEp6IKKpx2BFRPR/MBqNMJlM090GEf1HMVgR0SMhKSkJN2/eRHZ2NuRyOWJjY817arUaq1atMn9AcWVlpXmvoaEBMpkMlZWViI6Ohr+/PwYHB1FdXY34+HgEBgYiODgYqamp+PnnnwEAzc3NyMrKQn9/v/kDvL/66isAgEwmw6VLl8zX//bbbxEfH4+AgABER0ejuLhYFNxkMhk+++wzvPTSS5DL5YiLi0Nzc/Nkj4uI/i2BiOghtmbNGiEvL08QBEFQKpXCyZMnRfunTp0SIiIihLa2NsFoNApNTU2CXC4XmpqaBEEQhO+//17w9vYW0tLShKGhIUGr1QoGg0E4d+6c0NHRIRgMBmFwcFBISUkREhISRNcNDw8f04+3t7fw3XffCYIgCK2trcKTTz4pVFZWCnq9Xrh69aoQGhoqHD16VFQfFxcn9PT0CHq9XsjJyREiIyOlHhMRSYQnVkT0SDt69ChSU1OxZMkSWFpaQqFQQKVS4fTp06K6N954A05OTrC2tsasWbOwbNky+Pj4YNasWXB2dkZ6ejquXLmCkZGRB77v8vJyREREQKVSwcrKCr6+vkhKSsLnn38uqlu/fj3mz58PKysrJCQk4ObNmxgYGJDk8RORtKymuwEioul0/fp17NmzBx9++KF5zWg0QqFQiOo8PDxEtxsbG3Ho0CF0dXVBo9GY14eGhmBvb/9A933r1i0sWrRItPbEE0/g1q1bojU3Nzfz7+fMmQMAGB0dhYuLywPdDxFNHQYrInpkWFhYjFlzcXFBeno6nnvuuX/8s5aWfx7w63Q6pKSkYOPGjTh06BDs7e3R3t6O559/HoIgjKkfj7u7O3p7e0Vrvb29cHd3f5CHQ0T/QfxWIBE9MlxdXdHd3S1aW7duHQ4fPoy2tjaYTCbodDq0tbXh2rVr415Hr9dDq9XC0dER9vb2uH37Nj766CNRjYuLC4aHhzE8PDzudVavXo1z586htrYWRqMR7e3tKC4uxosvvjixB0pE04bBiogeGWlpafj666+hUCgQFxcH4I9gtWnTJrz77rsICgpCeHg4cnNzce/evXGvY2dnh5ycHBQUFEAul2PDhg2IiYkR1SxduhTLly9HTEwMFAoFKioqxlzH398f+/fvR2FhIQIDA5GRkYHExESsXbtW2gdORFPGQrh/bk1EREREE8ITKyIiIiKJMFgRERERSYTBioiIiEgiDFZEREREEmGwIiIiIpIIgxURERGRRBisiIiIiCTCYEVEREQkEQYrIiIiIokwWBERERFJhMGKiIiISCIMVkREREQS+R+VZRdmCkkFLAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yfiXjuv3aw9g"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# modules - models.py"
      ],
      "metadata": {
        "id": "UkjLUGKbmHTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications import MobileNetV2, ResNet50\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, LeakyReLU"
      ],
      "metadata": {
        "id": "VajGJf8OmMCf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TFoWETXXTgox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Original"
      ],
      "metadata": {
        "id": "anadRtgKnGS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _regularizer(weights_decay):\n",
        "    \"\"\"l2 regularizer\"\"\"\n",
        "    return tf.keras.regularizers.l2(weights_decay)\n",
        "\n",
        "\n",
        "def _kernel_init(scale=1.0, seed=None):\n",
        "    \"\"\"He normal initializer\"\"\"\n",
        "    return tf.keras.initializers.he_normal()\n",
        "\n",
        "\n",
        "class BatchNormalization(tf.keras.layers.BatchNormalization):\n",
        "    \"\"\"Make trainable=False freeze BN for real (the og version is sad).\n",
        "       ref: https://github.com/zzh8829/yolov3-tf2\n",
        "    \"\"\"\n",
        "    def __init__(self, axis=-1, momentum=0.9, epsilon=1e-5, center=True,\n",
        "                 scale=True, name=None, **kwargs):\n",
        "        super(BatchNormalization, self).__init__(\n",
        "            axis=axis, momentum=momentum, epsilon=epsilon, center=center,\n",
        "            scale=scale, name=name, **kwargs)\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        if training is None:\n",
        "            training = tf.constant(False)\n",
        "        training = tf.logical_and(training, self.trainable)\n",
        "\n",
        "        return super().call(x, training)\n",
        "\n",
        "\n",
        "def Backbone(backbone_type='ResNet50', use_pretrain=True):\n",
        "    \"\"\"Backbone Model\"\"\"\n",
        "    weights = None\n",
        "    if use_pretrain:\n",
        "        weights = 'imagenet'\n",
        "\n",
        "    def backbone(x):\n",
        "        if backbone_type == 'ResNet50':\n",
        "            extractor = ResNet50(\n",
        "                input_shape=x.shape[1:], include_top=False, weights=weights)\n",
        "            pick_layer1 = 80  # [80, 80, 512]\n",
        "            pick_layer2 = 142  # [40, 40, 1024]\n",
        "            pick_layer3 = 174  # [20, 20, 2048]\n",
        "            preprocess = tf.keras.applications.resnet.preprocess_input\n",
        "        elif backbone_type == 'MobileNetV2':\n",
        "            extractor = MobileNetV2(\n",
        "                input_shape=x.shape[1:], include_top=False, weights=weights)\n",
        "            pick_layer1 = 54  # [80, 80, 32]\n",
        "            pick_layer2 = 116  # [40, 40, 96]\n",
        "            pick_layer3 = 143  # [20, 20, 160]\n",
        "            preprocess = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "        else:\n",
        "            raise NotImplementedError(\n",
        "                'Backbone type {} is not recognized.'.format(backbone_type))\n",
        "\n",
        "        return Model(extractor.input,\n",
        "                     (extractor.layers[pick_layer1].output,\n",
        "                      extractor.layers[pick_layer2].output,\n",
        "                      extractor.layers[pick_layer3].output),\n",
        "                     name=backbone_type + '_extrator')(preprocess(x))\n",
        "\n",
        "    return backbone\n",
        "\n",
        "\n",
        "class ConvUnit(tf.keras.layers.Layer):\n",
        "    \"\"\"Conv + BN + Act\"\"\"\n",
        "    def __init__(self, f, k, s, wd, act=None, name='ConvBN', **kwargs):\n",
        "        super(ConvUnit, self).__init__(name=name, **kwargs)\n",
        "        self.conv = Conv2D(filters=f, kernel_size=k, strides=s, padding='same',\n",
        "                           kernel_initializer=_kernel_init(),\n",
        "                           kernel_regularizer=_regularizer(wd),\n",
        "                           use_bias=False, name='conv')\n",
        "        self.bn = BatchNormalization(name='bn')\n",
        "\n",
        "        if act is None:\n",
        "            self.act_fn = tf.identity\n",
        "        elif act == 'relu':\n",
        "            self.act_fn = ReLU()\n",
        "        elif act == 'lrelu':\n",
        "            self.act_fn = LeakyReLU(0.1)\n",
        "        else:\n",
        "            raise NotImplementedError(\n",
        "                'Activation function type {} is not recognized.'.format(act))\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.act_fn(self.bn(self.conv(x)))\n",
        "\n",
        "\n",
        "class FPN(tf.keras.layers.Layer):\n",
        "    \"\"\"Feature Pyramid Network\"\"\"\n",
        "    def __init__(self, out_ch, wd, name='FPN', **kwargs):\n",
        "        super(FPN, self).__init__(name=name, **kwargs)\n",
        "        act = 'relu'\n",
        "        if (out_ch <= 64):\n",
        "            act = 'lrelu'\n",
        "\n",
        "        self.output1 = ConvUnit(f=out_ch, k=1, s=1, wd=wd, act=act)\n",
        "        self.output2 = ConvUnit(f=out_ch, k=1, s=1, wd=wd, act=act)\n",
        "        self.output3 = ConvUnit(f=out_ch, k=1, s=1, wd=wd, act=act)\n",
        "        self.merge1 = ConvUnit(f=out_ch, k=3, s=1, wd=wd, act=act)\n",
        "        self.merge2 = ConvUnit(f=out_ch, k=3, s=1, wd=wd, act=act)\n",
        "\n",
        "    def call(self, x):\n",
        "        output1 = self.output1(x[0])  # [80, 80, out_ch]\n",
        "        output2 = self.output2(x[1])  # [40, 40, out_ch]\n",
        "        output3 = self.output3(x[2])  # [20, 20, out_ch]\n",
        "\n",
        "        up_h, up_w = tf.shape(output2)[1], tf.shape(output2)[2]\n",
        "        up3 = tf.image.resize(output3, [up_h, up_w], method='nearest')\n",
        "        output2 = output2 + up3\n",
        "        output2 = self.merge2(output2)\n",
        "\n",
        "        up_h, up_w = tf.shape(output1)[1], tf.shape(output1)[2]\n",
        "        up2 = tf.image.resize(output2, [up_h, up_w], method='nearest')\n",
        "        output1 = output1 + up2\n",
        "        output1 = self.merge1(output1)\n",
        "\n",
        "        return output1, output2, output3\n",
        "\n",
        "\n",
        "class SSH(tf.keras.layers.Layer):\n",
        "    \"\"\"Single Stage Headless Layer\"\"\"\n",
        "    def __init__(self, out_ch, wd, name='SSH', **kwargs):\n",
        "        super(SSH, self).__init__(name=name, **kwargs)\n",
        "        assert out_ch % 4 == 0\n",
        "        act = 'relu'\n",
        "        if (out_ch <= 64):\n",
        "            act = 'lrelu'\n",
        "\n",
        "        self.conv_3x3 = ConvUnit(f=out_ch // 2, k=3, s=1, wd=wd, act=None)\n",
        "\n",
        "        self.conv_5x5_1 = ConvUnit(f=out_ch // 4, k=3, s=1, wd=wd, act=act)\n",
        "        self.conv_5x5_2 = ConvUnit(f=out_ch // 4, k=3, s=1, wd=wd, act=None)\n",
        "\n",
        "        self.conv_7x7_2 = ConvUnit(f=out_ch // 4, k=3, s=1, wd=wd, act=act)\n",
        "        self.conv_7x7_3 = ConvUnit(f=out_ch // 4, k=3, s=1, wd=wd, act=None)\n",
        "\n",
        "        self.relu = ReLU()\n",
        "\n",
        "    def call(self, x):\n",
        "        conv_3x3 = self.conv_3x3(x)\n",
        "\n",
        "        conv_5x5_1 = self.conv_5x5_1(x)\n",
        "        conv_5x5 = self.conv_5x5_2(conv_5x5_1)\n",
        "\n",
        "        conv_7x7_2 = self.conv_7x7_2(conv_5x5_1)\n",
        "        conv_7x7 = self.conv_7x7_3(conv_7x7_2)\n",
        "\n",
        "        output = tf.concat([conv_3x3, conv_5x5, conv_7x7], axis=3)\n",
        "        output = self.relu(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class BboxHead(tf.keras.layers.Layer):\n",
        "    \"\"\"Bbox Head Layer\"\"\"\n",
        "    def __init__(self, num_anchor, wd, name='BboxHead', **kwargs):\n",
        "        super(BboxHead, self).__init__(name=name, **kwargs)\n",
        "        self.num_anchor = num_anchor\n",
        "        self.conv = Conv2D(filters=num_anchor * 4, kernel_size=1, strides=1)\n",
        "\n",
        "    def call(self, x):\n",
        "        h, w = tf.shape(x)[1], tf.shape(x)[2]\n",
        "        x = self.conv(x)\n",
        "\n",
        "        return tf.reshape(x, [-1, h * w * self.num_anchor, 4])\n",
        "\n",
        "\n",
        "class LandmarkHead(tf.keras.layers.Layer):\n",
        "    \"\"\"Landmark Head Layer\"\"\"\n",
        "    def __init__(self, num_anchor, wd, name='LandmarkHead', **kwargs):\n",
        "        super(LandmarkHead, self).__init__(name=name, **kwargs)\n",
        "        self.num_anchor = num_anchor\n",
        "        self.conv = Conv2D(filters=num_anchor * 10, kernel_size=1, strides=1)\n",
        "\n",
        "    def call(self, x):\n",
        "        h, w = tf.shape(x)[1], tf.shape(x)[2]\n",
        "        x = self.conv(x)\n",
        "\n",
        "        return tf.reshape(x, [-1, h * w * self.num_anchor, 10])\n",
        "\n",
        "\n",
        "class ClassHead(tf.keras.layers.Layer):\n",
        "    \"\"\"Class Head Layer\"\"\"\n",
        "    def __init__(self, num_anchor, wd, name='ClassHead', **kwargs):\n",
        "        super(ClassHead, self).__init__(name=name, **kwargs)\n",
        "        self.num_anchor = num_anchor\n",
        "        self.conv = Conv2D(filters=num_anchor * 2, kernel_size=1, strides=1)\n",
        "\n",
        "    def call(self, x):\n",
        "        h, w = tf.shape(x)[1], tf.shape(x)[2]\n",
        "        x = self.conv(x)\n",
        "\n",
        "        return tf.reshape(x, [-1, h * w * self.num_anchor, 2])\n",
        "\n",
        "\n",
        "def RetinaFaceModel(cfg, training=False, iou_th=0.4, score_th=0.02,\n",
        "                    name='RetinaFaceModel'):\n",
        "    \"\"\"Retina Face Model\"\"\"\n",
        "    input_size = cfg['input_size'] if training else None\n",
        "    wd = cfg['weights_decay']\n",
        "    out_ch = cfg['out_channel']\n",
        "    num_anchor = len(cfg['min_sizes'][0])\n",
        "    backbone_type = cfg['backbone_type']\n",
        "\n",
        "    # define model\n",
        "    x = inputs = Input([input_size, input_size, 3], name='input_image')\n",
        "\n",
        "    x = Backbone(backbone_type=backbone_type)(x)\n",
        "\n",
        "    fpn = FPN(out_ch=out_ch, wd=wd)(x)\n",
        "\n",
        "    features = [SSH(out_ch=out_ch, wd=wd, name=f'SSH_{i}')(f)\n",
        "                for i, f in enumerate(fpn)]\n",
        "\n",
        "    bbox_regressions = tf.concat(\n",
        "        [BboxHead(num_anchor, wd=wd, name=f'BboxHead_{i}')(f)\n",
        "         for i, f in enumerate(features)], axis=1)\n",
        "    landm_regressions = tf.concat(\n",
        "        [LandmarkHead(num_anchor, wd=wd, name=f'LandmarkHead_{i}')(f)\n",
        "         for i, f in enumerate(features)], axis=1)\n",
        "    classifications = tf.concat(\n",
        "        [ClassHead(num_anchor, wd=wd, name=f'ClassHead_{i}')(f)\n",
        "         for i, f in enumerate(features)], axis=1)\n",
        "\n",
        "    classifications = tf.keras.layers.Softmax(axis=-1)(classifications)\n",
        "\n",
        "    if training:\n",
        "        out = (bbox_regressions, landm_regressions, classifications)\n",
        "    else:\n",
        "        # only for batch size 1\n",
        "        preds = tf.concat(  # [bboxes, landms, landms_valid, conf]\n",
        "            [bbox_regressions[0], landm_regressions[0],\n",
        "             tf.ones_like(classifications[0, :, 0][..., tf.newaxis]),\n",
        "             classifications[0, :, 1][..., tf.newaxis]], 1)\n",
        "        priors = prior_box_tf((tf.shape(inputs)[1], tf.shape(inputs)[2]),\n",
        "                              cfg['min_sizes'],  cfg['steps'], cfg['clip'])\n",
        "        decode_preds = decode_tf(preds, priors, cfg['variances'])\n",
        "\n",
        "        selected_indices = tf.image.non_max_suppression(\n",
        "            boxes=decode_preds[:, :4],\n",
        "            scores=decode_preds[:, -1],\n",
        "            max_output_size=tf.shape(decode_preds)[0],\n",
        "            iou_threshold=iou_th,\n",
        "            score_threshold=score_th)\n",
        "\n",
        "        out = tf.gather(decode_preds, selected_indices)\n",
        "\n",
        "    return Model(inputs, out, name=name)"
      ],
      "metadata": {
        "id": "T-4Bbya6m7ul"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oV_EhlHnm7rd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dataset Exporting to drive - only bbox and classifications"
      ],
      "metadata": {
        "id": "AkyUiC2ojd-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define prior box\n",
        "priors = prior_box((cfg['input_size'], cfg['input_size']),\n",
        "                    cfg['min_sizes'],  cfg['steps'], cfg['clip'])\n",
        "\n",
        "priors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W5CojBMjgEM",
        "outputId": "4a177deb-8bd3-466a-e2e8-060171aa77a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00625, 0.00625, 0.025  , 0.025  ],\n",
              "       [0.00625, 0.00625, 0.05   , 0.05   ],\n",
              "       [0.01875, 0.00625, 0.025  , 0.025  ],\n",
              "       ...,\n",
              "       [0.925  , 0.975  , 0.8    , 0.8    ],\n",
              "       [0.975  , 0.975  , 0.4    , 0.4    ],\n",
              "       [0.975  , 0.975  , 0.8    , 0.8    ]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "priors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkrWmF_jjnKP",
        "outputId": "f106916d-440d-4dbc-9087-210ba5fed2cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16800, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "train_dataset = load_dataset(cfg, priors, shuffle=True)"
      ],
      "metadata": {
        "id": "GHyRXiM9jjIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "steps_per_epoch = cfg['dataset_len'] // cfg['batch_size']\n",
        "steps_per_epoch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpGFS2qmmnrh",
        "outputId": "32c0692f-f22b-424f-8f9c-d548c557ac15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12880"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)"
      ],
      "metadata": {
        "id": "KQfXBFPmsZov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ra2p-pj8sp5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oXgjAzKMskgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,j in train_dataset.take(1):\n",
        "\n",
        "    data = i[0].numpy()\n",
        "    label = j[0].numpy()\n",
        "\n",
        "    print(data.shape)\n",
        "    print(label[:,[0,1,2,3,-2,-1]].shape)\n",
        "\n",
        "    print()\n",
        "    print(label[:,[0,1,2,3,-2,-1]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6LU-CKlrrig",
        "outputId": "b456107d-54d1-43e6-f0d9-36181a39c71b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(640, 640, 3)\n",
            "(16800, 6)\n",
            "\n",
            "[[ 3.1085504e+02  3.9293970e+02 -4.6967721e+00 -4.6967721e+00\n",
            "   0.0000000e+00  0.0000000e+00]\n",
            " [ 1.5542752e+02  1.9646985e+02 -8.1625080e+00 -8.1625080e+00\n",
            "   0.0000000e+00  0.0000000e+00]\n",
            " [ 3.0585504e+02  3.9293970e+02 -4.6967721e+00 -4.6967721e+00\n",
            "   0.0000000e+00  0.0000000e+00]\n",
            " ...\n",
            " [-4.7322879e+00  3.7662681e-02 -1.8994764e+01 -1.8159508e+01\n",
            "   0.0000000e+00  0.0000000e+00]\n",
            " [-1.6754894e+00  5.0284857e-01 -1.7788975e+01 -1.8559715e+01\n",
            "   0.0000000e+00  0.0000000e+00]\n",
            " [-4.0136395e+00  1.5981196e-01 -1.8994780e+01 -1.8994780e+01\n",
            "   0.0000000e+00  0.0000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 1\n",
        "for i,j in tqdm(train_dataset.take(12880)):\n",
        "\n",
        "    data = i[0].numpy()\n",
        "    label = j[0].numpy()\n",
        "\n",
        "    label = label[:,[0,1,2,3,-2,-1]]\n",
        "\n",
        "    np.save(f'/content/drive/MyDrive/RetinaFace/Dataset_numpy/data/{idx}.npy',\n",
        "            data)\n",
        "    np.save(f'/content/drive/MyDrive/RetinaFace/Dataset_numpy/labels/{idx}.npy',\n",
        "            label)\n",
        "\n",
        "    idx+=1\n"
      ],
      "metadata": {
        "id": "ArwpUDSmjjFd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d8acee6-0854-44b2-d487-0a6c27ced0d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12880/12880 [22:33<00:00,  9.52it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir('/content/drive/MyDrive/RetinaFace/Dataset_numpy/labels'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2xtPLy02RD-",
        "outputId": "70544610-774a-4084-ad50-ba33cc98e5c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12880"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset_list), len(label_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmvds_PmjrXO",
        "outputId": "8f5a7189-07a9-45ba-9f2d-aad40d4129fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12880"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_numpy = np.array(dataset_list)"
      ],
      "metadata": {
        "id": "tuCeCsyknKgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qg7RuN5InKcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gtDJX38inKaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fVDBFi5ijrTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train.py"
      ],
      "metadata": {
        "id": "n1X98xwVcJCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# flags.DEFINE_string('cfg_path', './configs/retinaface_res50.yaml',\n",
        "#                 'config file path')\n",
        "# flags.DEFINE_string('gpu', '0', 'which gpu to use')"
      ],
      "metadata": {
        "id": "95vCSGFKcL8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# init\n",
        "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "# os.environ['CUDA_VISIBLE_DEVICES'] = FLAGS.gpu\n",
        "\n",
        "logger = tf.get_logger()\n",
        "logger.disabled = True\n",
        "logger.setLevel(logging.FATAL)\n",
        "set_memory_growth()\n",
        "\n",
        "#cfg = load_yaml(FLAGS.cfg_path)\n",
        "\n",
        "# define network\n",
        "model = RetinaFaceModel(cfg, training=True)\n",
        "model.summary(line_length=80)\n",
        "\n",
        "# define prior box\n",
        "priors = prior_box((cfg['input_size'], cfg['input_size']),\n",
        "                    cfg['min_sizes'],  cfg['steps'], cfg['clip'])\n",
        "\n",
        "# load dataset\n",
        "train_dataset = load_dataset(cfg, priors, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO3V-Mn7S5BA",
        "outputId": "49f410fc-4d6a-43f5-ee4e-057dd9780141"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "9420800/9406464 [==============================] - 0s 0us/step\n",
            "Model: \"RetinaFaceModel\"\n",
            "________________________________________________________________________________\n",
            " Layer (type)             Output Shape      Param #  Connected to               \n",
            "================================================================================\n",
            " input_image (InputLayer)  [(None, 640, 640  0       []                         \n",
            "                          , 3)]                                                 \n",
            "                                                                                \n",
            " tf.math.truediv (TFOpLam  (None, 640, 640,  0       ['input_image[0][0]']      \n",
            " bda)                      3)                                                   \n",
            "                                                                                \n",
            " tf.math.subtract (TFOpLa  (None, 640, 640,  0       ['tf.math.truediv[0][0]']  \n",
            " mbda)                     3)                                                   \n",
            "                                                                                \n",
            " MobileNetV2_extrator (Fu  ((None, 80, 80,   1518464  ['tf.math.subtract[0][0]']\n",
            " nctional)                192),                                                 \n",
            "                           (None, 40, 40,                                       \n",
            "                          576),                                                 \n",
            "                           (None, 20, 20,                                       \n",
            "                          960))                                                 \n",
            "                                                                                \n",
            " FPN (FPN)                ((None, 80, 80,   185600   ['MobileNetV2_extrator[0][0\n",
            "                          64),                       ]',                        \n",
            "                           (None, 40, 40,             'MobileNetV2_extrator[0][1\n",
            "                          64),                       ]',                        \n",
            "                           (None, 20, 20,             'MobileNetV2_extrator[0][2\n",
            "                          64))                       ]']                        \n",
            "                                                                                \n",
            " SSH_0 (SSH)              (None, 80, 80, 6  34944    ['FPN[0][0]']              \n",
            "                          4)                                                    \n",
            "                                                                                \n",
            " SSH_1 (SSH)              (None, 40, 40, 6  34944    ['FPN[0][1]']              \n",
            "                          4)                                                    \n",
            "                                                                                \n",
            " SSH_2 (SSH)              (None, 20, 20, 6  34944    ['FPN[0][2]']              \n",
            "                          4)                                                    \n",
            "                                                                                \n",
            " ClassHead_0 (ClassHead)  (None, 12800, 2)  260      ['SSH_0[0][0]']            \n",
            "                                                                                \n",
            " ClassHead_1 (ClassHead)  (None, 3200, 2)   260      ['SSH_1[0][0]']            \n",
            "                                                                                \n",
            " ClassHead_2 (ClassHead)  (None, 800, 2)    260      ['SSH_2[0][0]']            \n",
            "                                                                                \n",
            " BboxHead_0 (BboxHead)    (None, 12800, 4)  520      ['SSH_0[0][0]']            \n",
            "                                                                                \n",
            " BboxHead_1 (BboxHead)    (None, 3200, 4)   520      ['SSH_1[0][0]']            \n",
            "                                                                                \n",
            " BboxHead_2 (BboxHead)    (None, 800, 4)    520      ['SSH_2[0][0]']            \n",
            "                                                                                \n",
            " LandmarkHead_0 (Landmark  (None, 12800, 10  1300    ['SSH_0[0][0]']            \n",
            " Head)                    )                                                     \n",
            "                                                                                \n",
            " LandmarkHead_1 (Landmark  (None, 3200, 10)  1300    ['SSH_1[0][0]']            \n",
            " Head)                                                                          \n",
            "                                                                                \n",
            " LandmarkHead_2 (Landmark  (None, 800, 10)  1300     ['SSH_2[0][0]']            \n",
            " Head)                                                                          \n",
            "                                                                                \n",
            " tf.concat_2 (TFOpLambda)  (None, 16800, 2)  0       ['ClassHead_0[0][0]',      \n",
            "                                                      'ClassHead_1[0][0]',      \n",
            "                                                      'ClassHead_2[0][0]']      \n",
            "                                                                                \n",
            " tf.concat (TFOpLambda)   (None, 16800, 4)  0        ['BboxHead_0[0][0]',       \n",
            "                                                      'BboxHead_1[0][0]',       \n",
            "                                                      'BboxHead_2[0][0]']       \n",
            "                                                                                \n",
            " tf.concat_1 (TFOpLambda)  (None, 16800, 10  0       ['LandmarkHead_0[0][0]',   \n",
            "                          )                           'LandmarkHead_1[0][0]',   \n",
            "                                                      'LandmarkHead_2[0][0]']   \n",
            "                                                                                \n",
            " softmax (Softmax)        (None, 16800, 2)  0        ['tf.concat_2[0][0]']      \n",
            "                                                                                \n",
            "================================================================================\n",
            "Total params: 1,815,136\n",
            "Trainable params: 1,786,848\n",
            "Non-trainable params: 28,288\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3KH6MXbyTISp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in train_dataset.take(1):\n",
        "\n",
        "  xtemp = i\n",
        "  ytemp = j"
      ],
      "metadata": {
        "id": "ZP1pae_LS71g"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtemp.shape, ytemp.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLKS8z_MTONJ",
        "outputId": "bab9453b-a577-476d-f898-c7f0a2da1806"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 640, 640, 3]), TensorShape([1, 16800, 16]))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AisrchedUVSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred_temp1 = model(xtemp)\n",
        "ypred_temp1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVginGqGTUsw",
        "outputId": "4e2bbdb8-f5ea-4843-ad0f-6182146861d7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 16800, 4), dtype=float32, numpy=\n",
              " array([[[ 0.35473648,  0.13475156,  3.7759504 ,  6.856581  ],\n",
              "         [-1.531177  ,  0.48871338, -2.081355  , -0.12608624],\n",
              "         [ 3.5543811 , -4.8035517 ,  6.689021  ,  7.8595057 ],\n",
              "         ...,\n",
              "         [-3.0992239 ,  1.319152  ,  2.2535667 ,  1.4098037 ],\n",
              "         [-0.70297134, -3.591864  ,  0.22981703, -0.15286635],\n",
              "         [-2.8850117 ,  3.7312758 ,  2.0049443 ,  0.9901669 ]]],\n",
              "       dtype=float32)>, <tf.Tensor: shape=(1, 16800, 10), dtype=float32, numpy=\n",
              " array([[[-1.3899478 , -4.0483303 , -3.9506795 , ..., -0.06935198,\n",
              "          -1.0926036 , -0.50610954],\n",
              "         [ 1.4040815 , -0.27496356,  1.8950644 , ..., -0.70333517,\n",
              "           2.2094898 , -1.42324   ],\n",
              "         [ 1.691037  , -4.472405  , -1.4335517 , ..., -1.655506  ,\n",
              "          -3.3709562 ,  4.684601  ],\n",
              "         ...,\n",
              "         [ 0.31487387, -0.2155874 , -3.7514577 , ..., -1.291543  ,\n",
              "           2.559754  , -0.7800139 ],\n",
              "         [ 0.78551584,  1.4627323 ,  2.5879245 , ..., -3.4375303 ,\n",
              "           1.1674482 ,  0.87335074],\n",
              "         [-0.08665269, -0.65463656,  0.23498222, ..., -3.1739714 ,\n",
              "           2.6124763 ,  1.8913809 ]]], dtype=float32)>, <tf.Tensor: shape=(1, 16800, 2), dtype=float32, numpy=\n",
              " array([[[0.6094847 , 0.39051536],\n",
              "         [0.65673053, 0.3432695 ],\n",
              "         [0.8760688 , 0.12393126],\n",
              "         ...,\n",
              "         [0.9986701 , 0.0013299 ],\n",
              "         [0.78368235, 0.2163176 ],\n",
              "         [0.5279641 , 0.47203588]]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(ypred_temp1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcXUQZC3TwLZ",
        "outputId": "cf61ce37-335c-497f-db32-dafe0d6e3375"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ypred_temp = list(ypred_temp1)\n",
        "len(ypred_temp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoWU2o0aTUqG",
        "outputId": "80288b5a-8353-465e-bd05-866158cdbc7d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ypred_temp[0].shape, ypred_temp[1].shape, ypred_temp[2].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gv84CnSNTp9c",
        "outputId": "510237e3-fb34-4c5e-85f7-667a6d7bd1d1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 16800, 4]),\n",
              " TensorShape([1, 16800, 10]),\n",
              " TensorShape([1, 16800, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define losses function\n",
        "multi_box_loss = MultiBoxLoss()\n",
        "\n",
        "multi_box_loss(ytemp, ypred_temp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpbqjDrDUUJJ",
        "outputId": "f9c48e1e-e5dd-4d62-e930-f71b1cb1ab50"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=4.817335>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=6.3045397>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=12.088662>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "L9pOglGxTp6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gLsAeb6gTB-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define optimizer\n",
        "steps_per_epoch = cfg['dataset_len'] // cfg['batch_size']\n",
        "learning_rate = MultiStepWarmUpLR(\n",
        "    initial_learning_rate=cfg['init_lr'],\n",
        "    lr_steps=[e * steps_per_epoch for e in cfg['lr_decay_epoch']],\n",
        "    lr_rate=cfg['lr_rate'],\n",
        "    warmup_steps=cfg['warmup_epoch'] * steps_per_epoch,\n",
        "    min_lr=cfg['min_lr'])\n",
        "optimizer = tf.keras.optimizers.SGD(\n",
        "    learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
        "\n",
        "\n",
        "# load checkpoint\n",
        "checkpoint_dir = './checkpoints/' + cfg['sub_name']\n",
        "checkpoint = tf.train.Checkpoint(step=tf.Variable(0, name='step'),\n",
        "                                    optimizer=optimizer,\n",
        "                                    model=model)\n",
        "manager = tf.train.CheckpointManager(checkpoint=checkpoint,\n",
        "                                        directory=checkpoint_dir,\n",
        "                                        max_to_keep=3)\n",
        "if manager.latest_checkpoint:\n",
        "    checkpoint.restore(manager.latest_checkpoint)\n",
        "    print('[*] load ckpt from {} at step {}.'.format(\n",
        "        manager.latest_checkpoint, checkpoint.step.numpy()))\n",
        "else:\n",
        "    print(\"[*] training from scratch.\")"
      ],
      "metadata": {
        "id": "HoPNz73OUFWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "U86teu0TUFQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# define losses function\n",
        "multi_box_loss = MultiBoxLoss()\n",
        "\n",
        "\n",
        "\n",
        "# define training step function\n",
        "@tf.function\n",
        "def train_step(inputs, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs, training=True)\n",
        "\n",
        "        losses = {}\n",
        "        losses['reg'] = tf.reduce_sum(model.losses)\n",
        "        losses['loc'], losses['landm'], losses['class'] = \\\n",
        "            multi_box_loss(labels, predictions)\n",
        "        total_loss = tf.add_n([l for l in losses.values()])\n",
        "\n",
        "    grads = tape.gradient(total_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    return total_loss, losses\n",
        "\n",
        "# training loop\n",
        "summary_writer = tf.summary.create_file_writer('./logs/' + cfg['sub_name'])\n",
        "remain_steps = max(\n",
        "    steps_per_epoch * cfg['epoch'] - checkpoint.step.numpy(), 0)\n",
        "prog_bar = ProgressBar(steps_per_epoch,\n",
        "                        checkpoint.step.numpy() % steps_per_epoch)\n",
        "\n",
        "for inputs, labels in train_dataset.take(remain_steps):\n",
        "    checkpoint.step.assign_add(1)\n",
        "    steps = checkpoint.step.numpy()\n",
        "\n",
        "    total_loss, losses = train_step(inputs, labels)\n",
        "\n",
        "    prog_bar.update(\"epoch={}/{}, loss={:.4f}, lr={:.1e}\".format(\n",
        "        ((steps - 1) // steps_per_epoch) + 1, cfg['epoch'],\n",
        "        total_loss.numpy(), optimizer.lr(steps).numpy()))\n",
        "\n",
        "    if steps % 10 == 0:\n",
        "        with summary_writer.as_default():\n",
        "            tf.summary.scalar(\n",
        "                'loss/total_loss', total_loss, step=steps)\n",
        "            for k, l in losses.items():\n",
        "                tf.summary.scalar('loss/{}'.format(k), l, step=steps)\n",
        "            tf.summary.scalar(\n",
        "                'learning_rate', optimizer.lr(steps), step=steps)\n",
        "\n",
        "    if steps % cfg['save_steps'] == 0:\n",
        "        manager.save()\n",
        "        print(\"\\n[*] save ckpt file at {}\".format(\n",
        "            manager.latest_checkpoint))\n",
        "\n",
        "manager.save()\n",
        "print(\"\\n[*] training done! save ckpt file at {}\".format(\n",
        "    manager.latest_checkpoint))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Fx5X-Xc_cL2t",
        "outputId": "a2d5f7ee-5725-4b3f-a6f1-246d30ec2c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"RetinaFaceModel\"\n",
            "________________________________________________________________________________\n",
            " Layer (type)             Output Shape      Param #  Connected to               \n",
            "================================================================================\n",
            " input_image (InputLayer)  [(None, None, No  0       []                         \n",
            "                          ne, 3)]                                               \n",
            "                                                                                \n",
            " tf.compat.v1.shape (TFOp  (4,)             0        ['input_image[0][0]']      \n",
            " Lambda)                                                                        \n",
            "                                                                                \n",
            " tf.compat.v1.shape_1 (TF  (4,)             0        ['input_image[0][0]']      \n",
            " OpLambda)                                                                      \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.compat.v1.shape[0][0]'\n",
            " _6 (SlicingOpLambda)                                ]                          \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.compat.v1.shape_1[0][0\n",
            " _7 (SlicingOpLambda)                                ]']                        \n",
            "                                                                                \n",
            " tf.convert_to_tensor (TF  (2,)             0        ['tf.__operators__.getitem_\n",
            " OpLambda)                                           6[0][0]',                  \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     7[0][0]']                  \n",
            "                                                                                \n",
            " tf.cast (TFOpLambda)     (2,)              0        ['tf.convert_to_tensor[0][0\n",
            "                                                     ]']                        \n",
            "                                                                                \n",
            " tf.reshape (TFOpLambda)  (1, 2)            0        ['tf.cast[0][0]']          \n",
            "                                                                                \n",
            " tf.math.truediv_1 (TFOpL  (3, 2)           0        ['tf.reshape[0][0]']       \n",
            " ambda)                                                                         \n",
            "                                                                                \n",
            " tf.math.ceil (TFOpLambda  (3, 2)           0        ['tf.math.truediv_1[0][0]']\n",
            " )                                                                              \n",
            "                                                                                \n",
            " tf.math.truediv (TFOpLam  (None, None, Non  0       ['input_image[0][0]']      \n",
            " bda)                     e, 3)                                                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (2,)             0        ['tf.math.ceil[0][0]']     \n",
            " _8 (SlicingOpLambda)                                                           \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (2,)             0        ['tf.math.ceil[0][0]']     \n",
            " _10 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (2,)             0        ['tf.math.ceil[0][0]']     \n",
            " _21 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (2,)             0        ['tf.math.ceil[0][0]']     \n",
            " _23 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (2,)             0        ['tf.math.ceil[0][0]']     \n",
            " _34 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (2,)             0        ['tf.math.ceil[0][0]']     \n",
            " _36 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.subtract (TFOpLa  (None, None, Non  0       ['tf.math.truediv[0][0]']  \n",
            " mbda)                    e, 3)                                                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.__operators__.getitem_\n",
            " _9 (SlicingOpLambda)                                8[0][0]']                  \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.__operators__.getitem_\n",
            " _11 (SlicingOpLambda)                               10[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.__operators__.getitem_\n",
            " _22 (SlicingOpLambda)                               21[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.__operators__.getitem_\n",
            " _24 (SlicingOpLambda)                               23[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.__operators__.getitem_\n",
            " _35 (SlicingOpLambda)                               34[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.__operators__.getitem_\n",
            " _37 (SlicingOpLambda)                               36[0][0]']                 \n",
            "                                                                                \n",
            " MobileNetV2_extrator (Fu  ((None, None, No  1518464  ['tf.math.subtract[0][0]']\n",
            " nctional)                ne, 192),                                             \n",
            "                           (None, None, No                                      \n",
            "                          ne, 576),                                             \n",
            "                           (None, None, No                                      \n",
            "                          ne, 960))                                             \n",
            "                                                                                \n",
            " tf.range (TFOpLambda)    (None,)           0        ['tf.__operators__.getitem_\n",
            "                                                     9[0][0]']                  \n",
            "                                                                                \n",
            " tf.range_1 (TFOpLambda)  (None,)           0        ['tf.__operators__.getitem_\n",
            "                                                     11[0][0]']                 \n",
            "                                                                                \n",
            " tf.range_2 (TFOpLambda)  (None,)           0        ['tf.__operators__.getitem_\n",
            "                                                     22[0][0]']                 \n",
            "                                                                                \n",
            " tf.range_3 (TFOpLambda)  (None,)           0        ['tf.__operators__.getitem_\n",
            "                                                     24[0][0]']                 \n",
            "                                                                                \n",
            " tf.range_4 (TFOpLambda)  (None,)           0        ['tf.__operators__.getitem_\n",
            "                                                     35[0][0]']                 \n",
            "                                                                                \n",
            " tf.range_5 (TFOpLambda)  (None,)           0        ['tf.__operators__.getitem_\n",
            "                                                     37[0][0]']                 \n",
            "                                                                                \n",
            " FPN (FPN)                ((None, None, No  185600   ['MobileNetV2_extrator[0][0\n",
            "                          ne, 64),                   ]',                        \n",
            "                           (None, None, No            'MobileNetV2_extrator[0][1\n",
            "                          ne, 64),                   ]',                        \n",
            "                           (None, None, No            'MobileNetV2_extrator[0][2\n",
            "                          ne, 64))                   ]']                        \n",
            "                                                                                \n",
            " tf.compat.v1.shape_2 (TF  (1,)             0        ['tf.range_1[0][0]']       \n",
            " OpLambda)                                                                      \n",
            "                                                                                \n",
            " tf.compat.v1.shape_3 (TF  (1,)             0        ['tf.range[0][0]']         \n",
            " OpLambda)                                                                      \n",
            "                                                                                \n",
            " tf.compat.v1.shape_6 (TF  (1,)             0        ['tf.range_3[0][0]']       \n",
            " OpLambda)                                                                      \n",
            "                                                                                \n",
            " tf.compat.v1.shape_7 (TF  (1,)             0        ['tf.range_2[0][0]']       \n",
            " OpLambda)                                                                      \n",
            "                                                                                \n",
            " tf.compat.v1.shape_10 (T  (1,)             0        ['tf.range_5[0][0]']       \n",
            " FOpLambda)                                                                     \n",
            "                                                                                \n",
            " tf.compat.v1.shape_11 (T  (1,)             0        ['tf.range_4[0][0]']       \n",
            " FOpLambda)                                                                     \n",
            "                                                                                \n",
            " SSH_0 (SSH)              (None, None, Non  34944    ['FPN[0][0]']              \n",
            "                          e, 64)                                                \n",
            "                                                                                \n",
            " SSH_1 (SSH)              (None, None, Non  34944    ['FPN[0][1]']              \n",
            "                          e, 64)                                                \n",
            "                                                                                \n",
            " SSH_2 (SSH)              (None, None, Non  34944    ['FPN[0][2]']              \n",
            "                          e, 64)                                                \n",
            "                                                                                \n",
            " tf.reshape_1 (TFOpLambda  (1, None)        0        ['tf.range[0][0]']         \n",
            " )                                                                              \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.compat.v1.shape_2[0][0\n",
            " _12 (SlicingOpLambda)                               ]']                        \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.compat.v1.shape_3[0][0\n",
            " _13 (SlicingOpLambda)                               ]']                        \n",
            "                                                                                \n",
            " tf.reshape_2 (TFOpLambda  (None, 1)        0        ['tf.range_1[0][0]']       \n",
            " )                                                                              \n",
            "                                                                                \n",
            " tf.reshape_5 (TFOpLambda  (1, None)        0        ['tf.range_2[0][0]']       \n",
            " )                                                                              \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.compat.v1.shape_6[0][0\n",
            " _25 (SlicingOpLambda)                               ]']                        \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.compat.v1.shape_7[0][0\n",
            " _26 (SlicingOpLambda)                               ]']                        \n",
            "                                                                                \n",
            " tf.reshape_6 (TFOpLambda  (None, 1)        0        ['tf.range_3[0][0]']       \n",
            " )                                                                              \n",
            "                                                                                \n",
            " tf.reshape_9 (TFOpLambda  (1, None)        0        ['tf.range_4[0][0]']       \n",
            " )                                                                              \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.compat.v1.shape_10[0][\n",
            " _38 (SlicingOpLambda)                               0]']                       \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.compat.v1.shape_11[0][\n",
            " _39 (SlicingOpLambda)                               0]']                       \n",
            "                                                                                \n",
            " tf.reshape_10 (TFOpLambd  (None, 1)        0        ['tf.range_5[0][0]']       \n",
            " a)                                                                             \n",
            "                                                                                \n",
            " ClassHead_0 (ClassHead)  (None, None, 2)   260      ['SSH_0[0][0]']            \n",
            "                                                                                \n",
            " ClassHead_1 (ClassHead)  (None, None, 2)   260      ['SSH_1[0][0]']            \n",
            "                                                                                \n",
            " ClassHead_2 (ClassHead)  (None, None, 2)   260      ['SSH_2[0][0]']            \n",
            "                                                                                \n",
            " tf.broadcast_to (TFOpLam  (None, None)     0        ['tf.reshape_1[0][0]',     \n",
            " bda)                                                 'tf.__operators__.getitem_\n",
            "                                                     12[0][0]',                 \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     13[0][0]']                 \n",
            "                                                                                \n",
            " tf.broadcast_to_1 (TFOpL  (None, None)     0        ['tf.reshape_2[0][0]',     \n",
            " ambda)                                               'tf.__operators__.getitem_\n",
            "                                                     12[0][0]',                 \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     13[0][0]']                 \n",
            "                                                                                \n",
            " tf.broadcast_to_2 (TFOpL  (None, None)     0        ['tf.reshape_5[0][0]',     \n",
            " ambda)                                               'tf.__operators__.getitem_\n",
            "                                                     25[0][0]',                 \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     26[0][0]']                 \n",
            "                                                                                \n",
            " tf.broadcast_to_3 (TFOpL  (None, None)     0        ['tf.reshape_6[0][0]',     \n",
            " ambda)                                               'tf.__operators__.getitem_\n",
            "                                                     25[0][0]',                 \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     26[0][0]']                 \n",
            "                                                                                \n",
            " tf.broadcast_to_4 (TFOpL  (None, None)     0        ['tf.reshape_9[0][0]',     \n",
            " ambda)                                               'tf.__operators__.getitem_\n",
            "                                                     38[0][0]',                 \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     39[0][0]']                 \n",
            "                                                                                \n",
            " tf.broadcast_to_5 (TFOpL  (None, None)     0        ['tf.reshape_10[0][0]',    \n",
            " ambda)                                               'tf.__operators__.getitem_\n",
            "                                                     38[0][0]',                 \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     39[0][0]']                 \n",
            "                                                                                \n",
            " tf.concat_2 (TFOpLambda)  (None, None, 2)  0        ['ClassHead_0[0][0]',      \n",
            "                                                      'ClassHead_1[0][0]',      \n",
            "                                                      'ClassHead_2[0][0]']      \n",
            "                                                                                \n",
            " tf.__operators__.add (TF  (None, None)     0        ['tf.broadcast_to[0][0]']  \n",
            " OpLambda)                                                                      \n",
            "                                                                                \n",
            " tf.__operators__.add_1 (  (None, None)     0        ['tf.broadcast_to_1[0][0]']\n",
            " TFOpLambda)                                                                    \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.cast[0][0]']          \n",
            " _16 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.cast[0][0]']          \n",
            " _17 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.__operators__.add_2 (  (None, None)     0        ['tf.broadcast_to_2[0][0]']\n",
            " TFOpLambda)                                                                    \n",
            "                                                                                \n",
            " tf.__operators__.add_3 (  (None, None)     0        ['tf.broadcast_to_3[0][0]']\n",
            " TFOpLambda)                                                                    \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.cast[0][0]']          \n",
            " _29 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.cast[0][0]']          \n",
            " _30 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.__operators__.add_4 (  (None, None)     0        ['tf.broadcast_to_4[0][0]']\n",
            " TFOpLambda)                                                                    \n",
            "                                                                                \n",
            " tf.__operators__.add_5 (  (None, None)     0        ['tf.broadcast_to_5[0][0]']\n",
            " TFOpLambda)                                                                    \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.cast[0][0]']          \n",
            " _42 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.cast[0][0]']          \n",
            " _43 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " softmax (Softmax)        (None, None, 2)   0        ['tf.concat_2[0][0]']      \n",
            "                                                                                \n",
            " tf.math.multiply (TFOpLa  (None, None)     0        ['tf.__operators__.add[0][0\n",
            " mbda)                                               ]']                        \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.cast[0][0]']          \n",
            " _14 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.multiply_1 (TFOp  (None, None)     0        ['tf.__operators__.add_1[0]\n",
            " Lambda)                                             [0]']                      \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.cast[0][0]']          \n",
            " _15 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.truediv_4 (TFOpL  (2,)             0        ['tf.__operators__.getitem_\n",
            " ambda)                                              16[0][0]']                 \n",
            "                                                                                \n",
            " tf.math.truediv_5 (TFOpL  (2,)             0        ['tf.__operators__.getitem_\n",
            " ambda)                                              17[0][0]']                 \n",
            "                                                                                \n",
            " tf.compat.v1.shape_4 (TF  (2,)             0        ['tf.broadcast_to[0][0]']  \n",
            " OpLambda)                                                                      \n",
            "                                                                                \n",
            " tf.compat.v1.shape_5 (TF  (2,)             0        ['tf.broadcast_to[0][0]']  \n",
            " OpLambda)                                                                      \n",
            "                                                                                \n",
            " tf.math.multiply_3 (TFOp  (None, None)     0        ['tf.__operators__.add_2[0]\n",
            " Lambda)                                             [0]']                      \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.cast[0][0]']          \n",
            " _27 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.multiply_4 (TFOp  (None, None)     0        ['tf.__operators__.add_3[0]\n",
            " Lambda)                                             [0]']                      \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.cast[0][0]']          \n",
            " _28 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.truediv_8 (TFOpL  (2,)             0        ['tf.__operators__.getitem_\n",
            " ambda)                                              29[0][0]']                 \n",
            "                                                                                \n",
            " tf.math.truediv_9 (TFOpL  (2,)             0        ['tf.__operators__.getitem_\n",
            " ambda)                                              30[0][0]']                 \n",
            "                                                                                \n",
            " tf.compat.v1.shape_8 (TF  (2,)             0        ['tf.broadcast_to_2[0][0]']\n",
            " OpLambda)                                                                      \n",
            "                                                                                \n",
            " tf.compat.v1.shape_9 (TF  (2,)             0        ['tf.broadcast_to_2[0][0]']\n",
            " OpLambda)                                                                      \n",
            "                                                                                \n",
            " tf.math.multiply_6 (TFOp  (None, None)     0        ['tf.__operators__.add_4[0]\n",
            " Lambda)                                             [0]']                      \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.cast[0][0]']          \n",
            " _40 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.multiply_7 (TFOp  (None, None)     0        ['tf.__operators__.add_5[0]\n",
            " Lambda)                                             [0]']                      \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.cast[0][0]']          \n",
            " _41 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.truediv_12 (TFOp  (2,)             0        ['tf.__operators__.getitem_\n",
            " Lambda)                                             42[0][0]']                 \n",
            "                                                                                \n",
            " tf.math.truediv_13 (TFOp  (2,)             0        ['tf.__operators__.getitem_\n",
            " Lambda)                                             43[0][0]']                 \n",
            "                                                                                \n",
            " tf.compat.v1.shape_12 (T  (2,)             0        ['tf.broadcast_to_4[0][0]']\n",
            " FOpLambda)                                                                     \n",
            "                                                                                \n",
            " tf.compat.v1.shape_13 (T  (2,)             0        ['tf.broadcast_to_4[0][0]']\n",
            " FOpLambda)                                                                     \n",
            "                                                                                \n",
            " BboxHead_0 (BboxHead)    (None, None, 4)   520      ['SSH_0[0][0]']            \n",
            "                                                                                \n",
            " BboxHead_1 (BboxHead)    (None, None, 4)   520      ['SSH_1[0][0]']            \n",
            "                                                                                \n",
            " BboxHead_2 (BboxHead)    (None, None, 4)   520      ['SSH_2[0][0]']            \n",
            "                                                                                \n",
            " LandmarkHead_0 (Landmark  (None, None, 10)  1300    ['SSH_0[0][0]']            \n",
            " Head)                                                                          \n",
            "                                                                                \n",
            " LandmarkHead_1 (Landmark  (None, None, 10)  1300    ['SSH_1[0][0]']            \n",
            " Head)                                                                          \n",
            "                                                                                \n",
            " LandmarkHead_2 (Landmark  (None, None, 10)  1300    ['SSH_2[0][0]']            \n",
            " Head)                                                                          \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None,)          0        ['softmax[0][0]']          \n",
            " _2 (SlicingOpLambda)                                                           \n",
            "                                                                                \n",
            " tf.math.truediv_2 (TFOpL  (None, None)     0        ['tf.math.multiply[0][0]', \n",
            " ambda)                                               'tf.__operators__.getitem_\n",
            "                                                     14[0][0]']                 \n",
            "                                                                                \n",
            " tf.math.truediv_3 (TFOpL  (None, None)     0        ['tf.math.multiply_1[0][0]'\n",
            " ambda)                                              , 'tf.__operators__.getitem\n",
            "                                                     _15[0][0]']                \n",
            "                                                                                \n",
            " tf.stack_1 (TFOpLambda)  (2, 2)            0        ['tf.math.truediv_4[0][0]',\n",
            "                                                      'tf.math.truediv_5[0][0]']\n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.compat.v1.shape_4[0][0\n",
            " _19 (SlicingOpLambda)                               ]']                        \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.compat.v1.shape_5[0][0\n",
            " _20 (SlicingOpLambda)                               ]']                        \n",
            "                                                                                \n",
            " tf.math.truediv_6 (TFOpL  (None, None)     0        ['tf.math.multiply_3[0][0]'\n",
            " ambda)                                              , 'tf.__operators__.getitem\n",
            "                                                     _27[0][0]']                \n",
            "                                                                                \n",
            " tf.math.truediv_7 (TFOpL  (None, None)     0        ['tf.math.multiply_4[0][0]'\n",
            " ambda)                                              , 'tf.__operators__.getitem\n",
            "                                                     _28[0][0]']                \n",
            "                                                                                \n",
            " tf.stack_3 (TFOpLambda)  (2, 2)            0        ['tf.math.truediv_8[0][0]',\n",
            "                                                      'tf.math.truediv_9[0][0]']\n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.compat.v1.shape_8[0][0\n",
            " _32 (SlicingOpLambda)                               ]']                        \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.compat.v1.shape_9[0][0\n",
            " _33 (SlicingOpLambda)                               ]']                        \n",
            "                                                                                \n",
            " tf.math.truediv_10 (TFOp  (None, None)     0        ['tf.math.multiply_6[0][0]'\n",
            " Lambda)                                             , 'tf.__operators__.getitem\n",
            "                                                     _40[0][0]']                \n",
            "                                                                                \n",
            " tf.math.truediv_11 (TFOp  (None, None)     0        ['tf.math.multiply_7[0][0]'\n",
            " Lambda)                                             , 'tf.__operators__.getitem\n",
            "                                                     _41[0][0]']                \n",
            "                                                                                \n",
            " tf.stack_5 (TFOpLambda)  (2, 2)            0        ['tf.math.truediv_12[0][0]'\n",
            "                                                     , 'tf.math.truediv_13[0][0]\n",
            "                                                     ']                         \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.compat.v1.shape_12[0][\n",
            " _45 (SlicingOpLambda)                               0]']                       \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.compat.v1.shape_13[0][\n",
            " _46 (SlicingOpLambda)                               0]']                       \n",
            "                                                                                \n",
            " tf.concat (TFOpLambda)   (None, None, 4)   0        ['BboxHead_0[0][0]',       \n",
            "                                                      'BboxHead_1[0][0]',       \n",
            "                                                      'BboxHead_2[0][0]']       \n",
            "                                                                                \n",
            " tf.concat_1 (TFOpLambda)  (None, None, 10)  0       ['LandmarkHead_0[0][0]',   \n",
            "                                                      'LandmarkHead_1[0][0]',   \n",
            "                                                      'LandmarkHead_2[0][0]']   \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 1)        0        ['tf.__operators__.getitem_\n",
            " _3 (SlicingOpLambda)                                2[0][0]']                  \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None,)          0        ['softmax[0][0]']          \n",
            " _4 (SlicingOpLambda)                                                           \n",
            "                                                                                \n",
            " tf.stack (TFOpLambda)    (None, None, 2)   0        ['tf.math.truediv_2[0][0]',\n",
            "                                                      'tf.math.truediv_3[0][0]']\n",
            "                                                                                \n",
            " tf.__operators__.getitem  (1, 2, 2)        0        ['tf.stack_1[0][0]']       \n",
            " _18 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.multiply_2 (TFOp  ()               0        ['tf.__operators__.getitem_\n",
            " Lambda)                                             19[0][0]',                 \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     20[0][0]']                 \n",
            "                                                                                \n",
            " tf.stack_2 (TFOpLambda)  (None, None, 2)   0        ['tf.math.truediv_6[0][0]',\n",
            "                                                      'tf.math.truediv_7[0][0]']\n",
            "                                                                                \n",
            " tf.__operators__.getitem  (1, 2, 2)        0        ['tf.stack_3[0][0]']       \n",
            " _31 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.multiply_5 (TFOp  ()               0        ['tf.__operators__.getitem_\n",
            " Lambda)                                             32[0][0]',                 \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     33[0][0]']                 \n",
            "                                                                                \n",
            " tf.stack_4 (TFOpLambda)  (None, None, 2)   0        ['tf.math.truediv_10[0][0]'\n",
            "                                                     , 'tf.math.truediv_11[0][0]\n",
            "                                                     ']                         \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (1, 2, 2)        0        ['tf.stack_5[0][0]']       \n",
            " _44 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.multiply_8 (TFOp  ()               0        ['tf.__operators__.getitem_\n",
            " Lambda)                                             45[0][0]',                 \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     46[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 4)        0        ['tf.concat[0][0]']        \n",
            "  (SlicingOpLambda)                                                             \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 10)       0        ['tf.concat_1[0][0]']      \n",
            " _1 (SlicingOpLambda)                                                           \n",
            "                                                                                \n",
            " tf.ones_like (TFOpLambda  (None, 1)        0        ['tf.__operators__.getitem_\n",
            " )                                                   3[0][0]']                  \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 1)        0        ['tf.__operators__.getitem_\n",
            " _5 (SlicingOpLambda)                                4[0][0]']                  \n",
            "                                                                                \n",
            " tf.reshape_3 (TFOpLambda  (None, 2)        0        ['tf.stack[0][0]']         \n",
            " )                                                                              \n",
            "                                                                                \n",
            " tf.repeat_1 (TFOpLambda)  (None, 2, 2)     0        ['tf.__operators__.getitem_\n",
            "                                                     18[0][0]',                 \n",
            "                                                      'tf.math.multiply_2[0][0]'\n",
            "                                                     ]                          \n",
            "                                                                                \n",
            " tf.reshape_7 (TFOpLambda  (None, 2)        0        ['tf.stack_2[0][0]']       \n",
            " )                                                                              \n",
            "                                                                                \n",
            " tf.repeat_3 (TFOpLambda)  (None, 2, 2)     0        ['tf.__operators__.getitem_\n",
            "                                                     31[0][0]',                 \n",
            "                                                      'tf.math.multiply_5[0][0]'\n",
            "                                                     ]                          \n",
            "                                                                                \n",
            " tf.reshape_11 (TFOpLambd  (None, 2)        0        ['tf.stack_4[0][0]']       \n",
            " a)                                                                             \n",
            "                                                                                \n",
            " tf.repeat_5 (TFOpLambda)  (None, 2, 2)     0        ['tf.__operators__.getitem_\n",
            "                                                     44[0][0]',                 \n",
            "                                                      'tf.math.multiply_8[0][0]'\n",
            "                                                     ]                          \n",
            "                                                                                \n",
            " tf.concat_3 (TFOpLambda)  (None, 16)       0        ['tf.__operators__.getitem[\n",
            "                                                     0][0]',                    \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     1[0][0]',                  \n",
            "                                                      'tf.ones_like[0][0]',     \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     5[0][0]']                  \n",
            "                                                                                \n",
            " tf.repeat (TFOpLambda)   (None, 2)         0        ['tf.reshape_3[0][0]']     \n",
            "                                                                                \n",
            " tf.reshape_4 (TFOpLambda  (None, 2)        0        ['tf.repeat_1[0][0]']      \n",
            " )                                                                              \n",
            "                                                                                \n",
            " tf.repeat_2 (TFOpLambda)  (None, 2)        0        ['tf.reshape_7[0][0]']     \n",
            "                                                                                \n",
            " tf.reshape_8 (TFOpLambda  (None, 2)        0        ['tf.repeat_3[0][0]']      \n",
            " )                                                                              \n",
            "                                                                                \n",
            " tf.repeat_4 (TFOpLambda)  (None, 2)        0        ['tf.reshape_11[0][0]']    \n",
            "                                                                                \n",
            " tf.reshape_12 (TFOpLambd  (None, 2)        0        ['tf.repeat_5[0][0]']      \n",
            " a)                                                                             \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 4)        0        ['tf.concat_3[0][0]']      \n",
            " _47 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.concat_4 (TFOpLambda)  (None, 4)        0        ['tf.repeat[0][0]',        \n",
            "                                                      'tf.reshape_4[0][0]']     \n",
            "                                                                                \n",
            " tf.concat_5 (TFOpLambda)  (None, 4)        0        ['tf.repeat_2[0][0]',      \n",
            "                                                      'tf.reshape_8[0][0]']     \n",
            "                                                                                \n",
            " tf.concat_6 (TFOpLambda)  (None, 4)        0        ['tf.repeat_4[0][0]',      \n",
            "                                                      'tf.reshape_12[0][0]']    \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 2)        0        ['tf.__operators__.getitem_\n",
            " _52 (SlicingOpLambda)                               47[0][0]']                 \n",
            "                                                                                \n",
            " tf.concat_7 (TFOpLambda)  (None, 4)        0        ['tf.concat_4[0][0]',      \n",
            "                                                      'tf.concat_5[0][0]',      \n",
            "                                                      'tf.concat_6[0][0]']      \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 2)        0        ['tf.__operators__.getitem_\n",
            " _49 (SlicingOpLambda)                               47[0][0]']                 \n",
            "                                                                                \n",
            " tf.math.multiply_11 (TFO  (None, 2)        0        ['tf.__operators__.getitem_\n",
            " pLambda)                                            52[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 10)       0        ['tf.concat_3[0][0]']      \n",
            " _53 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.multiply_9 (TFOp  (None, 2)        0        ['tf.__operators__.getitem_\n",
            " Lambda)                                             49[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 2)        0        ['tf.concat_7[0][0]']      \n",
            " _50 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 2)        0        ['tf.concat_7[0][0]']      \n",
            " _51 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.exp (TFOpLambda)  (None, 2)        0        ['tf.math.multiply_11[0][0]\n",
            "                                                     ']                         \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 2)        0        ['tf.__operators__.getitem_\n",
            " _55 (SlicingOpLambda)                               53[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 2)        0        ['tf.__operators__.getitem_\n",
            " _58 (SlicingOpLambda)                               53[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 2)        0        ['tf.__operators__.getitem_\n",
            " _61 (SlicingOpLambda)                               53[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 2)        0        ['tf.__operators__.getitem_\n",
            " _64 (SlicingOpLambda)                               53[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 2)        0        ['tf.__operators__.getitem_\n",
            " _67 (SlicingOpLambda)                               53[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 2)        0        ['tf.concat_7[0][0]']      \n",
            " _48 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.multiply_10 (TFO  (None, 2)        0        ['tf.math.multiply_9[0][0]'\n",
            " pLambda)                                            , 'tf.__operators__.getitem\n",
            "                                                     _50[0][0]']                \n",
            "                                                                                \n",
            " tf.math.multiply_12 (TFO  (None, 2)        0        ['tf.__operators__.getitem_\n",
            " pLambda)                                            51[0][0]',                 \n",
            "                                                      'tf.math.exp[0][0]']      \n",
            "                                                                                \n",
            " tf.math.multiply_13 (TFO  (None, 2)        0        ['tf.__operators__.getitem_\n",
            " pLambda)                                            55[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 2)        0        ['tf.concat_7[0][0]']      \n",
            " _56 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.multiply_15 (TFO  (None, 2)        0        ['tf.__operators__.getitem_\n",
            " pLambda)                                            58[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 2)        0        ['tf.concat_7[0][0]']      \n",
            " _59 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.multiply_17 (TFO  (None, 2)        0        ['tf.__operators__.getitem_\n",
            " pLambda)                                            61[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 2)        0        ['tf.concat_7[0][0]']      \n",
            " _62 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.multiply_19 (TFO  (None, 2)        0        ['tf.__operators__.getitem_\n",
            " pLambda)                                            64[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 2)        0        ['tf.concat_7[0][0]']      \n",
            " _65 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.multiply_21 (TFO  (None, 2)        0        ['tf.__operators__.getitem_\n",
            " pLambda)                                            67[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 2)        0        ['tf.concat_7[0][0]']      \n",
            " _68 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.__operators__.add_6 (  (None, 2)        0        ['tf.__operators__.getitem_\n",
            " TFOpLambda)                                         48[0][0]',                 \n",
            "                                                      'tf.math.multiply_10[0][0]\n",
            "                                                     ']                         \n",
            "                                                                                \n",
            " tf.math.truediv_14 (TFOp  (None, 2)        0        ['tf.math.multiply_12[0][0]\n",
            " Lambda)                                             ']                         \n",
            "                                                                                \n",
            " tf.math.truediv_15 (TFOp  (None, 2)        0        ['tf.math.multiply_12[0][0]\n",
            " Lambda)                                             ']                         \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 2)        0        ['tf.concat_7[0][0]']      \n",
            " _54 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.multiply_14 (TFO  (None, 2)        0        ['tf.math.multiply_13[0][0]\n",
            " pLambda)                                            ',                         \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     56[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 2)        0        ['tf.concat_7[0][0]']      \n",
            " _57 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.multiply_16 (TFO  (None, 2)        0        ['tf.math.multiply_15[0][0]\n",
            " pLambda)                                            ',                         \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     59[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 2)        0        ['tf.concat_7[0][0]']      \n",
            " _60 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.multiply_18 (TFO  (None, 2)        0        ['tf.math.multiply_17[0][0]\n",
            " pLambda)                                            ',                         \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     62[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 2)        0        ['tf.concat_7[0][0]']      \n",
            " _63 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.multiply_20 (TFO  (None, 2)        0        ['tf.math.multiply_19[0][0]\n",
            " pLambda)                                            ',                         \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     65[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 2)        0        ['tf.concat_7[0][0]']      \n",
            " _66 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.math.multiply_22 (TFO  (None, 2)        0        ['tf.math.multiply_21[0][0]\n",
            " pLambda)                                            ',                         \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     68[0][0]']                 \n",
            "                                                                                \n",
            " tf.math.subtract_1 (TFOp  (None, 2)        0        ['tf.__operators__.add_6[0]\n",
            " Lambda)                                             [0]',                      \n",
            "                                                      'tf.math.truediv_14[0][0]'\n",
            "                                                     ]                          \n",
            "                                                                                \n",
            " tf.__operators__.add_7 (  (None, 2)        0        ['tf.__operators__.add_6[0]\n",
            " TFOpLambda)                                         [0]',                      \n",
            "                                                      'tf.math.truediv_15[0][0]'\n",
            "                                                     ]                          \n",
            "                                                                                \n",
            " tf.__operators__.add_8 (  (None, 2)        0        ['tf.__operators__.getitem_\n",
            " TFOpLambda)                                         54[0][0]',                 \n",
            "                                                      'tf.math.multiply_14[0][0]\n",
            "                                                     ']                         \n",
            "                                                                                \n",
            " tf.__operators__.add_9 (  (None, 2)        0        ['tf.__operators__.getitem_\n",
            " TFOpLambda)                                         57[0][0]',                 \n",
            "                                                      'tf.math.multiply_16[0][0]\n",
            "                                                     ']                         \n",
            "                                                                                \n",
            " tf.__operators__.add_10   (None, 2)        0        ['tf.__operators__.getitem_\n",
            " (TFOpLambda)                                        60[0][0]',                 \n",
            "                                                      'tf.math.multiply_18[0][0]\n",
            "                                                     ']                         \n",
            "                                                                                \n",
            " tf.__operators__.add_11   (None, 2)        0        ['tf.__operators__.getitem_\n",
            " (TFOpLambda)                                        63[0][0]',                 \n",
            "                                                      'tf.math.multiply_20[0][0]\n",
            "                                                     ']                         \n",
            "                                                                                \n",
            " tf.__operators__.add_12   (None, 2)        0        ['tf.__operators__.getitem_\n",
            " (TFOpLambda)                                        66[0][0]',                 \n",
            "                                                      'tf.math.multiply_22[0][0]\n",
            "                                                     ']                         \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None,)          0        ['tf.concat_3[0][0]']      \n",
            " _69 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None,)          0        ['tf.concat_3[0][0]']      \n",
            " _71 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.concat_8 (TFOpLambda)  (None, 4)        0        ['tf.math.subtract_1[0][0]'\n",
            "                                                     , 'tf.__operators__.add_7[0\n",
            "                                                     ][0]']                     \n",
            "                                                                                \n",
            " tf.concat_9 (TFOpLambda)  (None, 10)       0        ['tf.__operators__.add_8[0]\n",
            "                                                     [0]',                      \n",
            "                                                      'tf.__operators__.add_9[0]\n",
            "                                                     [0]',                      \n",
            "                                                      'tf.__operators__.add_10[0\n",
            "                                                     ][0]',                     \n",
            "                                                      'tf.__operators__.add_11[0\n",
            "                                                     ][0]',                     \n",
            "                                                      'tf.__operators__.add_12[0\n",
            "                                                     ][0]']                     \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 1)        0        ['tf.__operators__.getitem_\n",
            " _70 (SlicingOpLambda)                               69[0][0]']                 \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 1)        0        ['tf.__operators__.getitem_\n",
            " _72 (SlicingOpLambda)                               71[0][0]']                 \n",
            "                                                                                \n",
            " tf.concat_10 (TFOpLambda  (None, 16)       0        ['tf.concat_8[0][0]',      \n",
            " )                                                    'tf.concat_9[0][0]',      \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     70[0][0]',                 \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     72[0][0]']                 \n",
            "                                                                                \n",
            " tf.compat.v1.shape_14 (T  (2,)             0        ['tf.concat_10[0][0]']     \n",
            " FOpLambda)                                                                     \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None, 4)        0        ['tf.concat_10[0][0]']     \n",
            " _73 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.__operators__.getitem  ()               0        ['tf.compat.v1.shape_14[0][\n",
            " _75 (SlicingOpLambda)                               0]']                       \n",
            "                                                                                \n",
            " tf.__operators__.getitem  (None,)          0        ['tf.concat_10[0][0]']     \n",
            " _74 (SlicingOpLambda)                                                          \n",
            "                                                                                \n",
            " tf.image.non_max_suppres  (None,)          0        ['tf.__operators__.getitem_\n",
            " sion (TFOpLambda)                                   73[0][0]',                 \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     75[0][0]',                 \n",
            "                                                      'tf.__operators__.getitem_\n",
            "                                                     74[0][0]']                 \n",
            "                                                                                \n",
            " tf.compat.v1.gather (TFO  (None, 16)       0        ['tf.concat_10[0][0]',     \n",
            " pLambda)                                             'tf.image.non_max_suppress\n",
            "                                                     ion[0][0]']                \n",
            "                                                                                \n",
            "================================================================================\n",
            "Total params: 1,815,136\n",
            "Trainable params: 1,786,848\n",
            "Non-trainable params: 28,288\n",
            "________________________________________________________________________________\n",
            "[*] training from scratch.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-626253e8556f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     prog_bar.update(\"epoch={}/{}, loss={:.4f}, lr={:.1e}\".format(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"<ipython-input-10-626253e8556f>\", line 60, in train_step  *\n        losses['loc'], losses['landm'], losses['class'] =             multi_box_loss(labels, predictions)\n    File \"<ipython-input-6-40c4a4e68de3>\", line 12, in multi_box_loss  *\n        loc_pred = tf.reshape(y_pred[0], [num_batch * num_prior, 4])\n\n    ValueError: Cannot reshape a tensor with 16 elements to shape [134400,4] (537600 elements) for '{{node Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32](strided_slice_2, Reshape/shape)' with input shapes: [16], [2] and with input tensors computed as partial shapes: input[1] = [134400,4].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DRseXualcLbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test widerface.py"
      ],
      "metadata": {
        "id": "8coJacdLeW5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# flags.DEFINE_string('cfg_path', './configs/retinaface_res50.yaml',\n",
        "#                     'config file path')\n",
        "# flags.DEFINE_string('gpu', '0', 'which gpu to use')\n",
        "# flags.DEFINE_string('save_folder', './widerface_evaluate/widerface_txt/',\n",
        "#                     'folder path to save evaluate results')\n",
        "# flags.DEFINE_boolean('origin_size', True,\n",
        "#                      'whether use origin image size to evaluate')\n",
        "# flags.DEFINE_boolean('save_image', True, 'whether save evaluation images')\n",
        "# flags.DEFINE_float('iou_th', 0.4, 'iou threshold for nms')\n",
        "# flags.DEFINE_float('score_th', 0.02, 'score threshold for nms')\n",
        "# flags.DEFINE_float('vis_th', 0.5, 'threshold for visualization')"
      ],
      "metadata": {
        "id": "emChVFPSea9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "grPsFde-hX29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdirwiderface_evaluate"
      ],
      "metadata": {
        "id": "QWUCdgAKhObK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_folder = '/content/widerface_evaluate'\n",
        "origin_size = True\n",
        "save_image = True\n",
        "iou_th = .4\n",
        "score_th = .02\n",
        "vis_th = .5"
      ],
      "metadata": {
        "id": "4_ih9jCieek1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "def load_info(txt_path):\n",
        "    \"\"\"load info from txt\"\"\"\n",
        "    img_paths = []\n",
        "    words = []\n",
        "\n",
        "    f = open(txt_path, 'r')\n",
        "    lines = f.readlines()\n",
        "    isFirst = True\n",
        "    labels = []\n",
        "    for line in lines:\n",
        "        line = line.rstrip()\n",
        "        if line.startswith('#'):\n",
        "            if isFirst is True:\n",
        "                isFirst = False\n",
        "            else:\n",
        "                labels_copy = labels.copy()\n",
        "                words.append(labels_copy)\n",
        "                labels.clear()\n",
        "            path = line[2:]\n",
        "            path = txt_path.replace('label.txt', 'images/') + path\n",
        "            img_paths.append(path)\n",
        "        else:\n",
        "            line = line.split(' ')\n",
        "            label = [float(x) for x in line]\n",
        "            labels.append(label)\n",
        "\n",
        "    words.append(labels)\n",
        "    return img_paths, words\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "logger = tf.get_logger()\n",
        "logger.disabled = True\n",
        "logger.setLevel(logging.FATAL)\n",
        "set_memory_growth()\n",
        "\n",
        "#cfg = load_yaml(cfg_path)\n",
        "\n",
        "# define network\n",
        "model = RetinaFaceModel(cfg, training=False, iou_th=iou_th,\n",
        "                        score_th=score_th)\n",
        "\n",
        "# load checkpoint\n",
        "checkpoint_dir = './checkpoints/' + cfg['sub_name']\n",
        "checkpoint = tf.train.Checkpoint(model=model)\n",
        "if tf.train.latest_checkpoint(checkpoint_dir):\n",
        "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "    print(\"[*] load ckpt from {}.\".format(\n",
        "        tf.train.latest_checkpoint(checkpoint_dir)))\n",
        "else:\n",
        "    print(\"[*] Cannot find ckpt from {}.\".format(checkpoint_dir))\n",
        "    exit()\n",
        "\n",
        "# evaluation on testing dataset\n",
        "testset_folder = cfg['testing_dataset_path']\n",
        "testset_list = os.path.join(testset_folder, 'label.txt')\n",
        "\n",
        "img_paths, _ = load_info(testset_list)\n",
        "for img_index, img_path in enumerate(img_paths):\n",
        "    print(\" [{} / {}] det {}\".format(img_index + 1, len(img_paths),\n",
        "                                        img_path))\n",
        "    img_raw = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "    img_height_raw, img_width_raw, _ = img_raw.shape\n",
        "    img = np.float32(img_raw.copy())\n",
        "\n",
        "    # testing scale\n",
        "    target_size = 1600\n",
        "    max_size = 2150\n",
        "    img_shape = img.shape\n",
        "    img_size_min = np.min(img_shape[0:2])\n",
        "    img_size_max = np.max(img_shape[0:2])\n",
        "    resize = float(target_size) / float(img_size_min)\n",
        "    \n",
        "    # prevent bigger axis from being more than max_size:\n",
        "    if np.round(resize * img_size_max) > max_size:\n",
        "        resize = float(max_size) / float(img_size_max)\n",
        "    if origin_size:\n",
        "        if os.path.basename(img_path) == '6_Funeral_Funeral_6_618.jpg':\n",
        "            resize = 0.5 # this image is too big to avoid OOM problem\n",
        "        else:\n",
        "            resize = 1\n",
        "\n",
        "    img = cv2.resize(img, None, None, fx=resize, fy=resize,\n",
        "                        interpolation=cv2.INTER_LINEAR)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # pad input image to avoid unmatched shape problem\n",
        "    img, pad_params = pad_input_image(img, max_steps=max(cfg['steps']))\n",
        "\n",
        "    # run model\n",
        "    outputs = model(img[np.newaxis, ...]).numpy()\n",
        "\n",
        "    # recover padding effect\n",
        "    outputs = recover_pad_output(outputs, pad_params)\n",
        "\n",
        "    # write results\n",
        "    img_name = os.path.basename(img_path)\n",
        "    sub_dir = os.path.basename(os.path.dirname(img_path))\n",
        "    save_name = os.path.join(\n",
        "        save_folder, sub_dir, img_name.replace('.jpg', '.txt'))\n",
        "\n",
        "    pathlib.Path(os.path.join(save_folder, sub_dir)).mkdir(\n",
        "        parents=True, exist_ok=True)\n",
        "\n",
        "    with open(save_name, \"w\") as file:\n",
        "        bboxs = outputs[:, :4]\n",
        "        confs = outputs[:, -1]\n",
        "\n",
        "        file_name = img_name + \"\\n\"\n",
        "        bboxs_num = str(len(bboxs)) + \"\\n\"\n",
        "        file.write(file_name)\n",
        "        file.write(bboxs_num)\n",
        "        for box, conf in zip(bboxs, confs):\n",
        "            x = int(box[0] * img_width_raw)\n",
        "            y = int(box[1] * img_height_raw)\n",
        "            w = int(box[2] * img_width_raw) - int(box[0] * img_width_raw)\n",
        "            h = int(box[3] * img_height_raw) - int(box[1] * img_height_raw)\n",
        "            confidence = str(conf)\n",
        "            line = str(x) + \" \" + str(y) + \" \" + str(w) + \" \" + str(h) \\\n",
        "                + \" \" + confidence + \" \\n\"\n",
        "            file.write(line)\n",
        "\n",
        "    # save images\n",
        "    pathlib.Path(os.path.join(\n",
        "        './results', cfg['sub_name'], sub_dir)).mkdir(\n",
        "            parents=True, exist_ok=True)\n",
        "    if save_image:\n",
        "        for prior_index in range(len(outputs)):\n",
        "            if outputs[prior_index][15] >= vis_th:\n",
        "                draw_bbox_landm(img_raw, outputs[prior_index],\n",
        "                                img_height_raw, img_width_raw)\n",
        "        cv2.imwrite(os.path.join('./results', cfg['sub_name'], sub_dir,\n",
        "                                    img_name), img_raw)"
      ],
      "metadata": {
        "id": "P5iY40-LebRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zWFNr0AkeXOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test.py"
      ],
      "metadata": {
        "id": "5CadaTTxdeky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# flags.DEFINE_string('cfg_path', './configs/retinaface_res50.yaml',\n",
        "#                     'config file path')\n",
        "# flags.DEFINE_string('gpu', '0', 'which gpu to use')\n",
        "# flags.DEFINE_string('img_path', '', 'path to input image')\n",
        "# flags.DEFINE_boolean('webcam', False, 'get image source from webcam or not')\n",
        "# flags.DEFINE_float('iou_th', 0.4, 'iou threshold for nms')\n",
        "# flags.DEFINE_float('score_th', 0.5, 'score threshold for nms')\n",
        "# flags.DEFINE_float('down_scale_factor', 1.0, 'down-scale factor for inputs')\n",
        "\n"
      ],
      "metadata": {
        "id": "nPcuHY6udkST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \n",
        "iou_th = 0.4\n",
        "score_th = 0.5\n",
        "down_scale_factor = 1.0"
      ],
      "metadata": {
        "id": "1HV4hTvSdvk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "logger = tf.get_logger()\n",
        "logger.disabled = True\n",
        "logger.setLevel(logging.FATAL)\n",
        "set_memory_growth()\n",
        "\n",
        "cfg = load_yaml(FLAGS.cfg_path)\n",
        "\n",
        "# define network\n",
        "model = RetinaFaceModel(cfg, training=False, iou_th=FLAGS.iou_th,\n",
        "                        score_th=FLAGS.score_th)\n",
        "\n",
        "# load checkpoint\n",
        "checkpoint_dir = './checkpoints/' + cfg['sub_name']\n",
        "checkpoint = tf.train.Checkpoint(model=model)\n",
        "if tf.train.latest_checkpoint(checkpoint_dir):\n",
        "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "    print(\"[*] load ckpt from {}.\".format(\n",
        "        tf.train.latest_checkpoint(checkpoint_dir)))\n",
        "else:\n",
        "    print(\"[*] Cannot find ckpt from {}.\".format(checkpoint_dir))\n",
        "    exit()\n",
        "\n",
        "if not FLAGS.webcam:\n",
        "    if not os.path.exists(FLAGS.img_path):\n",
        "        print(f\"cannot find image path from {FLAGS.img_path}\")\n",
        "        exit()\n",
        "\n",
        "    print(\"[*] Processing on single image {}\".format(FLAGS.img_path))\n",
        "\n",
        "    img_raw = cv2.imread(FLAGS.img_path)\n",
        "    img_height_raw, img_width_raw, _ = img_raw.shape\n",
        "    img = np.float32(img_raw.copy())\n",
        "\n",
        "    if FLAGS.down_scale_factor < 1.0:\n",
        "        img = cv2.resize(img, (0, 0), fx=FLAGS.down_scale_factor,\n",
        "                            fy=FLAGS.down_scale_factor,\n",
        "                            interpolation=cv2.INTER_LINEAR)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # pad input image to avoid unmatched shape problem\n",
        "    img, pad_params = pad_input_image(img, max_steps=max(cfg['steps']))\n",
        "\n",
        "    # run model\n",
        "    outputs = model(img[np.newaxis, ...]).numpy()\n",
        "\n",
        "    # recover padding effect\n",
        "    outputs = recover_pad_output(outputs, pad_params)\n",
        "\n",
        "    # draw and save results\n",
        "    save_img_path = os.path.join('out_' + os.path.basename(FLAGS.img_path))\n",
        "    for prior_index in range(len(outputs)):\n",
        "        draw_bbox_landm(img_raw, outputs[prior_index], img_height_raw,\n",
        "                        img_width_raw)\n",
        "        cv2.imwrite(save_img_path, img_raw)\n",
        "    print(f\"[*] save result at {save_img_path}\")\n",
        "\n",
        "else:\n",
        "    cam = cv2.VideoCapture(0)\n",
        "\n",
        "    start_time = time.time()\n",
        "    while True:\n",
        "        _, frame = cam.read()\n",
        "        if frame is None:\n",
        "            print(\"no cam input\")\n",
        "\n",
        "        frame_height, frame_width, _ = frame.shape\n",
        "        img = np.float32(frame.copy())\n",
        "        if FLAGS.down_scale_factor < 1.0:\n",
        "            img = cv2.resize(img, (0, 0), fx=FLAGS.down_scale_factor,\n",
        "                                fy=FLAGS.down_scale_factor,\n",
        "                                interpolation=cv2.INTER_LINEAR)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # pad input image to avoid unmatched shape problem\n",
        "        img, pad_params = pad_input_image(img, max_steps=max(cfg['steps']))\n",
        "\n",
        "        # run model\n",
        "        outputs = model(img[np.newaxis, ...]).numpy()\n",
        "\n",
        "        # recover padding effect\n",
        "        outputs = recover_pad_output(outputs, pad_params)\n",
        "\n",
        "        # draw results\n",
        "        for prior_index in range(len(outputs)):\n",
        "            draw_bbox_landm(frame, outputs[prior_index], frame_height,\n",
        "                            frame_width)\n",
        "\n",
        "        # calculate fps\n",
        "        fps_str = \"FPS: %.2f\" % (1 / (time.time() - start_time))\n",
        "        start_time = time.time()\n",
        "        cv2.putText(frame, fps_str, (25, 25),\n",
        "                    cv2.FONT_HERSHEY_DUPLEX, 0.75, (0, 255, 0), 2)\n",
        "\n",
        "        # show frame\n",
        "        cv2.imshow('frame', frame)\n",
        "        if cv2.waitKey(1) == ord('q'):\n",
        "            exit()\n"
      ],
      "metadata": {
        "id": "46HPlSQwdkN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cIG-itn0dj0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modified model"
      ],
      "metadata": {
        "id": "txncwMKUWKXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_vNpSNUXWNCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = (640,640,3)"
      ],
      "metadata": {
        "id": "0JHYVbDxUSMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WDRQyUfNVLq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = MobileNetV2(input_shape = input_size, include_top=False, weights= 'imagenet')\n",
        "\n",
        "base_model.trainable = False\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6EUwtX1U8ZL",
        "outputId": "7c2442d0-0c7b-48a4-fdd3-e709352f3470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.summary()"
      ],
      "metadata": {
        "id": "t8ZS9pR2bGcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "btihrYaqWeIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.layers[143].output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6BbUYfvXNTO",
        "outputId": "c66a9256-c0ee-44b8-81b5-bec773fcf964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 20, 20, 960) dtype=float32 (created by layer 'block_16_expand')>"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExBuEXdWZSk4",
        "outputId": "da8b2932-3813-4355-efb3-d527a68ba7ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 640, 640, 3) dtype=float32 (created by layer 'input_2')>"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pick_layer1 = 54  # [80, 80, 192]\n",
        "pick_layer2 = 116  # [40, 40, 576]\n",
        "pick_layer3 = 143  # [20, 20, 960]"
      ],
      "metadata": {
        "id": "qQxBCKhNXNQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
      ],
      "metadata": {
        "id": "Us25d6ciZ0Oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "inputs = Input(input_size, name='input_image')\n",
        "\n",
        "x = preprocess_input(inputs)\n",
        "mobilenetv2_layer1_80 = Model(base_model.input, base_model.layers[pick_layer1].output, name = 'mobilenet_layer54_80')(x)\n",
        "mobilenetv2_layer2_40 = Model(base_model.input, base_model.layers[pick_layer2].output, name = 'mobilenet_layer116_40')(x)\n",
        "mobilenetv2_layer3_20 = Model(base_model.input, base_model.layers[pick_layer3].output, name = 'mobilenet_layer143_20')(x)\n",
        "\n",
        "model = Model(inputs,\n",
        "              (mobilenetv2_layer1_80,\n",
        "               mobilenetv2_layer2_40,\n",
        "               mobilenetv2_layer3_20))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ngHOJHHNZsf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1518464 + 613952 + 65152 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2oE52fIpGFt",
        "outputId": "e861a4e0-913c-44cb-9386-1ac33500d506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2197568"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "\n",
        "#model.save_weights('model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUyiUOOXmG3v",
        "outputId": "40c9517b-47d3-4edf-b4a3-d93d90e7a8a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load json and create model\n",
        "with open('model.json', 'r') as json_file:\n",
        "    model_json = json_file.read()\n",
        "\n",
        "model = tf.keras.models.model_from_json(model_json)\n",
        "# load weights into new model\n",
        "#model.load_weights(\"model.h5\")"
      ],
      "metadata": {
        "id": "wmFwqBPnoAmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "3BNBFuukoAjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zosSvHOKmGte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(prev_layer, name, filters, kernel, stride, act = True):\n",
        "    x =  Conv2D(filters = filters, \n",
        "                kernel_size = kernel, \n",
        "                strides = stride, \n",
        "                padding='same',\n",
        "                kernel_initializer = tf.keras.initializers.he_normal(),\n",
        "                use_bias = False,\n",
        "                name = name+'conv')(prev_layer)\n",
        "    \n",
        "    x = BatchNormalization(epsilon=1e-5,\n",
        "                           name = name+'batchnorm')(x)\n",
        "\n",
        "    if act:\n",
        "        x = ReLU(name = name+'relu')(x)\n",
        "               \n",
        "    \n",
        "    return x"
      ],
      "metadata": {
        "id": "hXGGnbxqZusF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cQ6aWYb42Wfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fpn(input_layer1, input_layer2, input_layer3):\n",
        "    output1 = conv_block(input_layer1,\n",
        "                        'fpn1_',\n",
        "                        filters = 64,\n",
        "                        kernel = 1,\n",
        "                        stride = 1)           #(None, 80, 80, 64)\n",
        "    \n",
        "    output2 = conv_block(input_layer2,\n",
        "                        'fpn2_',\n",
        "                        filters = 64,\n",
        "                        kernel = 1,\n",
        "                        stride = 1)           #(None, 40, 40, 64)\n",
        "    \n",
        "    output3 = conv_block(input_layer3,\n",
        "                        'fpn3_',\n",
        "                        filters = 64,\n",
        "                        kernel = 1,\n",
        "                        stride = 1)           #(None, 20, 20, 64)\n",
        "    \n",
        "    #Up sampling + feature fusion\n",
        "    up_h2, up_w2 = tf.shape(output2)[1], tf.shape(output2)[2]         #up_h = 40, up_w = 40\n",
        "    up3 = tf.image.resize(output3, [up_h2, up_w2], method='nearest')   # (None,40,40,64)\n",
        "    output2 = output2 + up3                                                         # (None,40,40,64)\n",
        "\n",
        "\n",
        "    merge2 = conv_block(output2,\n",
        "                        'fpn2_merge_',\n",
        "                        filters = 64,\n",
        "                        kernel = 3,\n",
        "                        stride = 1)                                                  # (None,40,40,64)\n",
        "    \n",
        "\n",
        "    #Up sampling + feature fusion\n",
        "    up_h1, up_w1 = tf.shape(output1)[1], tf.shape(output1)[2]         #up_h = 80, up_w = 80\n",
        "    up2 = tf.image.resize(merge2, [up_h1, up_w1], method='nearest')   # (None,80,80,64)\n",
        "    output1 = output1 + up2                                                  # (None,80,80,64)\n",
        "\n",
        "\n",
        "    merge1 = conv_block(output1,\n",
        "                        'fpn1_merge_',\n",
        "                        filters = 64,\n",
        "                        kernel = 3,\n",
        "                        stride = 1)                                               # (None,80,80,64)\n",
        "\n",
        "                        \n",
        "    return merge1, merge2, output3"
      ],
      "metadata": {
        "id": "c02BbHBwsfaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o1,o2,o3 = fpn(mobilenetv2_layer1_80, mobilenetv2_layer2_40, mobilenetv2_layer3_20)\n",
        "\n",
        "print(o1)\n",
        "print(o2)\n",
        "print(o3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONQNA9hTyswQ",
        "outputId": "f2d20b9a-f54e-40a6-e7a6-6d23a022f16f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 80, 80, 64), dtype=tf.float32, name=None), name='fpn1_merge_relu/Relu:0', description=\"created by layer 'fpn1_merge_relu'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 40, 40, 64), dtype=tf.float32, name=None), name='fpn2_merge_relu/Relu:0', description=\"created by layer 'fpn2_merge_relu'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 20, 20, 64), dtype=tf.float32, name=None), name='fpn3_relu/Relu:0', description=\"created by layer 'fpn3_relu'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uTArZRjuZupT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_3MZW5qe1gJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ssh(prev_layer, name):\n",
        "    conv_3x3 = conv_block(prev_layer,\n",
        "                        name = name + 'conv_3x3',\n",
        "                        filters = 64//2,\n",
        "                        kernel = 3,\n",
        "                        stride = 1,\n",
        "                         act = False)      \n",
        "\n",
        "    conv_5x5_1 = conv_block(prev_layer,\n",
        "                        name = name + 'conv_5x5_1',\n",
        "                        filters = 64//4,\n",
        "                        kernel = 3,\n",
        "                        stride = 1,\n",
        "                         act = True)  \n",
        "    conv_5x5 = conv_block(conv_5x5_1,\n",
        "                        name = name + 'conv_5x5',\n",
        "                        filters = 64//4,\n",
        "                        kernel = 3,\n",
        "                        stride = 1,\n",
        "                         act = False)  \n",
        "\n",
        "    conv_7x7_1 = conv_block(conv_5x5_1,\n",
        "                        name = name + 'conv_7x7_1',\n",
        "                        filters = 64//4,\n",
        "                        kernel = 3,\n",
        "                        stride = 1,\n",
        "                         act = True)  \n",
        "    conv_7x7 = conv_block(conv_7x7_1,\n",
        "                        name = name + 'conv_7x7',\n",
        "                        filters = 64//4,\n",
        "                        kernel = 3,\n",
        "                        stride = 1,\n",
        "                         act = False)    \n",
        "\n",
        "    output = tf.concat([conv_3x3, conv_5x5, conv_7x7], axis=3)\n",
        "    output = keras.layers.ReLU(name = name+'final_relu')(output)   \n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "ewy7xgXq1gHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ssh2 = ssh(o2, 'ssh2_40_')"
      ],
      "metadata": {
        "id": "sPnUhH-P1gD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ssh2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dti2HUBTxzIm",
        "outputId": "f2bd4e34-7ed4-4830-8d7c-b739e59a9e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 40, 40, 64) dtype=float32 (created by layer 'ssh2_40_final_relu')>"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7BW6FrDx62P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_sizes = [[16, 32], [64, 128], [256, 512]]\n",
        "len(min_sizes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHeS4rN7J0l0",
        "outputId": "18642d8d-774c-4c02-dad2-6e9cefcd8902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classification_head(prev_layer, num_anchor, name):\n",
        "\n",
        "    conv_1x1 = keras.layers.Conv2D(filters = num_anchor * 2, \n",
        "                                   kernel_size = 1, \n",
        "                                   strides = 1,\n",
        "                                   name = name)(prev_layer)\n",
        "    \n",
        "    h, w = tf.shape(prev_layer)[1], tf.shape(prev_layer)[2]\n",
        "\n",
        "    return tf.reshape(conv_1x1, [-1, h * w * num_anchor, 2])\n",
        "\n",
        "\n",
        "def bbox_head(prev_layer, num_anchor, name):\n",
        "\n",
        "    conv_1x1 = keras.layers.Conv2D(filters = num_anchor * 4, \n",
        "                                   kernel_size = 1, \n",
        "                                   strides = 1,\n",
        "                                   name = name)(prev_layer)\n",
        "    \n",
        "    h, w = tf.shape(prev_layer)[1], tf.shape(prev_layer)[2]\n",
        "\n",
        "    return tf.reshape(conv_1x1, [-1, h * w * num_anchor, 4])"
      ],
      "metadata": {
        "id": "IzlG_SJh51Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "okZGS90lJ4nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "inputs = Input(input_size, name='input_image')\n",
        "\n",
        "x = preprocess_input(inputs)\n",
        "mobilenetv2_layer1_80 = Model(base_model.input, base_model.layers[pick_layer1].output, name = 'mobilenet_layer54_80')(x)      #(None, 80, 80, 192)\n",
        "mobilenetv2_layer2_40 = Model(base_model.input, base_model.layers[pick_layer2].output, name = 'mobilenet_layer116_40')(x)      #(None, 40, 40, 576)\n",
        "mobilenetv2_layer3_20 = Model(base_model.input, base_model.layers[pick_layer3].output, name = 'mobilenet_layer143_20')(x)      #(None, 20, 20, 960)\n",
        "\n",
        "#feature pyramid network\n",
        "fpn_layer1_80, fpn_layer2_40, fpn_layer3_20 = fpn(mobilenetv2_layer1_80, mobilenetv2_layer2_40, mobilenetv2_layer3_20)\n",
        "\n",
        "ssh_layer1 = ssh(fpn_layer1_80, name = 'ssh1_80_')\n",
        "ssh_layer2 = ssh(fpn_layer2_40, name = 'ssh2_40_')\n",
        "ssh_layer3 = ssh(fpn_layer3_20, name = 'ssh3_20_')\n",
        "\n",
        "#Classification head\n",
        "classification_layer1 = classification_head(ssh_layer1, len(min_sizes[0]), 'classification_layer1')\n",
        "classification_layer2 = classification_head(ssh_layer2, len(min_sizes[0]), 'classification_layer2')\n",
        "classification_layer3 = classification_head(ssh_layer3, len(min_sizes[0]), 'classification_layer3')\n",
        "\n",
        "classifications = tf.concat([classification_layer1,\n",
        "                             classification_layer2,\n",
        "                             classification_layer3], axis=1)\n",
        "\n",
        "#classification activation function \n",
        "classifications = tf.keras.layers.Softmax(axis = -1, name = 'classifications_softmax')(classifications)\n",
        "\n",
        "\n",
        "#bounding box regressions head\n",
        "bbox_layer1 = bbox_head(ssh_layer1, len(min_sizes[0]), 'bbox_layer1')\n",
        "bbox_layer2 = bbox_head(ssh_layer2, len(min_sizes[0]), 'bbox_layer2')\n",
        "bbox_layer3 = bbox_head(ssh_layer3, len(min_sizes[0]), 'bbox_layer3')\n",
        "\n",
        "bbox_regressions = tf.concat([bbox_layer1,\n",
        "                              bbox_layer2,\n",
        "                              bbox_layer3], axis=1)\n",
        "\n",
        "#output\n",
        "output = (bbox_regressions, classifications)\n",
        "\n",
        "model = Model(inputs, output)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBrIUHrQ51Kl",
        "outputId": "43d54e25-350a-41fd-fb2b-0b0fd345eb23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_image (InputLayer)       [(None, 640, 640, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " tf.math.truediv_3 (TFOpLambda)  (None, 640, 640, 3)  0          ['input_image[0][0]']            \n",
            "                                                                                                  \n",
            " tf.math.subtract_3 (TFOpLambda  (None, 640, 640, 3)  0          ['tf.math.truediv_3[0][0]']      \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " mobilenet_layer116_40 (Functio  (None, 40, 40, 576)  613952     ['tf.math.subtract_3[0][0]']     \n",
            " nal)                                                                                             \n",
            "                                                                                                  \n",
            " fpn2_conv (Conv2D)             (None, 40, 40, 64)   36864       ['mobilenet_layer116_40[0][0]']  \n",
            "                                                                                                  \n",
            " fpn2_batchnorm (BatchNormaliza  (None, 40, 40, 64)  256         ['fpn2_conv[0][0]']              \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " mobilenet_layer143_20 (Functio  (None, 20, 20, 960)  1518464    ['tf.math.subtract_3[0][0]']     \n",
            " nal)                                                                                             \n",
            "                                                                                                  \n",
            " fpn2_relu (ReLU)               (None, 40, 40, 64)   0           ['fpn2_batchnorm[0][0]']         \n",
            "                                                                                                  \n",
            " fpn3_conv (Conv2D)             (None, 20, 20, 64)   61440       ['mobilenet_layer143_20[0][0]']  \n",
            "                                                                                                  \n",
            " fpn3_batchnorm (BatchNormaliza  (None, 20, 20, 64)  256         ['fpn3_conv[0][0]']              \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_24 (TFOpLam  (4,)                0           ['fpn2_relu[0][0]']              \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_25 (TFOpLam  (4,)                0           ['fpn2_relu[0][0]']              \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " mobilenet_layer54_80 (Function  (None, 80, 80, 192)  65152      ['tf.math.subtract_3[0][0]']     \n",
            " al)                                                                                              \n",
            "                                                                                                  \n",
            " fpn3_relu (ReLU)               (None, 20, 20, 64)   0           ['fpn3_batchnorm[0][0]']         \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_24 (S  ()                  0           ['tf.compat.v1.shape_24[0][0]']  \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_25 (S  ()                  0           ['tf.compat.v1.shape_25[0][0]']  \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " fpn1_conv (Conv2D)             (None, 80, 80, 64)   12288       ['mobilenet_layer54_80[0][0]']   \n",
            "                                                                                                  \n",
            " tf.image.resize_6 (TFOpLambda)  (None, 40, 40, 64)  0           ['fpn3_relu[0][0]',              \n",
            "                                                                  'tf.__operators__.getitem_24[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_25[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " fpn1_batchnorm (BatchNormaliza  (None, 80, 80, 64)  256         ['fpn1_conv[0][0]']              \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TFOpLa  (None, 40, 40, 64)  0           ['fpn2_relu[0][0]',              \n",
            " mbda)                                                            'tf.image.resize_6[0][0]']      \n",
            "                                                                                                  \n",
            " fpn1_relu (ReLU)               (None, 80, 80, 64)   0           ['fpn1_batchnorm[0][0]']         \n",
            "                                                                                                  \n",
            " fpn2_merge_conv (Conv2D)       (None, 40, 40, 64)   36864       ['tf.__operators__.add_6[0][0]'] \n",
            "                                                                                                  \n",
            " fpn2_merge_batchnorm (BatchNor  (None, 40, 40, 64)  256         ['fpn2_merge_conv[0][0]']        \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_26 (TFOpLam  (4,)                0           ['fpn1_relu[0][0]']              \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_27 (TFOpLam  (4,)                0           ['fpn1_relu[0][0]']              \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " fpn2_merge_relu (ReLU)         (None, 40, 40, 64)   0           ['fpn2_merge_batchnorm[0][0]']   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_26 (S  ()                  0           ['tf.compat.v1.shape_26[0][0]']  \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_27 (S  ()                  0           ['tf.compat.v1.shape_27[0][0]']  \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.image.resize_7 (TFOpLambda)  (None, 80, 80, 64)  0           ['fpn2_merge_relu[0][0]',        \n",
            "                                                                  'tf.__operators__.getitem_26[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_27[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_7 (TFOpLa  (None, 80, 80, 64)  0           ['fpn1_relu[0][0]',              \n",
            " mbda)                                                            'tf.image.resize_7[0][0]']      \n",
            "                                                                                                  \n",
            " fpn1_merge_conv (Conv2D)       (None, 80, 80, 64)   36864       ['tf.__operators__.add_7[0][0]'] \n",
            "                                                                                                  \n",
            " fpn1_merge_batchnorm (BatchNor  (None, 80, 80, 64)  256         ['fpn1_merge_conv[0][0]']        \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " fpn1_merge_relu (ReLU)         (None, 80, 80, 64)   0           ['fpn1_merge_batchnorm[0][0]']   \n",
            "                                                                                                  \n",
            " ssh1_80_conv_5x5_1conv (Conv2D  (None, 80, 80, 16)  9216        ['fpn1_merge_relu[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " ssh2_40_conv_5x5_1conv (Conv2D  (None, 40, 40, 16)  9216        ['fpn2_merge_relu[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " ssh3_20_conv_5x5_1conv (Conv2D  (None, 20, 20, 16)  9216        ['fpn3_relu[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " ssh1_80_conv_5x5_1batchnorm (B  (None, 80, 80, 16)  64          ['ssh1_80_conv_5x5_1conv[0][0]'] \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " ssh2_40_conv_5x5_1batchnorm (B  (None, 40, 40, 16)  64          ['ssh2_40_conv_5x5_1conv[0][0]'] \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " ssh3_20_conv_5x5_1batchnorm (B  (None, 20, 20, 16)  64          ['ssh3_20_conv_5x5_1conv[0][0]'] \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " ssh1_80_conv_5x5_1relu (ReLU)  (None, 80, 80, 16)   0           ['ssh1_80_conv_5x5_1batchnorm[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " ssh2_40_conv_5x5_1relu (ReLU)  (None, 40, 40, 16)   0           ['ssh2_40_conv_5x5_1batchnorm[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " ssh3_20_conv_5x5_1relu (ReLU)  (None, 20, 20, 16)   0           ['ssh3_20_conv_5x5_1batchnorm[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " ssh1_80_conv_7x7_1conv (Conv2D  (None, 80, 80, 16)  2304        ['ssh1_80_conv_5x5_1relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " ssh2_40_conv_7x7_1conv (Conv2D  (None, 40, 40, 16)  2304        ['ssh2_40_conv_5x5_1relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " ssh3_20_conv_7x7_1conv (Conv2D  (None, 20, 20, 16)  2304        ['ssh3_20_conv_5x5_1relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " ssh1_80_conv_7x7_1batchnorm (B  (None, 80, 80, 16)  64          ['ssh1_80_conv_7x7_1conv[0][0]'] \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " ssh2_40_conv_7x7_1batchnorm (B  (None, 40, 40, 16)  64          ['ssh2_40_conv_7x7_1conv[0][0]'] \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " ssh3_20_conv_7x7_1batchnorm (B  (None, 20, 20, 16)  64          ['ssh3_20_conv_7x7_1conv[0][0]'] \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " ssh1_80_conv_7x7_1relu (ReLU)  (None, 80, 80, 16)   0           ['ssh1_80_conv_7x7_1batchnorm[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " ssh2_40_conv_7x7_1relu (ReLU)  (None, 40, 40, 16)   0           ['ssh2_40_conv_7x7_1batchnorm[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " ssh3_20_conv_7x7_1relu (ReLU)  (None, 20, 20, 16)   0           ['ssh3_20_conv_7x7_1batchnorm[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " ssh1_80_conv_3x3conv (Conv2D)  (None, 80, 80, 32)   18432       ['fpn1_merge_relu[0][0]']        \n",
            "                                                                                                  \n",
            " ssh1_80_conv_5x5conv (Conv2D)  (None, 80, 80, 16)   2304        ['ssh1_80_conv_5x5_1relu[0][0]'] \n",
            "                                                                                                  \n",
            " ssh1_80_conv_7x7conv (Conv2D)  (None, 80, 80, 16)   2304        ['ssh1_80_conv_7x7_1relu[0][0]'] \n",
            "                                                                                                  \n",
            " ssh2_40_conv_3x3conv (Conv2D)  (None, 40, 40, 32)   18432       ['fpn2_merge_relu[0][0]']        \n",
            "                                                                                                  \n",
            " ssh2_40_conv_5x5conv (Conv2D)  (None, 40, 40, 16)   2304        ['ssh2_40_conv_5x5_1relu[0][0]'] \n",
            "                                                                                                  \n",
            " ssh2_40_conv_7x7conv (Conv2D)  (None, 40, 40, 16)   2304        ['ssh2_40_conv_7x7_1relu[0][0]'] \n",
            "                                                                                                  \n",
            " ssh3_20_conv_3x3conv (Conv2D)  (None, 20, 20, 32)   18432       ['fpn3_relu[0][0]']              \n",
            "                                                                                                  \n",
            " ssh3_20_conv_5x5conv (Conv2D)  (None, 20, 20, 16)   2304        ['ssh3_20_conv_5x5_1relu[0][0]'] \n",
            "                                                                                                  \n",
            " ssh3_20_conv_7x7conv (Conv2D)  (None, 20, 20, 16)   2304        ['ssh3_20_conv_7x7_1relu[0][0]'] \n",
            "                                                                                                  \n",
            " ssh1_80_conv_3x3batchnorm (Bat  (None, 80, 80, 32)  128         ['ssh1_80_conv_3x3conv[0][0]']   \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " ssh1_80_conv_5x5batchnorm (Bat  (None, 80, 80, 16)  64          ['ssh1_80_conv_5x5conv[0][0]']   \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " ssh1_80_conv_7x7batchnorm (Bat  (None, 80, 80, 16)  64          ['ssh1_80_conv_7x7conv[0][0]']   \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " ssh2_40_conv_3x3batchnorm (Bat  (None, 40, 40, 32)  128         ['ssh2_40_conv_3x3conv[0][0]']   \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " ssh2_40_conv_5x5batchnorm (Bat  (None, 40, 40, 16)  64          ['ssh2_40_conv_5x5conv[0][0]']   \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " ssh2_40_conv_7x7batchnorm (Bat  (None, 40, 40, 16)  64          ['ssh2_40_conv_7x7conv[0][0]']   \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " ssh3_20_conv_3x3batchnorm (Bat  (None, 20, 20, 32)  128         ['ssh3_20_conv_3x3conv[0][0]']   \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " ssh3_20_conv_5x5batchnorm (Bat  (None, 20, 20, 16)  64          ['ssh3_20_conv_5x5conv[0][0]']   \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " ssh3_20_conv_7x7batchnorm (Bat  (None, 20, 20, 16)  64          ['ssh3_20_conv_7x7conv[0][0]']   \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.concat_7 (TFOpLambda)       (None, 80, 80, 64)   0           ['ssh1_80_conv_3x3batchnorm[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'ssh1_80_conv_5x5batchnorm[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'ssh1_80_conv_7x7batchnorm[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " tf.concat_8 (TFOpLambda)       (None, 40, 40, 64)   0           ['ssh2_40_conv_3x3batchnorm[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'ssh2_40_conv_5x5batchnorm[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'ssh2_40_conv_7x7batchnorm[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " tf.concat_9 (TFOpLambda)       (None, 20, 20, 64)   0           ['ssh3_20_conv_3x3batchnorm[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'ssh3_20_conv_5x5batchnorm[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'ssh3_20_conv_7x7batchnorm[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " ssh1_80_final_relu (ReLU)      (None, 80, 80, 64)   0           ['tf.concat_7[0][0]']            \n",
            "                                                                                                  \n",
            " ssh2_40_final_relu (ReLU)      (None, 40, 40, 64)   0           ['tf.concat_8[0][0]']            \n",
            "                                                                                                  \n",
            " ssh3_20_final_relu (ReLU)      (None, 20, 20, 64)   0           ['tf.concat_9[0][0]']            \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_28 (TFOpLam  (4,)                0           ['ssh1_80_final_relu[0][0]']     \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_29 (TFOpLam  (4,)                0           ['ssh1_80_final_relu[0][0]']     \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_30 (TFOpLam  (4,)                0           ['ssh2_40_final_relu[0][0]']     \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_31 (TFOpLam  (4,)                0           ['ssh2_40_final_relu[0][0]']     \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_32 (TFOpLam  (4,)                0           ['ssh3_20_final_relu[0][0]']     \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_33 (TFOpLam  (4,)                0           ['ssh3_20_final_relu[0][0]']     \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_28 (S  ()                  0           ['tf.compat.v1.shape_28[0][0]']  \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_29 (S  ()                  0           ['tf.compat.v1.shape_29[0][0]']  \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_30 (S  ()                  0           ['tf.compat.v1.shape_30[0][0]']  \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_31 (S  ()                  0           ['tf.compat.v1.shape_31[0][0]']  \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_32 (S  ()                  0           ['tf.compat.v1.shape_32[0][0]']  \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_33 (S  ()                  0           ['tf.compat.v1.shape_33[0][0]']  \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_34 (TFOpLam  (4,)                0           ['ssh1_80_final_relu[0][0]']     \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_35 (TFOpLam  (4,)                0           ['ssh1_80_final_relu[0][0]']     \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_36 (TFOpLam  (4,)                0           ['ssh2_40_final_relu[0][0]']     \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_37 (TFOpLam  (4,)                0           ['ssh2_40_final_relu[0][0]']     \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_38 (TFOpLam  (4,)                0           ['ssh3_20_final_relu[0][0]']     \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_39 (TFOpLam  (4,)                0           ['ssh3_20_final_relu[0][0]']     \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_12 (TFOpLambd  ()                  0           ['tf.__operators__.getitem_28[0][\n",
            " a)                                                              0]',                             \n",
            "                                                                  'tf.__operators__.getitem_29[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_14 (TFOpLambd  ()                  0           ['tf.__operators__.getitem_30[0][\n",
            " a)                                                              0]',                             \n",
            "                                                                  'tf.__operators__.getitem_31[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_16 (TFOpLambd  ()                  0           ['tf.__operators__.getitem_32[0][\n",
            " a)                                                              0]',                             \n",
            "                                                                  'tf.__operators__.getitem_33[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_34 (S  ()                  0           ['tf.compat.v1.shape_34[0][0]']  \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_35 (S  ()                  0           ['tf.compat.v1.shape_35[0][0]']  \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_36 (S  ()                  0           ['tf.compat.v1.shape_36[0][0]']  \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_37 (S  ()                  0           ['tf.compat.v1.shape_37[0][0]']  \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_38 (S  ()                  0           ['tf.compat.v1.shape_38[0][0]']  \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_39 (S  ()                  0           ['tf.compat.v1.shape_39[0][0]']  \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " classification_layer1 (Conv2D)  (None, 80, 80, 4)   260         ['ssh1_80_final_relu[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.multiply_13 (TFOpLambd  ()                  0           ['tf.math.multiply_12[0][0]']    \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " classification_layer2 (Conv2D)  (None, 40, 40, 4)   260         ['ssh2_40_final_relu[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.multiply_15 (TFOpLambd  ()                  0           ['tf.math.multiply_14[0][0]']    \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " classification_layer3 (Conv2D)  (None, 20, 20, 4)   260         ['ssh3_20_final_relu[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.multiply_17 (TFOpLambd  ()                  0           ['tf.math.multiply_16[0][0]']    \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_18 (TFOpLambd  ()                  0           ['tf.__operators__.getitem_34[0][\n",
            " a)                                                              0]',                             \n",
            "                                                                  'tf.__operators__.getitem_35[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_20 (TFOpLambd  ()                  0           ['tf.__operators__.getitem_36[0][\n",
            " a)                                                              0]',                             \n",
            "                                                                  'tf.__operators__.getitem_37[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_22 (TFOpLambd  ()                  0           ['tf.__operators__.getitem_38[0][\n",
            " a)                                                              0]',                             \n",
            "                                                                  'tf.__operators__.getitem_39[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.reshape_6 (TFOpLambda)      (None, 12800, 2)     0           ['classification_layer1[0][0]',  \n",
            "                                                                  'tf.math.multiply_13[0][0]']    \n",
            "                                                                                                  \n",
            " tf.reshape_7 (TFOpLambda)      (None, 3200, 2)      0           ['classification_layer2[0][0]',  \n",
            "                                                                  'tf.math.multiply_15[0][0]']    \n",
            "                                                                                                  \n",
            " tf.reshape_8 (TFOpLambda)      (None, 800, 2)       0           ['classification_layer3[0][0]',  \n",
            "                                                                  'tf.math.multiply_17[0][0]']    \n",
            "                                                                                                  \n",
            " bbox_layer1 (Conv2D)           (None, 80, 80, 8)    520         ['ssh1_80_final_relu[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.multiply_19 (TFOpLambd  ()                  0           ['tf.math.multiply_18[0][0]']    \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " bbox_layer2 (Conv2D)           (None, 40, 40, 8)    520         ['ssh2_40_final_relu[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.multiply_21 (TFOpLambd  ()                  0           ['tf.math.multiply_20[0][0]']    \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " bbox_layer3 (Conv2D)           (None, 20, 20, 8)    520         ['ssh3_20_final_relu[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.multiply_23 (TFOpLambd  ()                  0           ['tf.math.multiply_22[0][0]']    \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.concat_10 (TFOpLambda)      (None, 16800, 2)     0           ['tf.reshape_6[0][0]',           \n",
            "                                                                  'tf.reshape_7[0][0]',           \n",
            "                                                                  'tf.reshape_8[0][0]']           \n",
            "                                                                                                  \n",
            " tf.reshape_9 (TFOpLambda)      (None, 12800, 4)     0           ['bbox_layer1[0][0]',            \n",
            "                                                                  'tf.math.multiply_19[0][0]']    \n",
            "                                                                                                  \n",
            " tf.reshape_10 (TFOpLambda)     (None, 3200, 4)      0           ['bbox_layer2[0][0]',            \n",
            "                                                                  'tf.math.multiply_21[0][0]']    \n",
            "                                                                                                  \n",
            " tf.reshape_11 (TFOpLambda)     (None, 800, 4)       0           ['bbox_layer3[0][0]',            \n",
            "                                                                  'tf.math.multiply_23[0][0]']    \n",
            "                                                                                                  \n",
            " classifications_softmax (Softm  (None, 16800, 2)    0           ['tf.concat_10[0][0]']           \n",
            " ax)                                                                                              \n",
            "                                                                                                  \n",
            " tf.concat_11 (TFOpLambda)      (None, 16800, 4)     0           ['tf.reshape_9[0][0]',           \n",
            "                                                                  'tf.reshape_10[0][0]',          \n",
            "                                                                  'tf.reshape_11[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,811,236\n",
            "Trainable params: 291,556\n",
            "Non-trainable params: 1,519,680\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, \n",
        "                          to_file='/content/drive/MyDrive/AI_Notebooks_and_Models/RetinaFace/Original/model_original.png', \n",
        "                          show_shapes=True,\n",
        "                          show_layer_names=True)"
      ],
      "metadata": {
        "id": "cYFFr4xK51OG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"/content/drive/MyDrive/AI_Notebooks_and_Models/RetinaFace/Original/model_original.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "\n",
        "model.save_weights('/content/drive/MyDrive/AI_Notebooks_and_Models/RetinaFace/Original/model_original_withoutTraining.h5')\n"
      ],
      "metadata": {
        "id": "N2ThmuWRHwnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZLxWSH4jHwVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "preds = tf.concat(  # [bboxes,  landms_valid, conf]\n",
        "    [bbox_regressions[0],\n",
        "    tf.ones_like(classifications[0, :, 0][..., tf.newaxis]),\n",
        "    classifications[0, :, 1][..., tf.newaxis]], 1)\n",
        "\n",
        "priors = prior_box_tf((tf.shape(inputs)[1], tf.shape(inputs)[2]),\n",
        "                        cfg['min_sizes'],  cfg['steps'], cfg['clip'])\n",
        "\n",
        "decode_preds = decode_tf(preds, priors, cfg['variances'])\n",
        "\n",
        "selected_indices = tf.image.non_max_suppression(\n",
        "    boxes=decode_preds[:, :4],\n",
        "    scores=decode_preds[:, -1],\n",
        "    max_output_size=tf.shape(decode_preds)[0],\n",
        "    iou_threshold=iou_th,\n",
        "    score_threshold=score_th)\n",
        "\n",
        "out = tf.gather(decode_preds, selected_indices)"
      ],
      "metadata": {
        "id": "lrBQjCr0HwTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AUg3CeZX6aBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XmTY20quJPXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2Xu0-OrT7bR",
        "outputId": "11e27968-4ee6-411e-a9e8-5b177a72ec0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'backbone_type': 'MobileNetV2',\n",
              " 'batch_size': 4,\n",
              " 'clip': False,\n",
              " 'dataset_len': 12880,\n",
              " 'dataset_path': '/content/widerface_train_bin.tfrecord',\n",
              " 'epoch': 1,\n",
              " 'ignore_thresh': 0.3,\n",
              " 'init_lr': 0.01,\n",
              " 'input_size': 640,\n",
              " 'lr_decay_epoch': [50, 68],\n",
              " 'lr_rate': 0.1,\n",
              " 'match_thresh': 0.45,\n",
              " 'min_lr': 0.001,\n",
              " 'min_sizes': [[16, 32], [64, 128], [256, 512]],\n",
              " 'momentum': 0.9,\n",
              " 'out_channel': 64,\n",
              " 'pretrain': True,\n",
              " 'save_steps': 1000,\n",
              " 'steps': [8, 16, 32],\n",
              " 'sub_name': 'retinaface_mbv2',\n",
              " 'using_bin': True,\n",
              " 'using_distort': True,\n",
              " 'using_flip': True,\n",
              " 'variances': [0.1, 0.2],\n",
              " 'warmup_epoch': 5,\n",
              " 'weights_decay': 0.0005}"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(cfg['min_sizes'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx8-SFf4p66n",
        "outputId": "68c86cc0-6696-4865-baea-c36c97ab171f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EA5lFV-4nFmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XgQymODtnFjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model defining and training - train.py"
      ],
      "metadata": {
        "id": "4IXSZvFMnQdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "T_f5GZRLdWWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FgKZO12EdWT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# END"
      ],
      "metadata": {
        "id": "ZYfuaRJa71xP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RSJPR99ZmGe-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}